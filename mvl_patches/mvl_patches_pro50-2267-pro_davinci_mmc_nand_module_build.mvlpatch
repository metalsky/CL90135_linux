#! /usr/bin/env bash
# Patch: -pro_davinci_mmc_nand_module_build
# Date: Thu Feb 19 15:12:30 2009
# Source: MontaVista Software, Inc.
# MR: 31986
# Type: Defect Fix
# Disposition: needs submitting to linux-arm-kernel
# Signed-off-by: Steve Chen <schen@mvista.com>
# Description:
# 
#  Patch based on suggestion from Snehaprabha Narnakaje <nsnehaprabha@ti.com>
#  Unable to build both MMC and NAND as modules due to name conflict.  Rename
#  both the MMC and NAND driver so that both can be build as module.
# 
#  drivers/mmc/Makefile            |    2 
#  drivers/mmc/davinci-mmc.c       | 1595 ++++++++++++++++++++++++++++++++++++++++
#  drivers/mmc/davinci.c           | 1595 ----------------------------------------
#  drivers/mtd/nand/Makefile       |    2 
#  drivers/mtd/nand/davinci-nand.c | 1136 ++++++++++++++++++++++++++++
#  drivers/mtd/nand/davinci.c      | 1136 ----------------------------
#  6 files changed, 2733 insertions(+), 2733 deletions(-)
# 

PATCHNUM=2267
LSPINFO=include/linux/lsppatchlevel.h
TMPFILE=/tmp/mvl_patch_$$

function dopatch() {
    patch $* >${TMPFILE} 2>&1 <<"EOF"
Source: MontaVista Software, Inc.
MR: 31986
Type: Defect Fix
Disposition: needs submitting to linux-arm-kernel
Signed-off-by: Steve Chen <schen@mvista.com>
Description:

 Patch based on suggestion from Snehaprabha Narnakaje <nsnehaprabha@ti.com>
 Unable to build both MMC and NAND as modules due to name conflict.  Rename
 both the MMC and NAND driver so that both can be build as module.

 drivers/mmc/Makefile            |    2 
 drivers/mmc/davinci-mmc.c       | 1595 ++++++++++++++++++++++++++++++++++++++++
 drivers/mmc/davinci.c           | 1595 ----------------------------------------
 drivers/mtd/nand/Makefile       |    2 
 drivers/mtd/nand/davinci-nand.c | 1136 ++++++++++++++++++++++++++++
 drivers/mtd/nand/davinci.c      | 1136 ----------------------------
 mvl_patches/pro50-2267.c        |   16 
 7 files changed, 2749 insertions(+), 2733 deletions(-)

Index: linux-2.6.18/drivers/mmc/Makefile
===================================================================
--- linux-2.6.18.orig/drivers/mmc/Makefile
+++ linux-2.6.18/drivers/mmc/Makefile
@@ -23,7 +23,7 @@ obj-$(CONFIG_MMC_WBSD)		+= wbsd.o
 obj-$(CONFIG_MMC_AU1X)		+= au1xmmc.o
 obj-$(CONFIG_MMC_OMAP)		+= omap.o
 obj-$(CONFIG_MMC_AT91RM9200)	+= at91_mci.o
-obj-$(CONFIG_MMC_DAVINCI) 	+= davinci.o
+obj-$(CONFIG_MMC_DAVINCI)	+= davinci-mmc.o
 
 mmc_core-y := mmc.o mmc_queue.o mmc_sysfs.o
 
Index: linux-2.6.18/drivers/mmc/davinci-mmc.c
===================================================================
--- /dev/null
+++ linux-2.6.18/drivers/mmc/davinci-mmc.c
@@ -0,0 +1,1595 @@
+/*
+ * linux/drivers/mmc/davinci.c
+ *
+ * TI DaVinci MMC controller file
+ *
+ * Copyright (C) 2006 Texas Instruments.
+ *
+ * ----------------------------------------------------------------------------
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ * ----------------------------------------------------------------------------
+ * Modifications:
+ * ver. 1.0: Oct 2005, Purushotam Kumar   Initial version
+ * ver 1.1:  Nov  2005, Purushotam Kumar  Solved bugs
+ * ver 1.2:  Jan  2006, Purushotam Kumar   Added card remove insert support
+ */
+
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+#include <linux/ioport.h>
+#include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/dma-mapping.h>
+#include <linux/delay.h>
+#include <linux/spinlock.h>
+#include <linux/timer.h>
+#include <linux/mmc/host.h>
+#include <linux/mmc/protocol.h>
+#include <linux/mmc/card.h>
+#include <linux/clk.h>
+#include <linux/io.h>
+#include <linux/irq.h>
+#include <linux/scatterlist.h>
+
+#include <asm/arch/mmc.h>
+#include <asm/arch/edma.h>
+
+#define	DAVINCI_MMC_REG_CTL	0x00
+#define	DAVINCI_MMC_REG_CLK	0x04
+#define	DAVINCI_MMC_REG_ST0	0x08
+#define	DAVINCI_MMC_REG_ST1	0x0c
+#define	DAVINCI_MMC_REG_IM	0x10
+#define	DAVINCI_MMC_REG_TOR	0x14
+#define	DAVINCI_MMC_REG_TOD	0x18
+#define	DAVINCI_MMC_REG_BLEN	0x1c
+#define	DAVINCI_MMC_REG_NBLK	0x20
+#define	DAVINCI_MMC_REG_NBLC	0x24
+#define	DAVINCI_MMC_REG_DRR	0x28
+#define	DAVINCI_MMC_REG_DXR	0x2c
+#define	DAVINCI_MMC_REG_CMD	0x30
+#define	DAVINCI_MMC_REG_ARGHL	0x34
+#define	DAVINCI_MMC_REG_RSP01	0x38
+#define	DAVINCI_MMC_REG_RSP23	0x3c
+#define	DAVINCI_MMC_REG_RSP45	0x40
+#define	DAVINCI_MMC_REG_RSP67	0x44
+#define	DAVINCI_MMC_REG_DRSP	0x48
+#define	DAVINCI_MMC_REG_ETOK	0x4c
+#define	DAVINCI_MMC_REG_CIDX	0x50
+#define	DAVINCI_MMC_REG_CKC	0x54
+#define	DAVINCI_MMC_REG_TORC	0x58
+#define	DAVINCI_MMC_REG_TODC	0x5c
+#define	DAVINCI_MMC_REG_BLNC	0x60
+#define	DAVINCI_SDIO_REG_CTL	0x64
+#define	DAVINCI_SDIO_REG_ST0	0x68
+#define	DAVINCI_SDIO_REG_EN	0x6c
+#define	DAVINCI_SDIO_REG_ST	0x70
+#define	DAVINCI_MMC_REG_FIFO_CTL	0x74
+
+#define DAVINCI_MMC_READW(host, reg) \
+	__raw_readw((host)->virt_base + DAVINCI_MMC_REG_##reg)
+#define DAVINCI_MMC_WRITEW(host, reg, val) \
+	__raw_writew((val), (host)->virt_base + DAVINCI_MMC_REG_##reg)
+#define DAVINCI_MMC_READL(host, reg) \
+	__raw_readl((host)->virt_base + DAVINCI_MMC_REG_##reg)
+#define DAVINCI_MMC_WRITEL(host, reg, val) \
+	__raw_writel((val), (host)->virt_base + DAVINCI_MMC_REG_##reg)
+/*
+ * Command types
+ */
+#define DAVINCI_MMC_CMDTYPE_BC		0
+#define DAVINCI_MMC_CMDTYPE_BCR		1
+#define DAVINCI_MMC_CMDTYPE_AC		2
+#define DAVINCI_MMC_CMDTYPE_ADTC	3
+#define EDMA_MAX_LOGICAL_CHA_ALLOWED	1
+
+#define DAVINCI_MMC_EVENT_BLOCK_XFERRED		(1 <<  0)
+#define DAVINCI_MMC_EVENT_CARD_EXITBUSY		(1 <<  1)
+#define	DAVINCI_MMC_EVENT_EOFCMD		(1 <<  2)
+#define DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT	(1 <<  3)
+#define DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT	(1 <<  4)
+#define DAVINCI_MMC_EVENT_ERROR_DATACRC		((1 << 6) | (1 << 5))
+#define DAVINCI_MMC_EVENT_ERROR_CMDCRC		(1 <<  7)
+#define DAVINCI_MMC_EVENT_WRITE			(1 <<  9)
+#define DAVINCI_MMC_EVENT_READ			(1 << 10)
+
+#define DAVINCI_MMC_EVENT_TIMEOUT_ERROR \
+ (DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT | DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT)
+#define DAVINCI_MMC_EVENT_CRC_ERROR \
+ (DAVINCI_MMC_EVENT_ERROR_DATACRC | DAVINCI_MMC_EVENT_ERROR_CMDCRC)
+#define DAVINCI_MMC_EVENT_ERROR \
+ (DAVINCI_MMC_EVENT_TIMEOUT_ERROR | DAVINCI_MMC_EVENT_CRC_ERROR)
+#define DRIVER_NAME "davinci-mmc"
+#define RSP_TYPE(x)	((x) & ~(MMC_RSP_BUSY|MMC_RSP_OPCODE))
+
+struct edma_ch_mmcsd {
+	unsigned char cnt_chanel;
+	unsigned int chanel_num[EDMA_MAX_LOGICAL_CHA_ALLOWED];
+};
+
+struct mmc_davinci_host {
+	struct resource 	*reg_res;
+	spinlock_t		mmc_lock;
+	int			is_card_busy;
+	int			is_card_detect_progress;
+	int			is_card_initialized;
+	int			is_card_removed;
+	int			is_init_progress;
+	int			is_req_queued_up;
+	struct mmc_host		*que_mmc_host;
+	struct mmc_request	*que_mmc_request;
+	struct mmc_command	*cmd;
+	struct mmc_data		*data;
+	struct mmc_host		*mmc;
+	struct device		*dev;
+	struct clk		*clk;
+	struct resource		*mem_res;
+	void __iomem		*virt_base;
+	unsigned int		phys_base;
+	unsigned int		rw_threshold;
+	unsigned int		option_read;
+	unsigned int		option_write;
+	int			flag_sd_mmc;
+	int			irq;
+	unsigned char		bus_mode;
+
+#define DAVINCI_MMC_DATADIR_NONE	0
+#define DAVINCI_MMC_DATADIR_READ	1
+#define DAVINCI_MMC_DATADIR_WRITE	2
+	unsigned char		data_dir;
+	u32			*buffer;
+	u32			bytes_left;
+
+	int			use_dma;
+	int			do_dma;
+	unsigned int		dma_rx_event;
+	unsigned int		dma_tx_event;
+
+	struct timer_list	timer;
+	unsigned int		is_core_command;
+	unsigned int		cmd_code;
+	unsigned int		old_card_state;
+	unsigned int		new_card_state;
+
+	unsigned char		sd_support;
+
+	struct edma_ch_mmcsd	edma_ch_details;
+
+	unsigned int		sg_len;
+	int			sg_idx;
+	unsigned int		buffer_bytes_left;
+	unsigned char		pio_set_dmatrig;
+	int 			(*get_ro) (int);
+};
+
+
+void davinci_clean_channel(int ch_no);
+
+/* MMCSD Init clock in Hz in opendain mode */
+#define DAVINCI_MMC_INIT_CLOCK 		200000
+
+/* This macro could not be defined to 0 (ZERO) or -ve value.
+ * This value is multiplied to "HZ"
+ * while requesting for timer interrupt every time for probing card.
+ */
+#define MULTIPLIER_TO_HZ 1
+
+#define MMCST1_BUSY	(1 << 0)
+
+static inline void wait_on_data(struct mmc_davinci_host *host)
+{
+	int cnt = 900000;
+	u16 reg = DAVINCI_MMC_READW(host, ST1);
+
+	while ((reg & MMCST1_BUSY) && cnt) {
+		cnt--;
+		udelay(1);
+		reg = DAVINCI_MMC_READW(host, ST1);
+	}
+	if (!cnt)
+		dev_warn(host->mmc->dev, "ERROR: TOUT waiting for BUSY\n");
+}
+
+/* PIO only */
+static void mmc_davinci_sg_to_buf(struct mmc_davinci_host *host)
+{
+	struct scatterlist *sg;
+
+	sg = host->data->sg + host->sg_idx;
+	host->buffer_bytes_left = sg->length;
+	host->buffer = page_address(sg->page) + sg->offset;
+	if (host->buffer_bytes_left > host->bytes_left)
+		host->buffer_bytes_left = host->bytes_left;
+}
+
+static void davinci_fifo_data_trans(struct mmc_davinci_host *host)
+{
+	int n, i;
+
+	if (host->buffer_bytes_left == 0) {
+		host->sg_idx++;
+		BUG_ON(host->sg_idx == host->sg_len);
+		mmc_davinci_sg_to_buf(host);
+	}
+
+	n = host->rw_threshold;
+	if (n > host->buffer_bytes_left)
+		n = host->buffer_bytes_left;
+
+	host->buffer_bytes_left -= n;
+	host->bytes_left -= n;
+
+	if (host->data_dir == DAVINCI_MMC_DATADIR_WRITE)
+		for (i = 0; i < (n / 4); i++) {
+			DAVINCI_MMC_WRITEL(host, DXR, *host->buffer);
+			host->buffer++;
+		}
+	else
+		for (i = 0; i < (n / 4); i++) {
+			*host->buffer = DAVINCI_MMC_READL(host, DRR);
+			host->buffer++;
+		}
+}
+
+
+
+static void mmc_davinci_start_command(struct mmc_davinci_host *host,
+				      struct mmc_command *cmd)
+{
+	u32 cmdreg = 0;
+	u32 resptype = 0;
+	u32 cmdtype = 0;
+	unsigned long flags;
+
+	host->cmd = cmd;
+
+	resptype = 0;
+	cmdtype = 0;
+
+	switch (RSP_TYPE(mmc_resp_type(cmd))) {
+	case RSP_TYPE(MMC_RSP_R1):
+		/* resp 1, resp 1b */
+		resptype = 1;
+		break;
+	case RSP_TYPE(MMC_RSP_R2):
+		resptype = 2;
+		break;
+	case RSP_TYPE(MMC_RSP_R3):
+		resptype = 3;
+		break;
+	default:
+		break;
+	}
+
+	/* Protocol layer does not provide command type, but our hardware
+	 * needs it!
+	 * any data transfer means adtc type (but that information is not
+	 * in command structure, so we flagged it into host struct.)
+	 * However, telling bc, bcr and ac apart based on response is
+	 * not foolproof:
+	 * CMD0  = bc  = resp0  CMD15 = ac  = resp0
+	 * CMD2  = bcr = resp2  CMD10 = ac  = resp2
+	 *
+	 * Resolve to best guess with some exception testing:
+	 * resp0 -> bc, except CMD15 = ac
+	 * rest are ac, except if opendrain
+	 */
+
+	if (host->data_dir)
+		cmdtype = DAVINCI_MMC_CMDTYPE_ADTC;
+	else if (resptype == 0 && cmd->opcode != 15)
+		cmdtype = DAVINCI_MMC_CMDTYPE_BC;
+	else if (host->bus_mode == MMC_BUSMODE_OPENDRAIN)
+		cmdtype = DAVINCI_MMC_CMDTYPE_BCR;
+	else
+		cmdtype = DAVINCI_MMC_CMDTYPE_AC;
+
+	/*
+	 * Set command Busy or not
+	 * Linux core sending BUSY which is not defined for cmd 24
+	 * as per mmc standard
+	 */
+	if (cmd->flags & MMC_RSP_BUSY)
+		if (cmd->opcode != 24)
+			cmdreg = cmdreg | (1 << 8);
+
+	/* Set command index */
+	cmdreg |= cmd->opcode;
+
+	/* Setting initialize clock */
+	if (cmd->opcode == 0)
+		cmdreg = cmdreg | (1 << 14);
+
+	/* Set for generating DMA Xfer event */
+	if ((host->do_dma == 1) && (host->data != NULL)
+	    && ((cmd->opcode == 18) || (cmd->opcode == 25)
+		|| (cmd->opcode == 24) || (cmd->opcode == 17)))
+		cmdreg = cmdreg | (1 << 16);
+
+	if ((host->data != NULL) && (host->pio_set_dmatrig)
+			&& (host->data_dir == DAVINCI_MMC_DATADIR_READ))
+		cmdreg = cmdreg | (1 << 16);
+
+	/* Setting whether command involves data transfer or not */
+	if (cmdtype == DAVINCI_MMC_CMDTYPE_ADTC)
+		cmdreg = cmdreg | (1 << 13);
+
+	/* Setting whether stream or block transfer */
+	if (cmd->flags & MMC_DATA_STREAM)
+		cmdreg = cmdreg | (1 << 12);
+
+	/* Setting whether data read or write */
+	if (host->data_dir == DAVINCI_MMC_DATADIR_WRITE)
+		cmdreg = cmdreg | (1 << 11);
+
+	/* Setting response type */
+	cmdreg = cmdreg | (resptype << 9);
+
+	if (host->bus_mode == MMC_BUSMODE_PUSHPULL)
+		cmdreg = cmdreg | (1 << 7);
+
+	/* set Command timeout */
+	DAVINCI_MMC_WRITEW(host, TOR, 0xFFFF);
+
+	/* Enable interrupt */
+	if (host->data_dir == DAVINCI_MMC_DATADIR_WRITE) {
+		if (host->do_dma != 1)
+			DAVINCI_MMC_WRITEW(host, IM, (DAVINCI_MMC_EVENT_EOFCMD |
+				      DAVINCI_MMC_EVENT_WRITE |
+				      DAVINCI_MMC_EVENT_ERROR_CMDCRC |
+				      DAVINCI_MMC_EVENT_ERROR_DATACRC |
+				      DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT |
+				      DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT |
+				      DAVINCI_MMC_EVENT_BLOCK_XFERRED));
+		else
+			DAVINCI_MMC_WRITEW(host, IM, (DAVINCI_MMC_EVENT_EOFCMD |
+				      DAVINCI_MMC_EVENT_ERROR_CMDCRC |
+				      DAVINCI_MMC_EVENT_ERROR_DATACRC |
+				      DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT |
+				      DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT |
+				      DAVINCI_MMC_EVENT_BLOCK_XFERRED));
+	} else if (host->data_dir == DAVINCI_MMC_DATADIR_READ) {
+		if (host->do_dma != 1)
+			DAVINCI_MMC_WRITEW(host, IM, (DAVINCI_MMC_EVENT_EOFCMD |
+				      DAVINCI_MMC_EVENT_READ |
+				      DAVINCI_MMC_EVENT_ERROR_CMDCRC |
+				      DAVINCI_MMC_EVENT_ERROR_DATACRC |
+				      DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT |
+				      DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT |
+				      DAVINCI_MMC_EVENT_BLOCK_XFERRED));
+		else
+			DAVINCI_MMC_WRITEW(host, IM, (DAVINCI_MMC_EVENT_EOFCMD |
+				      DAVINCI_MMC_EVENT_ERROR_CMDCRC |
+				      DAVINCI_MMC_EVENT_ERROR_DATACRC |
+				      DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT |
+				      DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT |
+				      DAVINCI_MMC_EVENT_BLOCK_XFERRED));
+	} else
+		DAVINCI_MMC_WRITEW(host, IM, (DAVINCI_MMC_EVENT_EOFCMD |
+				      DAVINCI_MMC_EVENT_ERROR_CMDCRC |
+				      DAVINCI_MMC_EVENT_ERROR_DATACRC |
+				      DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT |
+				      DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT));
+
+	/*
+	 * It is required by controoler b4 WRITE command that
+	 * FIFO should be populated with 32 bytes
+	 */
+	if ((host->data_dir == DAVINCI_MMC_DATADIR_WRITE) &&
+	    (cmdtype == DAVINCI_MMC_CMDTYPE_ADTC) && (host->do_dma != 1))
+		davinci_fifo_data_trans(host);
+
+	if (cmd->opcode == 7) {
+		spin_lock_irqsave(&host->mmc_lock, flags);
+		host->is_card_removed = 0;
+		host->new_card_state = 1;
+		host->is_card_initialized = 1;
+		host->old_card_state = host->new_card_state;
+		host->is_init_progress = 0;
+		spin_unlock_irqrestore(&host->mmc_lock, flags);
+	}
+	if (cmd->opcode == 1 || cmd->opcode == 41) {
+		spin_lock_irqsave(&host->mmc_lock, flags);
+		host->is_card_initialized = 0;
+		host->is_init_progress = 1;
+		spin_unlock_irqrestore(&host->mmc_lock, flags);
+	}
+
+	host->is_core_command = 1;
+	DAVINCI_MMC_WRITEL(host, ARGHL, cmd->arg);
+	DAVINCI_MMC_WRITEL(host, CMD, cmdreg);
+}
+
+static void davinci_abort_dma(struct mmc_davinci_host *host)
+{
+	int sync_dev = 0;
+
+	if (host->data_dir == DAVINCI_MMC_DATADIR_READ)
+		sync_dev = host->dma_tx_event;
+	else
+		sync_dev = host->dma_rx_event;
+
+	davinci_stop_dma(sync_dev);
+	davinci_clean_channel(sync_dev);
+
+}
+
+
+static void mmc_davinci_dma_cb(int lch, u16 ch_status, void *data)
+{
+	if (DMA_COMPLETE != ch_status) {
+		struct mmc_davinci_host *host = (struct mmc_davinci_host *)data;
+		dev_warn(host->mmc->dev, "[DMA FAILED]");
+		davinci_abort_dma(host);
+	}
+}
+
+static void davinci_reinit_chan(struct mmc_davinci_host *host)
+{
+	davinci_stop_dma(host->dma_tx_event);
+	davinci_clean_channel(host->dma_tx_event);
+
+	davinci_stop_dma(host->dma_rx_event);
+	davinci_clean_channel(host->dma_rx_event);
+}
+
+static int mmc_davinci_send_dma_request(struct mmc_davinci_host *host,
+					struct mmc_request *req)
+{
+	int sync_dev;
+	unsigned char i, j;
+	unsigned short acnt, bcnt, ccnt;
+	unsigned int src_port, dst_port, temp_ccnt;
+	enum address_mode mode_src, mode_dst;
+	enum fifo_width fifo_width_src, fifo_width_dst;
+	unsigned short src_bidx, dst_bidx;
+	unsigned short src_cidx, dst_cidx;
+	unsigned short bcntrld;
+	enum sync_dimension sync_mode;
+	struct paramentry_descriptor temp;
+	int edma_chan_num;
+	struct mmc_data *data = host->data;
+	struct scatterlist *sg = &data->sg[0];
+	unsigned int count;
+	int num_frames, frame;
+
+#define MAX_C_CNT		64000
+
+	frame = data->blksz;
+	count = sg_dma_len(sg);
+
+	if ((data->blocks == 1) && (count > data->blksz))
+		count = frame;
+
+	if (count % host->rw_threshold == 0) {
+		acnt = 4;
+		bcnt = host->rw_threshold / 4;
+		num_frames = count / host->rw_threshold;
+	} else {
+		acnt = count;
+		bcnt = 1;
+		num_frames = 1;
+	}
+
+	if (num_frames > MAX_C_CNT) {
+		temp_ccnt = MAX_C_CNT;
+		ccnt = temp_ccnt;
+	} else {
+		ccnt = num_frames;
+		temp_ccnt = ccnt;
+	}
+
+	if (host->data_dir == DAVINCI_MMC_DATADIR_WRITE) {
+		/*AB Sync Transfer */
+		sync_dev = host->dma_tx_event;
+
+		src_port = (unsigned int)sg_dma_address(sg);
+		mode_src = INCR;
+		fifo_width_src = W8BIT;	/* It's not cared as modeDsr is INCR */
+		src_bidx = acnt;
+		src_cidx = acnt * bcnt;
+		dst_port = host->phys_base + DAVINCI_MMC_REG_DXR;
+		mode_dst = INCR;
+		fifo_width_dst = W8BIT;	/* It's not cared as modeDsr is INCR */
+		dst_bidx = 0;
+		dst_cidx = 0;
+		bcntrld = 8;
+		sync_mode = ABSYNC;
+	} else {
+		sync_dev = host->dma_rx_event;
+
+		src_port = host->phys_base + DAVINCI_MMC_REG_DRR;
+		mode_src = INCR;
+		fifo_width_src = W8BIT;
+		src_bidx = 0;
+		src_cidx = 0;
+		dst_port = (unsigned int)sg_dma_address(sg);
+		mode_dst = INCR;
+		fifo_width_dst = W8BIT;	/* It's not cared as modeDsr is INCR */
+		dst_bidx = acnt;
+		dst_cidx = acnt * bcnt;
+		bcntrld = 8;
+		sync_mode = ABSYNC;
+	}
+
+	if (host->pio_set_dmatrig)
+		davinci_dma_clear_event(sync_dev);
+	davinci_set_dma_src_params(sync_dev, src_port, mode_src,
+				   fifo_width_src);
+	davinci_set_dma_dest_params(sync_dev, dst_port, mode_dst,
+				    fifo_width_dst);
+	davinci_set_dma_src_index(sync_dev, src_bidx, src_cidx);
+	davinci_set_dma_dest_index(sync_dev, dst_bidx, dst_cidx);
+	davinci_set_dma_transfer_params(sync_dev, acnt, bcnt, ccnt, bcntrld,
+					sync_mode);
+
+	davinci_get_dma_params(sync_dev, &temp);
+	if (sync_dev == host->dma_tx_event) {
+		if (host->option_write == 0) {
+			host->option_write = temp.opt;
+		} else {
+			temp.opt = host->option_write;
+			davinci_set_dma_params(sync_dev, &temp);
+		}
+	}
+	if (sync_dev == host->dma_rx_event) {
+		if (host->option_read == 0) {
+			host->option_read = temp.opt;
+		} else {
+			temp.opt = host->option_read;
+			davinci_set_dma_params(sync_dev, &temp);
+		}
+	}
+
+	if (host->sg_len > 1) {
+		davinci_get_dma_params(sync_dev, &temp);
+		temp.opt &= ~TCINTEN;
+		davinci_set_dma_params(sync_dev, &temp);
+
+		for (i = 0; i < host->sg_len - 1; i++) {
+
+			sg = &data->sg[i + 1];
+
+			if (i != 0) {
+				j = i - 1;
+				davinci_get_dma_params(host->edma_ch_details.
+						       chanel_num[j], &temp);
+				temp.opt &= ~TCINTEN;
+				davinci_set_dma_params(host->edma_ch_details.
+						       chanel_num[j], &temp);
+			}
+
+			edma_chan_num = host->edma_ch_details.chanel_num[0];
+
+			frame = data->blksz;
+			count = sg_dma_len(sg);
+
+			if ((data->blocks == 1) && (count > data->blksz))
+				count = frame;
+
+			ccnt = count / host->rw_threshold;
+
+			if (sync_dev == host->dma_tx_event)
+				temp.src = (unsigned int)sg_dma_address(sg);
+			else
+				temp.dst = (unsigned int)sg_dma_address(sg);
+
+			temp.opt |= TCINTEN;
+
+			temp.ccnt = (temp.ccnt & 0xFFFF0000) | (ccnt);
+
+			davinci_set_dma_params(edma_chan_num, &temp);
+			if (i != 0) {
+				j = i - 1;
+				davinci_dma_link_lch(host->edma_ch_details.
+						     chanel_num[j],
+						     edma_chan_num);
+			}
+		}
+		davinci_dma_link_lch(sync_dev,
+				     host->edma_ch_details.chanel_num[0]);
+	}
+
+	davinci_start_dma(sync_dev);
+	return 0;
+}
+
+static int mmc_davinci_start_dma_transfer(struct mmc_davinci_host *host,
+					  struct mmc_request *req)
+{
+	int use_dma = 1, i;
+	struct mmc_data *data = host->data;
+	int block_size = (1 << data->blksz_bits);
+
+	host->sg_len = dma_map_sg(host->mmc->dev, data->sg, host->sg_len,
+				  ((data->
+				    flags & MMC_DATA_WRITE) ? DMA_TO_DEVICE :
+				   DMA_FROM_DEVICE));
+
+	/* Decide if we can use DMA */
+	for (i = 0; i < host->sg_len; i++) {
+		if ((data->sg[i].length % block_size) != 0) {
+			use_dma = 0;
+			break;
+		}
+	}
+
+	if (!use_dma) {
+		dma_unmap_sg(host->mmc->dev, data->sg, host->sg_len,
+			     (data->
+			      flags & MMC_DATA_WRITE) ? DMA_TO_DEVICE :
+			     DMA_FROM_DEVICE);
+		return -1;
+	}
+
+	host->do_dma = 1;
+
+	mmc_davinci_send_dma_request(host, req);
+
+	return 0;
+
+}
+
+static int davinci_release_dma_channels(struct mmc_davinci_host *host)
+{
+	davinci_free_dma(host->dma_tx_event);
+	davinci_free_dma(host->dma_rx_event);
+
+	if (host->edma_ch_details.cnt_chanel) {
+		davinci_free_dma(host->edma_ch_details.chanel_num[0]);
+		host->edma_ch_details.cnt_chanel = 0;
+	}
+
+	return 0;
+}
+
+static int davinci_acquire_dma_channels(struct mmc_davinci_host *host)
+{
+	int edma_chan_num, tcc = 0, r, sync_dev;
+	enum dma_event_q queue_no = EVENTQ_0;
+
+	/* Acquire master DMA write channel */
+	r = davinci_request_dma(host->dma_tx_event, "MMC_WRITE",
+				     mmc_davinci_dma_cb, host,
+				     &edma_chan_num, &tcc, queue_no);
+	if (r) {
+		dev_warn(host->mmc->dev,
+			 "MMC: davinci_request_dma() failed with %d\n", r);
+		return r;
+	}
+
+	/* Acquire master DMA read channel */
+	r = davinci_request_dma(host->dma_rx_event, "MMC_READ",
+				     mmc_davinci_dma_cb, host,
+				     &edma_chan_num, &tcc, queue_no);
+	if (r) {
+		dev_warn(host->mmc->dev,
+			 "MMC: davinci_request_dma() failed with %d\n", r);
+		goto free_master_write;
+	}
+
+	host->edma_ch_details.cnt_chanel = 0;
+
+	/* currently data Writes are done using single block mode,
+	 * so no DMA slave write channel is required for now */
+
+	/* Create a DMA slave read channel
+	 * (assuming max segments handled is 2) */
+	sync_dev = host->dma_rx_event;
+	r = davinci_request_dma(DAVINCI_EDMA_PARAM_ANY, "LINK",
+				     NULL, NULL, &edma_chan_num,
+				     &sync_dev, queue_no);
+	if (r) {
+		dev_warn(host->mmc->dev,
+			 "MMC: davinci_request_dma() failed with %d\n", r);
+		goto free_master_read;
+	}
+
+	host->edma_ch_details.cnt_chanel++;
+	host->edma_ch_details.chanel_num[0] = edma_chan_num;
+
+	return 0;
+
+free_master_read:
+	davinci_free_dma(host->dma_rx_event);
+free_master_write:
+	davinci_free_dma(host->dma_tx_event);
+
+	return r;
+}
+
+static void mmc_davinci_prepare_data(struct mmc_davinci_host *host,
+				     struct mmc_request *req)
+{
+	int timeout, sg_len;
+	u16 reg;
+	host->data = req->data;
+	if (req->data == NULL) {
+		host->data_dir = DAVINCI_MMC_DATADIR_NONE;
+		DAVINCI_MMC_WRITEW(host, BLEN, 0);
+		DAVINCI_MMC_WRITEW(host, NBLK, 0);
+		return;
+	}
+	/* Init idx */
+	host->sg_idx = 0;
+
+	dev_dbg(host->mmc->dev,
+		"MMCSD : Data xfer (%s %s), "
+		"DTO %d cycles + %d ns, %d blocks of %d bytes\n",
+		(req->data->flags & MMC_DATA_STREAM) ? "stream" : "block",
+		(req->data->flags & MMC_DATA_WRITE) ? "write" : "read",
+		req->data->timeout_clks, req->data->timeout_ns,
+		req->data->blocks, 1 << req->data->blksz_bits);
+
+	/* Convert ns to clock cycles by assuming 20MHz frequency
+	 * 1 cycle at 20MHz = 500 ns
+	 */
+	timeout = req->data->timeout_clks + req->data->timeout_ns / 500;
+	if (timeout > 0xffff)
+		timeout = 0xffff;
+
+	DAVINCI_MMC_WRITEW(host, TOD, timeout);
+	DAVINCI_MMC_WRITEW(host, NBLK, req->data->blocks);
+	DAVINCI_MMC_WRITEW(host, BLEN, (1 << req->data->blksz_bits));
+	host->data_dir = (req->data->flags & MMC_DATA_WRITE) ?
+	    DAVINCI_MMC_DATADIR_WRITE : DAVINCI_MMC_DATADIR_READ;
+
+	/* Configure the FIFO */
+	switch (host->data_dir) {
+	case DAVINCI_MMC_DATADIR_WRITE:
+		reg = DAVINCI_MMC_READW(host, FIFO_CTL);
+		reg |= 0x1;
+		DAVINCI_MMC_WRITEW(host, FIFO_CTL, reg);
+		DAVINCI_MMC_WRITEW(host, FIFO_CTL, 0x0);
+		reg = DAVINCI_MMC_READW(host, FIFO_CTL);
+		reg |= (1 << 1);
+		DAVINCI_MMC_WRITEW(host, FIFO_CTL, reg);
+		reg = DAVINCI_MMC_READW(host, FIFO_CTL);
+		reg |= (1 << 2);
+		DAVINCI_MMC_WRITEW(host, FIFO_CTL, reg);
+		break;
+	case DAVINCI_MMC_DATADIR_READ:
+		reg = DAVINCI_MMC_READW(host, FIFO_CTL);
+		reg |= 0x1;
+		DAVINCI_MMC_WRITEW(host, FIFO_CTL, reg);
+		DAVINCI_MMC_WRITEW(host, FIFO_CTL, 0x0);
+		reg = DAVINCI_MMC_READW(host, FIFO_CTL);
+		reg |= (1 << 2);
+		DAVINCI_MMC_WRITEW(host, FIFO_CTL, reg);
+		break;
+	default:
+		break;
+	}
+
+	sg_len = (req->data->blocks == 1) ? 1 : req->data->sg_len;
+	host->sg_len = sg_len;
+
+	host->bytes_left = req->data->blocks * (1 << req->data->blksz_bits);
+
+	if ((host->use_dma == 1) && (host->bytes_left % host->rw_threshold == 0)
+	    && (mmc_davinci_start_dma_transfer(host, req) == 0)) {
+		host->buffer = NULL;
+		host->bytes_left = 0;
+	} else {
+		/* Revert to CPU Copy */
+
+		host->do_dma = 0;
+		mmc_davinci_sg_to_buf(host);
+	}
+}
+
+static void mmc_davinci_request(struct mmc_host *mmc, struct mmc_request *req)
+{
+	struct mmc_davinci_host *host = mmc_priv(mmc);
+	unsigned long flags;
+
+	if (host->is_card_removed) {
+		if (req->cmd) {
+			req->cmd->error |= MMC_ERR_TIMEOUT;
+			mmc_request_done(mmc, req);
+		}
+		dev_dbg(host->mmc->dev,
+			"From code segment excuted when card removed\n");
+		return;
+	}
+
+	wait_on_data(host);
+
+	if (!host->is_card_detect_progress) {
+		spin_lock_irqsave(&host->mmc_lock, flags);
+		host->is_card_busy = 1;
+		spin_unlock_irqrestore(&host->mmc_lock, flags);
+		host->do_dma = 0;
+		mmc_davinci_prepare_data(host, req);
+		mmc_davinci_start_command(host, req->cmd);
+	} else {
+		/* Queue up the request as card dectection is being excuted */
+		host->que_mmc_host = mmc;
+		host->que_mmc_request = req;
+		spin_lock_irqsave(&host->mmc_lock, flags);
+		host->is_req_queued_up = 1;
+		spin_unlock_irqrestore(&host->mmc_lock, flags);
+	}
+}
+
+static unsigned int calculate_freq_for_card(struct mmc_davinci_host *host,
+			unsigned int mmc_req_freq)
+{
+	unsigned int mmc_freq, cpu_arm_clk, mmc_push_pull;
+
+	cpu_arm_clk = clk_get_rate(host->clk);
+
+	if (cpu_arm_clk > (2 * mmc_req_freq)) {
+		mmc_push_pull =
+		    ((unsigned int)cpu_arm_clk / (2 * mmc_req_freq)) - 1;
+	} else
+		mmc_push_pull = 0;
+
+	mmc_freq = (unsigned int)cpu_arm_clk / (2 * (mmc_push_pull + 1));
+
+	if (mmc_freq > mmc_req_freq)
+		mmc_push_pull = mmc_push_pull + 1;
+
+	return mmc_push_pull;
+}
+
+static void mmc_davinci_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	unsigned short status;
+	unsigned int open_drain_freq, cpu_arm_clk;
+	unsigned int mmc_push_pull_freq;
+	u16 reg;
+	struct mmc_davinci_host *host = mmc_priv(mmc);
+
+	cpu_arm_clk = clk_get_rate(host->clk);
+	dev_dbg(host->mmc->dev, "clock %dHz busmode %d powermode %d \
+			Vdd %d.%02d\n",
+		ios->clock, ios->bus_mode, ios->power_mode,
+		ios->vdd / 100, ios->vdd % 100);
+
+	reg = DAVINCI_MMC_READW(host, CTL);
+	switch (ios->bus_width) {
+	case MMC_BUS_WIDTH_8:
+		dev_dbg(host->mmc->dev, "\nEnabling 8 bit mode\n");
+		reg |=	(1 << 8);
+		reg &= ~(1 << 2);
+		break;
+	case MMC_BUS_WIDTH_4:
+		dev_dbg(host->mmc->dev, "\nEnabling 4 bit mode\n");
+		reg &= ~(1 << 8);
+		reg |=	(1 << 2);
+		break;
+	default:
+		dev_dbg(host->mmc->dev, "\nEnabling 1 bit mode\n");
+		reg &= ~((1 << 8) | (1 << 2));
+	}
+	DAVINCI_MMC_WRITEW(host, CTL, reg);
+
+	if (ios->bus_mode == MMC_BUSMODE_OPENDRAIN) {
+		open_drain_freq =
+		    ((unsigned int)(cpu_arm_clk + 2*DAVINCI_MMC_INIT_CLOCK - 1)
+			/ (2 * DAVINCI_MMC_INIT_CLOCK)) - 1;
+		if (open_drain_freq > 0xff)
+			open_drain_freq = 0xff;
+		DAVINCI_MMC_WRITEW(host, CLK, open_drain_freq | 0x100);
+
+	} else {
+		mmc_push_pull_freq = calculate_freq_for_card(host, ios->clock);
+		reg = DAVINCI_MMC_READW(host, CLK);
+		reg &= ~(0x100);
+		DAVINCI_MMC_WRITEW(host, CLK, reg);
+		udelay(10);
+		DAVINCI_MMC_WRITEW(host, CLK, mmc_push_pull_freq | 0x100);
+		udelay(10);
+	}
+	host->bus_mode = ios->bus_mode;
+	if (ios->power_mode == MMC_POWER_UP) {
+		/* Send clock cycles, poll completion */
+		reg = DAVINCI_MMC_READW(host, IM);
+		DAVINCI_MMC_WRITEW(host, IM, 0);
+		DAVINCI_MMC_WRITEL(host, ARGHL, 0x0);
+		DAVINCI_MMC_WRITEL(host, CMD, 0x4000);
+		status = 0;
+		while (!(status & (DAVINCI_MMC_EVENT_EOFCMD)))
+			status = DAVINCI_MMC_READW(host, ST0);
+
+		DAVINCI_MMC_WRITEW(host, IM, reg);
+	}
+}
+
+static void mmc_davinci_xfer_done(struct mmc_davinci_host *host,
+				  struct mmc_data *data)
+{
+	unsigned long flags;
+	host->data = NULL;
+	host->data_dir = DAVINCI_MMC_DATADIR_NONE;
+	if (data->error == MMC_ERR_NONE)
+		data->bytes_xfered += data->blocks * (1 << data->blksz_bits);
+
+	if (host->do_dma) {
+		davinci_abort_dma(host);
+
+		dma_unmap_sg(host->mmc->dev, data->sg, host->sg_len,
+			     (data->
+			      flags & MMC_DATA_WRITE) ? DMA_TO_DEVICE :
+			     DMA_FROM_DEVICE);
+	}
+
+	if (data->error == MMC_ERR_TIMEOUT) {
+		spin_lock_irqsave(&host->mmc_lock, flags);
+		host->is_card_busy = 0;
+		spin_unlock_irqrestore(&host->mmc_lock, flags);
+		mmc_request_done(host->mmc, data->mrq);
+		return;
+	}
+
+	if (!data->stop) {
+		spin_lock_irqsave(&host->mmc_lock, flags);
+		host->is_card_busy = 0;
+		spin_unlock_irqrestore(&host->mmc_lock, flags);
+		mmc_request_done(host->mmc, data->mrq);
+		return;
+	}
+	mmc_davinci_start_command(host, data->stop);
+}
+
+static void mmc_davinci_cmd_done(struct mmc_davinci_host *host,
+				 struct mmc_command *cmd)
+{
+	unsigned long flags;
+	host->cmd = NULL;
+
+	if (!cmd) {
+		dev_warn(host->mmc->dev, "%s(): No cmd ptr\n", __func__);
+		return;
+	}
+
+	if (cmd->flags & MMC_RSP_PRESENT) {
+		if (cmd->flags & MMC_RSP_136) {
+			/* response type 2 */
+			cmd->resp[3] = DAVINCI_MMC_READL(host, RSP01);
+			cmd->resp[2] = DAVINCI_MMC_READL(host, RSP23);
+			cmd->resp[1] = DAVINCI_MMC_READL(host, RSP45);
+			cmd->resp[0] = DAVINCI_MMC_READL(host, RSP67);
+		} else {
+		/* response types 1, 1b, 3, 4, 5, 6 */
+		cmd->resp[0] = DAVINCI_MMC_READL(host, RSP67);
+		}
+	}
+
+	if (host->data == NULL || cmd->error != MMC_ERR_NONE) {
+		if (cmd->error == MMC_ERR_TIMEOUT)
+			cmd->mrq->cmd->retries = 0;
+		spin_lock_irqsave(&host->mmc_lock, flags);
+		host->is_card_busy = 0;
+		spin_unlock_irqrestore(&host->mmc_lock, flags);
+		mmc_request_done(host->mmc, cmd->mrq);
+	}
+
+}
+
+static irqreturn_t mmc_davinci_irq(int irq, void *dev_id, struct pt_regs *regs)
+{
+	struct mmc_davinci_host *host = (struct mmc_davinci_host *)dev_id;
+	u16 status;
+	int end_command;
+	int end_transfer;
+	unsigned long flags;
+	u16 reg;
+
+	if (host->is_core_command) {
+		if (host->cmd == NULL && host->data == NULL) {
+			status = DAVINCI_MMC_READW(host, ST0);
+			dev_dbg(host->mmc->dev, "Spurious interrupt 0x%04x\n",
+				status);
+			/* Disable the interrupt from mmcsd */
+			DAVINCI_MMC_WRITEW(host, IM, 0);
+			return IRQ_HANDLED;
+		}
+	}
+	end_command = 0;
+	end_transfer = 0;
+
+	status = DAVINCI_MMC_READW(host, ST0);
+	if (status == 0)
+		return IRQ_HANDLED;
+
+	if (host->is_core_command) {
+		if (host->is_card_initialized) {
+			if (host->new_card_state == 0) {
+				if (host->cmd) {
+					host->cmd->error |= MMC_ERR_TIMEOUT;
+					mmc_davinci_cmd_done(host, host->cmd);
+				}
+				dev_dbg(host->mmc->dev,
+					"From code segment excuted when card \
+					removed\n");
+				return IRQ_HANDLED;
+			}
+		}
+
+		while (status != 0) {
+			if (host->data_dir == DAVINCI_MMC_DATADIR_WRITE) {
+				if (status & DAVINCI_MMC_EVENT_WRITE) {
+					/* Buffer almost empty */
+					if (host->bytes_left > 0)
+						davinci_fifo_data_trans(host);
+				}
+			}
+
+			if (host->data_dir == DAVINCI_MMC_DATADIR_READ)
+				if (status & DAVINCI_MMC_EVENT_READ)
+					/* Buffer almost empty */
+					if (host->bytes_left > 0)
+						davinci_fifo_data_trans(host);
+
+			if (status & DAVINCI_MMC_EVENT_BLOCK_XFERRED) {
+				/* Block sent/received */
+				if (host->data != NULL) {
+					if (host->do_dma == 1)
+						end_transfer = 1;
+					else {
+						/* if datasize <
+						 * host_rw_threshold no RX ints
+						 * are generated */
+						if (host->bytes_left > 0)
+							davinci_fifo_data_trans
+							    (host);
+						end_transfer = 1;
+					}
+				} else
+					dev_warn(host->mmc->dev,
+						 "TC:host->data is NULL\n");
+			}
+
+			if (status & DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT) {
+				/* Data timeout */
+				if ((host->data) &&
+						(host->new_card_state != 0)) {
+					host->data->error |= MMC_ERR_TIMEOUT;
+					spin_lock_irqsave(&host->mmc_lock,
+							flags);
+					host->is_card_removed = 1;
+					host->new_card_state = 0;
+					host->is_card_initialized = 0;
+					spin_unlock_irqrestore(&host->mmc_lock,
+							       flags);
+					dev_dbg(host->mmc->dev,
+						"MMCSD: Data timeout, CMD%d \
+						and status is %x\n",
+						host->cmd->opcode, status);
+
+					if (host->cmd)
+						host->cmd->error |=
+						    MMC_ERR_TIMEOUT;
+					end_transfer = 1;
+				}
+			}
+
+			if (status & DAVINCI_MMC_EVENT_ERROR_DATACRC) {
+				/* DAT line portion is diabled and in reset
+				 * state */
+				reg = DAVINCI_MMC_READW(host, CTL);
+				reg |= (1 << 1);
+				DAVINCI_MMC_WRITEW(host, CTL, reg);
+				udelay(10);
+				reg = DAVINCI_MMC_READW(host, CTL);
+				reg &= ~(1 << 1);
+				DAVINCI_MMC_WRITEW(host, CTL, reg);
+
+				/* Data CRC error */
+				if (host->data) {
+					host->data->error |= MMC_ERR_BADCRC;
+					dev_dbg(host->mmc->dev,
+						"MMCSD: Data CRC error, bytes \
+						left %d\n",
+						host->bytes_left);
+					end_transfer = 1;
+				} else
+					dev_dbg(host->mmc->dev,
+						"MMCSD: Data CRC error\n");
+			}
+
+			if (status & DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT) {
+				if (host->do_dma)
+					davinci_abort_dma(host);
+
+				/* Command timeout */
+				if (host->cmd) {
+					/* Timeouts are normal in case of
+					 * MMC_SEND_STATUS
+					 */
+					if (host->cmd->opcode !=
+					    MMC_ALL_SEND_CID) {
+						dev_dbg(host->mmc->dev,
+							"MMCSD: Command \
+							timeout, CMD%d and \
+							status is %x\n",
+							host->cmd->opcode,
+							status);
+						spin_lock_irqsave(
+								&host->mmc_lock,
+								  flags);
+						host->new_card_state = 0;
+						host->is_card_initialized = 0;
+						spin_unlock_irqrestore
+						    (&host->mmc_lock, flags);
+					}
+					host->cmd->error |= MMC_ERR_TIMEOUT;
+					end_command = 1;
+
+				}
+			}
+
+			if (status & DAVINCI_MMC_EVENT_ERROR_CMDCRC) {
+				/* Command CRC error */
+				dev_dbg(host->mmc->dev, "Command CRC error\n");
+				if (host->cmd) {
+					/* Ignore CMD CRC errors during high
+					 * speed operation */
+					if (host->mmc->ios.clock <= 25000000) {
+						host->cmd->error |=
+						    MMC_ERR_BADCRC;
+					}
+					end_command = 1;
+				}
+			}
+
+			if (status & DAVINCI_MMC_EVENT_EOFCMD)
+				end_command = 1;
+
+			if (host->data == NULL) {
+				status = DAVINCI_MMC_READW(host, ST0);
+				if (status != 0) {
+					dev_dbg(host->mmc->dev,
+						"Status is %x at end of ISR \
+						when host->data is NULL",
+						status);
+					status = 0;
+
+				}
+			} else
+				status = DAVINCI_MMC_READW(host, ST0);
+		}
+
+		if (end_command)
+			mmc_davinci_cmd_done(host, host->cmd);
+
+		if (end_transfer)
+			mmc_davinci_xfer_done(host, host->data);
+	} else {
+		if (host->cmd_code == 13) {
+			if (status & DAVINCI_MMC_EVENT_EOFCMD) {
+				spin_lock_irqsave(&host->mmc_lock, flags);
+				host->new_card_state = 1;
+				spin_unlock_irqrestore(&host->mmc_lock, flags);
+
+			} else {
+				spin_lock_irqsave(&host->mmc_lock, flags);
+				host->is_card_removed = 1;
+				host->new_card_state = 0;
+				host->is_card_initialized = 0;
+				spin_unlock_irqrestore(&host->mmc_lock, flags);
+			}
+
+			spin_lock_irqsave(&host->mmc_lock, flags);
+			host->is_card_detect_progress = 0;
+			spin_unlock_irqrestore(&host->mmc_lock, flags);
+
+			if (host->is_req_queued_up) {
+				mmc_davinci_request(host->que_mmc_host,
+						    host->que_mmc_request);
+				spin_lock_irqsave(&host->mmc_lock, flags);
+				host->is_req_queued_up = 0;
+				spin_unlock_irqrestore(&host->mmc_lock, flags);
+			}
+
+		}
+
+		if (host->cmd_code == 1 || host->cmd_code == 55) {
+			if (status & DAVINCI_MMC_EVENT_EOFCMD) {
+				spin_lock_irqsave(&host->mmc_lock, flags);
+				host->is_card_removed = 0;
+				host->new_card_state = 1;
+				host->is_card_initialized = 0;
+				spin_unlock_irqrestore(&host->mmc_lock, flags);
+			} else {
+
+				spin_lock_irqsave(&host->mmc_lock, flags);
+				host->is_card_removed = 1;
+				host->new_card_state = 0;
+				host->is_card_initialized = 0;
+				spin_unlock_irqrestore(&host->mmc_lock, flags);
+			}
+
+			spin_lock_irqsave(&host->mmc_lock, flags);
+			host->is_card_detect_progress = 0;
+			spin_unlock_irqrestore(&host->mmc_lock, flags);
+
+			if (host->is_req_queued_up) {
+				mmc_davinci_request(host->que_mmc_host,
+						    host->que_mmc_request);
+				spin_lock_irqsave(&host->mmc_lock, flags);
+				host->is_req_queued_up = 0;
+				spin_unlock_irqrestore(&host->mmc_lock, flags);
+			}
+		}
+
+		if (host->cmd_code == 0) {
+			if (status & DAVINCI_MMC_EVENT_EOFCMD) {
+				host->is_core_command = 0;
+
+				if (host->flag_sd_mmc) {
+					host->flag_sd_mmc = 0;
+					host->cmd_code = 1;
+					/* Issue cmd1 */
+					DAVINCI_MMC_WRITEL(host, ARGHL,
+							0x80300000);
+					DAVINCI_MMC_WRITEL(host, CMD,
+							0x00000601);
+				} else {
+					host->flag_sd_mmc = 1;
+					host->cmd_code = 55;
+					/* Issue cmd55 */
+					DAVINCI_MMC_WRITEL(host, ARGHL, 0x0);
+					DAVINCI_MMC_WRITEL(host, CMD,
+					    ((0x0 | (1 << 9) | 55)));
+				}
+
+				dev_dbg(host->mmc->dev,
+					"MMC-Probing mmc with cmd%d\n",
+					host->cmd_code);
+			} else {
+				spin_lock_irqsave(&host->mmc_lock, flags);
+				host->new_card_state = 0;
+				host->is_card_initialized = 0;
+				host->is_card_detect_progress = 0;
+				spin_unlock_irqrestore(&host->mmc_lock, flags);
+			}
+		}
+
+	}
+	return IRQ_HANDLED;
+}
+
+static int mmc_davinci_get_ro(struct mmc_host *mmc)
+{
+	struct mmc_davinci_host *host = mmc_priv(mmc);
+
+	return host->get_ro ? host->get_ro(mmc->index) : 0;
+}
+
+static struct mmc_host_ops mmc_davinci_ops = {
+	.request = mmc_davinci_request,
+	.set_ios = mmc_davinci_set_ios,
+	.get_ro = mmc_davinci_get_ro
+};
+
+void mmc_check_card(unsigned long data)
+{
+	struct mmc_davinci_host *host = (struct mmc_davinci_host *)data;
+	unsigned long flags;
+	struct mmc_card *card = NULL;
+
+	if (host->mmc && host->mmc->card_selected)
+		card = host->mmc->card_selected;
+
+	if ((!host->is_card_detect_progress) || (!host->is_init_progress)) {
+		if (host->is_card_initialized) {
+			host->is_core_command = 0;
+			host->cmd_code = 13;
+			spin_lock_irqsave(&host->mmc_lock, flags);
+			host->is_card_detect_progress = 1;
+			spin_unlock_irqrestore(&host->mmc_lock, flags);
+			/* Issue cmd13 */
+			DAVINCI_MMC_WRITEL(host, ARGHL, (card && (card->state
+							 & MMC_STATE_SDCARD))
+					? (card->rca << 16) : 0x10000);
+			DAVINCI_MMC_WRITEL(host, CMD, 0x0000028D);
+		} else {
+			host->is_core_command = 0;
+			host->cmd_code = 0;
+			spin_lock_irqsave(&host->mmc_lock, flags);
+			host->is_card_detect_progress = 1;
+			spin_unlock_irqrestore(&host->mmc_lock, flags);
+			/* Issue cmd0 */
+			DAVINCI_MMC_WRITEL(host, ARGHL, 0);
+			DAVINCI_MMC_WRITEL(host, CMD, 0x4000);
+		}
+		DAVINCI_MMC_WRITEW(host, IM, (DAVINCI_MMC_EVENT_EOFCMD |
+				      DAVINCI_MMC_EVENT_ERROR_CMDCRC |
+				      DAVINCI_MMC_EVENT_ERROR_DATACRC |
+				      DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT |
+				      DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT));
+
+	}
+}
+
+static void init_mmcsd_host(struct mmc_davinci_host *host)
+{
+	u16 reg;
+	/* CMD line portion is disabled and in reset state */
+	reg = DAVINCI_MMC_READW(host, CTL);
+	reg |= 0x1;
+	DAVINCI_MMC_WRITEW(host, CTL, reg);
+	/* DAT line portion is disabled and in reset state */
+	reg = DAVINCI_MMC_READW(host, CTL);
+	reg |= (1 << 1);
+	DAVINCI_MMC_WRITEW(host, CTL, reg);
+	udelay(10);
+
+	DAVINCI_MMC_WRITEW(host, CLK, 0x0);
+	reg = DAVINCI_MMC_READW(host, CLK);
+	reg |= (1 << 8);
+	DAVINCI_MMC_WRITEW(host, CLK, reg);
+
+	DAVINCI_MMC_WRITEW(host, TOR, 0xFFFF);
+	DAVINCI_MMC_WRITEW(host, TOD, 0xFFFF);
+
+	reg = DAVINCI_MMC_READW(host, CTL);
+	reg &= ~(0x1);
+	DAVINCI_MMC_WRITEW(host, CTL, reg);
+	reg = DAVINCI_MMC_READW(host, CTL);
+	reg &= ~(1 << 1);
+	DAVINCI_MMC_WRITEW(host, CTL, reg);
+	udelay(10);
+}
+
+static void davinci_mmc_check_status(unsigned long data)
+{
+	unsigned long flags;
+	struct mmc_davinci_host *host = (struct mmc_davinci_host *)data;
+	if (!host->is_card_busy) {
+		if (host->old_card_state ^ host->new_card_state) {
+			davinci_reinit_chan(host);
+			init_mmcsd_host(host);
+			mmc_detect_change(host->mmc, 0);
+			spin_lock_irqsave(&host->mmc_lock, flags);
+			host->old_card_state = host->new_card_state;
+			spin_unlock_irqrestore(&host->mmc_lock, flags);
+		} else {
+			mmc_check_card(data);
+		}
+
+	}
+	mod_timer(&host->timer, jiffies + MULTIPLIER_TO_HZ * HZ);
+}
+
+static int davinci_mmc_probe(struct platform_device *pdev)
+{
+	struct davinci_mmc_platform_data *minfo = pdev->dev.platform_data;
+	struct mmc_host *mmc;
+	struct mmc_davinci_host *host = NULL;
+	struct resource *res;
+	int ret = 0;
+	int irq;
+
+	if (minfo == NULL) {
+		dev_err(&pdev->dev, "platform data missing\n");
+		return -ENODEV;
+	}
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	irq = platform_get_irq(pdev, 0);
+	if (res == NULL || irq < 0)
+		return -ENODEV;
+
+	res = request_mem_region(res->start, res->end - res->start + 1,
+				 pdev->name);
+	if (res == NULL)
+		return -EBUSY;
+
+	mmc = mmc_alloc_host(sizeof(struct mmc_davinci_host), &pdev->dev);
+	if (mmc == NULL) {
+		ret = -ENOMEM;
+		goto err_free_mem_region;
+	}
+
+	host = mmc_priv(mmc);
+	host->mmc = mmc;
+
+	spin_lock_init(&host->mmc_lock);
+
+	host->mem_res = res;
+	host->irq = irq;
+
+	host->phys_base = host->mem_res->start;
+	host->virt_base = (void __iomem *) IO_ADDRESS(host->phys_base);
+
+	host->use_dma = 0;
+
+	res = platform_get_resource(pdev, IORESOURCE_DMA, 0);
+	if (res > 0) {
+		host->dma_rx_event = res->start;
+		res = platform_get_resource(pdev, IORESOURCE_DMA, 1);
+		if (res > 0) {
+			host->dma_tx_event = res->start;
+			host->use_dma = 1;
+		} else
+			host->dma_rx_event = 0;
+	}
+
+	host->clk = clk_get(&pdev->dev, minfo->mmc_clk);
+	if (IS_ERR(host->clk)) {
+		ret = -ENODEV;
+		goto err_free_mmc_host;
+	}
+
+	ret = clk_enable(host->clk);
+	if (ret)
+		goto err_put_clk;
+
+	init_mmcsd_host(host);
+
+	if (minfo->use_8bit_mode) {
+		dev_info(mmc->dev, "Supporting 8-bit mode\n");
+		mmc->caps |= MMC_CAP_8_BIT_DATA;
+	}
+
+	if (minfo->use_4bit_mode) {
+		dev_info(mmc->dev, "Supporting 4-bit mode\n");
+		mmc->caps |= MMC_CAP_4_BIT_DATA;
+	}
+
+	if (!minfo->use_8bit_mode && !minfo->use_4bit_mode)
+		dev_info(mmc->dev, "Supporting 1-bit mode\n");
+
+	host->get_ro = minfo->get_ro;
+
+	host->pio_set_dmatrig = minfo->pio_set_dmatrig;
+
+	host->rw_threshold = minfo->rw_threshold;
+
+	mmc->ops = &mmc_davinci_ops;
+	mmc->f_min = 312500;
+	if (minfo->max_frq)
+		mmc->f_max = minfo->max_frq;
+	else
+		mmc->f_max = 25000000;
+	mmc->ocr_avail = MMC_VDD_32_33;
+
+	mmc->max_phys_segs = 2;
+	mmc->max_hw_segs = 2;
+	mmc->max_sectors = 256;
+
+	/* Restrict the max size of seg we can handle */
+	mmc->max_seg_size = mmc->max_sectors * 512;
+
+	dev_dbg(mmc->dev, "max_phys_segs=%d\n", mmc->max_phys_segs);
+	dev_dbg(mmc->dev, "max_hw_segs=%d\n", mmc->max_hw_segs);
+	dev_dbg(mmc->dev, "max_sect=%d\n", mmc->max_sectors);
+	dev_dbg(mmc->dev, "max_seg_size=%d\n", mmc->max_seg_size);
+
+	if (host->use_dma) {
+		dev_info(mmc->dev, "Using DMA mode\n");
+		ret = davinci_acquire_dma_channels(host);
+		if (ret)
+			goto err_release_clk;
+	} else {
+		dev_info(mmc->dev, "Not Using DMA mode\n");
+	}
+
+	host->sd_support = 1;
+	ret = request_irq(host->irq, mmc_davinci_irq, 0, DRIVER_NAME, host);
+	if (ret)
+		goto err_release_dma;
+
+	host->dev = &pdev->dev;
+	platform_set_drvdata(pdev, host);
+	mmc_add_host(mmc);
+
+	init_timer(&host->timer);
+	host->timer.data = (unsigned long)host;
+	host->timer.function = davinci_mmc_check_status;
+	host->timer.expires = jiffies + MULTIPLIER_TO_HZ * HZ;
+	add_timer(&host->timer);
+
+	return 0;
+
+err_release_dma:
+	davinci_release_dma_channels(host);
+err_release_clk:
+	clk_disable(host->clk);
+err_put_clk:
+	clk_put(host->clk);
+err_free_mmc_host:
+	mmc_free_host(mmc);
+err_free_mem_region:
+	release_mem_region(res->start, res->end - res->start + 1);
+
+	return ret;
+}
+
+static int davinci_mmcsd_remove(struct platform_device *dev)
+{
+	struct mmc_davinci_host *host = platform_get_drvdata(dev);
+	unsigned long flags;
+
+	if (host) {
+		spin_lock_irqsave(&host->mmc_lock, flags);
+		del_timer(&host->timer);
+		spin_unlock_irqrestore(&host->mmc_lock, flags);
+
+		mmc_remove_host(host->mmc);
+		platform_set_drvdata(dev, NULL);
+		free_irq(host->irq, host);
+		davinci_release_dma_channels(host);
+		clk_disable(host->clk);
+		clk_put(host->clk);
+		release_resource(host->mem_res);
+		kfree(host->mem_res);
+		mmc_free_host(host->mmc);
+	}
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int davinci_mmcsd_suspend(struct platform_device *pdev,
+		pm_message_t state)
+{
+	struct mmc_davinci_host *host = platform_get_drvdata(pdev);
+	int ret = 0;
+
+	if (host && host->mmc)
+		ret = mmc_suspend_host(host->mmc, state);
+
+	return ret;
+}
+
+static int davinci_mmcsd_resume(struct platform_device *pdev)
+{
+	struct mmc_davinci_host *host = platform_get_drvdata(pdev);
+	int ret = 0;
+
+	if (host && host->mmc)
+		ret = mmc_resume_host(host->mmc);
+
+	return ret;
+}
+#else
+#define davinci_mmcsd_suspend	NULL
+#define davinci_mmcsd_resume	NULL
+#endif
+
+static struct platform_driver davinci_mmcsd_driver = {
+	.probe 		= davinci_mmc_probe,
+	.remove		= davinci_mmcsd_remove,
+	.suspend	= davinci_mmcsd_suspend,
+	.resume		= davinci_mmcsd_resume,
+	.driver		= {
+		.name	= DRIVER_NAME,
+	},
+};
+
+
+static int davinci_mmcsd_init(void)
+{
+	return platform_driver_register(&davinci_mmcsd_driver);
+}
+
+static void __exit davinci_mmcsd_exit(void)
+{
+	platform_driver_unregister(&davinci_mmcsd_driver);
+}
+
+module_init(davinci_mmcsd_init);
+module_exit(davinci_mmcsd_exit);
+
+MODULE_DESCRIPTION("DAVINCI Multimedia Card driver");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS(DRIVER_NAME);
+MODULE_AUTHOR("Texas Instruments");
Index: linux-2.6.18/drivers/mmc/davinci.c
===================================================================
--- linux-2.6.18.orig/drivers/mmc/davinci.c
+++ /dev/null
@@ -1,1595 +0,0 @@
-/*
- * linux/drivers/mmc/davinci.c
- *
- * TI DaVinci MMC controller file
- *
- * Copyright (C) 2006 Texas Instruments.
- *
- * ----------------------------------------------------------------------------
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- *  You should have received a copy of the GNU General Public License
- *  along with this program; if not, write to the Free Software
- *  Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
- * ----------------------------------------------------------------------------
- * Modifications:
- * ver. 1.0: Oct 2005, Purushotam Kumar   Initial version
- * ver 1.1:  Nov  2005, Purushotam Kumar  Solved bugs
- * ver 1.2:  Jan  2006, Purushotam Kumar   Added card remove insert support
- */
-
-#include <linux/module.h>
-#include <linux/moduleparam.h>
-#include <linux/init.h>
-#include <linux/ioport.h>
-#include <linux/platform_device.h>
-#include <linux/interrupt.h>
-#include <linux/dma-mapping.h>
-#include <linux/delay.h>
-#include <linux/spinlock.h>
-#include <linux/timer.h>
-#include <linux/mmc/host.h>
-#include <linux/mmc/protocol.h>
-#include <linux/mmc/card.h>
-#include <linux/clk.h>
-#include <linux/io.h>
-#include <linux/irq.h>
-#include <linux/scatterlist.h>
-
-#include <asm/arch/mmc.h>
-#include <asm/arch/edma.h>
-
-#define	DAVINCI_MMC_REG_CTL	0x00
-#define	DAVINCI_MMC_REG_CLK	0x04
-#define	DAVINCI_MMC_REG_ST0	0x08
-#define	DAVINCI_MMC_REG_ST1	0x0c
-#define	DAVINCI_MMC_REG_IM	0x10
-#define	DAVINCI_MMC_REG_TOR	0x14
-#define	DAVINCI_MMC_REG_TOD	0x18
-#define	DAVINCI_MMC_REG_BLEN	0x1c
-#define	DAVINCI_MMC_REG_NBLK	0x20
-#define	DAVINCI_MMC_REG_NBLC	0x24
-#define	DAVINCI_MMC_REG_DRR	0x28
-#define	DAVINCI_MMC_REG_DXR	0x2c
-#define	DAVINCI_MMC_REG_CMD	0x30
-#define	DAVINCI_MMC_REG_ARGHL	0x34
-#define	DAVINCI_MMC_REG_RSP01	0x38
-#define	DAVINCI_MMC_REG_RSP23	0x3c
-#define	DAVINCI_MMC_REG_RSP45	0x40
-#define	DAVINCI_MMC_REG_RSP67	0x44
-#define	DAVINCI_MMC_REG_DRSP	0x48
-#define	DAVINCI_MMC_REG_ETOK	0x4c
-#define	DAVINCI_MMC_REG_CIDX	0x50
-#define	DAVINCI_MMC_REG_CKC	0x54
-#define	DAVINCI_MMC_REG_TORC	0x58
-#define	DAVINCI_MMC_REG_TODC	0x5c
-#define	DAVINCI_MMC_REG_BLNC	0x60
-#define	DAVINCI_SDIO_REG_CTL	0x64
-#define	DAVINCI_SDIO_REG_ST0	0x68
-#define	DAVINCI_SDIO_REG_EN	0x6c
-#define	DAVINCI_SDIO_REG_ST	0x70
-#define	DAVINCI_MMC_REG_FIFO_CTL	0x74
-
-#define DAVINCI_MMC_READW(host, reg) \
-	__raw_readw((host)->virt_base + DAVINCI_MMC_REG_##reg)
-#define DAVINCI_MMC_WRITEW(host, reg, val) \
-	__raw_writew((val), (host)->virt_base + DAVINCI_MMC_REG_##reg)
-#define DAVINCI_MMC_READL(host, reg) \
-	__raw_readl((host)->virt_base + DAVINCI_MMC_REG_##reg)
-#define DAVINCI_MMC_WRITEL(host, reg, val) \
-	__raw_writel((val), (host)->virt_base + DAVINCI_MMC_REG_##reg)
-/*
- * Command types
- */
-#define DAVINCI_MMC_CMDTYPE_BC		0
-#define DAVINCI_MMC_CMDTYPE_BCR		1
-#define DAVINCI_MMC_CMDTYPE_AC		2
-#define DAVINCI_MMC_CMDTYPE_ADTC	3
-#define EDMA_MAX_LOGICAL_CHA_ALLOWED	1
-
-#define DAVINCI_MMC_EVENT_BLOCK_XFERRED		(1 <<  0)
-#define DAVINCI_MMC_EVENT_CARD_EXITBUSY		(1 <<  1)
-#define	DAVINCI_MMC_EVENT_EOFCMD		(1 <<  2)
-#define DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT	(1 <<  3)
-#define DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT	(1 <<  4)
-#define DAVINCI_MMC_EVENT_ERROR_DATACRC		((1 << 6) | (1 << 5))
-#define DAVINCI_MMC_EVENT_ERROR_CMDCRC		(1 <<  7)
-#define DAVINCI_MMC_EVENT_WRITE			(1 <<  9)
-#define DAVINCI_MMC_EVENT_READ			(1 << 10)
-
-#define DAVINCI_MMC_EVENT_TIMEOUT_ERROR \
- (DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT | DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT)
-#define DAVINCI_MMC_EVENT_CRC_ERROR \
- (DAVINCI_MMC_EVENT_ERROR_DATACRC | DAVINCI_MMC_EVENT_ERROR_CMDCRC)
-#define DAVINCI_MMC_EVENT_ERROR \
- (DAVINCI_MMC_EVENT_TIMEOUT_ERROR | DAVINCI_MMC_EVENT_CRC_ERROR)
-#define DRIVER_NAME "davinci-mmc"
-#define RSP_TYPE(x)	((x) & ~(MMC_RSP_BUSY|MMC_RSP_OPCODE))
-
-struct edma_ch_mmcsd {
-	unsigned char cnt_chanel;
-	unsigned int chanel_num[EDMA_MAX_LOGICAL_CHA_ALLOWED];
-};
-
-struct mmc_davinci_host {
-	struct resource 	*reg_res;
-	spinlock_t		mmc_lock;
-	int			is_card_busy;
-	int			is_card_detect_progress;
-	int			is_card_initialized;
-	int			is_card_removed;
-	int			is_init_progress;
-	int			is_req_queued_up;
-	struct mmc_host		*que_mmc_host;
-	struct mmc_request	*que_mmc_request;
-	struct mmc_command	*cmd;
-	struct mmc_data		*data;
-	struct mmc_host		*mmc;
-	struct device		*dev;
-	struct clk		*clk;
-	struct resource		*mem_res;
-	void __iomem		*virt_base;
-	unsigned int		phys_base;
-	unsigned int		rw_threshold;
-	unsigned int		option_read;
-	unsigned int		option_write;
-	int			flag_sd_mmc;
-	int			irq;
-	unsigned char		bus_mode;
-
-#define DAVINCI_MMC_DATADIR_NONE	0
-#define DAVINCI_MMC_DATADIR_READ	1
-#define DAVINCI_MMC_DATADIR_WRITE	2
-	unsigned char		data_dir;
-	u32			*buffer;
-	u32			bytes_left;
-
-	int			use_dma;
-	int			do_dma;
-	unsigned int		dma_rx_event;
-	unsigned int		dma_tx_event;
-
-	struct timer_list	timer;
-	unsigned int		is_core_command;
-	unsigned int		cmd_code;
-	unsigned int		old_card_state;
-	unsigned int		new_card_state;
-
-	unsigned char		sd_support;
-
-	struct edma_ch_mmcsd	edma_ch_details;
-
-	unsigned int		sg_len;
-	int			sg_idx;
-	unsigned int		buffer_bytes_left;
-	unsigned char		pio_set_dmatrig;
-	int 			(*get_ro) (int);
-};
-
-
-void davinci_clean_channel(int ch_no);
-
-/* MMCSD Init clock in Hz in opendain mode */
-#define DAVINCI_MMC_INIT_CLOCK 		200000
-
-/* This macro could not be defined to 0 (ZERO) or -ve value.
- * This value is multiplied to "HZ"
- * while requesting for timer interrupt every time for probing card.
- */
-#define MULTIPLIER_TO_HZ 1
-
-#define MMCST1_BUSY	(1 << 0)
-
-static inline void wait_on_data(struct mmc_davinci_host *host)
-{
-	int cnt = 900000;
-	u16 reg = DAVINCI_MMC_READW(host, ST1);
-
-	while ((reg & MMCST1_BUSY) && cnt) {
-		cnt--;
-		udelay(1);
-		reg = DAVINCI_MMC_READW(host, ST1);
-	}
-	if (!cnt)
-		dev_warn(host->mmc->dev, "ERROR: TOUT waiting for BUSY\n");
-}
-
-/* PIO only */
-static void mmc_davinci_sg_to_buf(struct mmc_davinci_host *host)
-{
-	struct scatterlist *sg;
-
-	sg = host->data->sg + host->sg_idx;
-	host->buffer_bytes_left = sg->length;
-	host->buffer = page_address(sg->page) + sg->offset;
-	if (host->buffer_bytes_left > host->bytes_left)
-		host->buffer_bytes_left = host->bytes_left;
-}
-
-static void davinci_fifo_data_trans(struct mmc_davinci_host *host)
-{
-	int n, i;
-
-	if (host->buffer_bytes_left == 0) {
-		host->sg_idx++;
-		BUG_ON(host->sg_idx == host->sg_len);
-		mmc_davinci_sg_to_buf(host);
-	}
-
-	n = host->rw_threshold;
-	if (n > host->buffer_bytes_left)
-		n = host->buffer_bytes_left;
-
-	host->buffer_bytes_left -= n;
-	host->bytes_left -= n;
-
-	if (host->data_dir == DAVINCI_MMC_DATADIR_WRITE)
-		for (i = 0; i < (n / 4); i++) {
-			DAVINCI_MMC_WRITEL(host, DXR, *host->buffer);
-			host->buffer++;
-		}
-	else
-		for (i = 0; i < (n / 4); i++) {
-			*host->buffer = DAVINCI_MMC_READL(host, DRR);
-			host->buffer++;
-		}
-}
-
-
-
-static void mmc_davinci_start_command(struct mmc_davinci_host *host,
-				      struct mmc_command *cmd)
-{
-	u32 cmdreg = 0;
-	u32 resptype = 0;
-	u32 cmdtype = 0;
-	unsigned long flags;
-
-	host->cmd = cmd;
-
-	resptype = 0;
-	cmdtype = 0;
-
-	switch (RSP_TYPE(mmc_resp_type(cmd))) {
-	case RSP_TYPE(MMC_RSP_R1):
-		/* resp 1, resp 1b */
-		resptype = 1;
-		break;
-	case RSP_TYPE(MMC_RSP_R2):
-		resptype = 2;
-		break;
-	case RSP_TYPE(MMC_RSP_R3):
-		resptype = 3;
-		break;
-	default:
-		break;
-	}
-
-	/* Protocol layer does not provide command type, but our hardware
-	 * needs it!
-	 * any data transfer means adtc type (but that information is not
-	 * in command structure, so we flagged it into host struct.)
-	 * However, telling bc, bcr and ac apart based on response is
-	 * not foolproof:
-	 * CMD0  = bc  = resp0  CMD15 = ac  = resp0
-	 * CMD2  = bcr = resp2  CMD10 = ac  = resp2
-	 *
-	 * Resolve to best guess with some exception testing:
-	 * resp0 -> bc, except CMD15 = ac
-	 * rest are ac, except if opendrain
-	 */
-
-	if (host->data_dir)
-		cmdtype = DAVINCI_MMC_CMDTYPE_ADTC;
-	else if (resptype == 0 && cmd->opcode != 15)
-		cmdtype = DAVINCI_MMC_CMDTYPE_BC;
-	else if (host->bus_mode == MMC_BUSMODE_OPENDRAIN)
-		cmdtype = DAVINCI_MMC_CMDTYPE_BCR;
-	else
-		cmdtype = DAVINCI_MMC_CMDTYPE_AC;
-
-	/*
-	 * Set command Busy or not
-	 * Linux core sending BUSY which is not defined for cmd 24
-	 * as per mmc standard
-	 */
-	if (cmd->flags & MMC_RSP_BUSY)
-		if (cmd->opcode != 24)
-			cmdreg = cmdreg | (1 << 8);
-
-	/* Set command index */
-	cmdreg |= cmd->opcode;
-
-	/* Setting initialize clock */
-	if (cmd->opcode == 0)
-		cmdreg = cmdreg | (1 << 14);
-
-	/* Set for generating DMA Xfer event */
-	if ((host->do_dma == 1) && (host->data != NULL)
-	    && ((cmd->opcode == 18) || (cmd->opcode == 25)
-		|| (cmd->opcode == 24) || (cmd->opcode == 17)))
-		cmdreg = cmdreg | (1 << 16);
-
-	if ((host->data != NULL) && (host->pio_set_dmatrig)
-			&& (host->data_dir == DAVINCI_MMC_DATADIR_READ))
-		cmdreg = cmdreg | (1 << 16);
-
-	/* Setting whether command involves data transfer or not */
-	if (cmdtype == DAVINCI_MMC_CMDTYPE_ADTC)
-		cmdreg = cmdreg | (1 << 13);
-
-	/* Setting whether stream or block transfer */
-	if (cmd->flags & MMC_DATA_STREAM)
-		cmdreg = cmdreg | (1 << 12);
-
-	/* Setting whether data read or write */
-	if (host->data_dir == DAVINCI_MMC_DATADIR_WRITE)
-		cmdreg = cmdreg | (1 << 11);
-
-	/* Setting response type */
-	cmdreg = cmdreg | (resptype << 9);
-
-	if (host->bus_mode == MMC_BUSMODE_PUSHPULL)
-		cmdreg = cmdreg | (1 << 7);
-
-	/* set Command timeout */
-	DAVINCI_MMC_WRITEW(host, TOR, 0xFFFF);
-
-	/* Enable interrupt */
-	if (host->data_dir == DAVINCI_MMC_DATADIR_WRITE) {
-		if (host->do_dma != 1)
-			DAVINCI_MMC_WRITEW(host, IM, (DAVINCI_MMC_EVENT_EOFCMD |
-				      DAVINCI_MMC_EVENT_WRITE |
-				      DAVINCI_MMC_EVENT_ERROR_CMDCRC |
-				      DAVINCI_MMC_EVENT_ERROR_DATACRC |
-				      DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT |
-				      DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT |
-				      DAVINCI_MMC_EVENT_BLOCK_XFERRED));
-		else
-			DAVINCI_MMC_WRITEW(host, IM, (DAVINCI_MMC_EVENT_EOFCMD |
-				      DAVINCI_MMC_EVENT_ERROR_CMDCRC |
-				      DAVINCI_MMC_EVENT_ERROR_DATACRC |
-				      DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT |
-				      DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT |
-				      DAVINCI_MMC_EVENT_BLOCK_XFERRED));
-	} else if (host->data_dir == DAVINCI_MMC_DATADIR_READ) {
-		if (host->do_dma != 1)
-			DAVINCI_MMC_WRITEW(host, IM, (DAVINCI_MMC_EVENT_EOFCMD |
-				      DAVINCI_MMC_EVENT_READ |
-				      DAVINCI_MMC_EVENT_ERROR_CMDCRC |
-				      DAVINCI_MMC_EVENT_ERROR_DATACRC |
-				      DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT |
-				      DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT |
-				      DAVINCI_MMC_EVENT_BLOCK_XFERRED));
-		else
-			DAVINCI_MMC_WRITEW(host, IM, (DAVINCI_MMC_EVENT_EOFCMD |
-				      DAVINCI_MMC_EVENT_ERROR_CMDCRC |
-				      DAVINCI_MMC_EVENT_ERROR_DATACRC |
-				      DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT |
-				      DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT |
-				      DAVINCI_MMC_EVENT_BLOCK_XFERRED));
-	} else
-		DAVINCI_MMC_WRITEW(host, IM, (DAVINCI_MMC_EVENT_EOFCMD |
-				      DAVINCI_MMC_EVENT_ERROR_CMDCRC |
-				      DAVINCI_MMC_EVENT_ERROR_DATACRC |
-				      DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT |
-				      DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT));
-
-	/*
-	 * It is required by controoler b4 WRITE command that
-	 * FIFO should be populated with 32 bytes
-	 */
-	if ((host->data_dir == DAVINCI_MMC_DATADIR_WRITE) &&
-	    (cmdtype == DAVINCI_MMC_CMDTYPE_ADTC) && (host->do_dma != 1))
-		davinci_fifo_data_trans(host);
-
-	if (cmd->opcode == 7) {
-		spin_lock_irqsave(&host->mmc_lock, flags);
-		host->is_card_removed = 0;
-		host->new_card_state = 1;
-		host->is_card_initialized = 1;
-		host->old_card_state = host->new_card_state;
-		host->is_init_progress = 0;
-		spin_unlock_irqrestore(&host->mmc_lock, flags);
-	}
-	if (cmd->opcode == 1 || cmd->opcode == 41) {
-		spin_lock_irqsave(&host->mmc_lock, flags);
-		host->is_card_initialized = 0;
-		host->is_init_progress = 1;
-		spin_unlock_irqrestore(&host->mmc_lock, flags);
-	}
-
-	host->is_core_command = 1;
-	DAVINCI_MMC_WRITEL(host, ARGHL, cmd->arg);
-	DAVINCI_MMC_WRITEL(host, CMD, cmdreg);
-}
-
-static void davinci_abort_dma(struct mmc_davinci_host *host)
-{
-	int sync_dev = 0;
-
-	if (host->data_dir == DAVINCI_MMC_DATADIR_READ)
-		sync_dev = host->dma_tx_event;
-	else
-		sync_dev = host->dma_rx_event;
-
-	davinci_stop_dma(sync_dev);
-	davinci_clean_channel(sync_dev);
-
-}
-
-
-static void mmc_davinci_dma_cb(int lch, u16 ch_status, void *data)
-{
-	if (DMA_COMPLETE != ch_status) {
-		struct mmc_davinci_host *host = (struct mmc_davinci_host *)data;
-		dev_warn(host->mmc->dev, "[DMA FAILED]");
-		davinci_abort_dma(host);
-	}
-}
-
-static void davinci_reinit_chan(struct mmc_davinci_host *host)
-{
-	davinci_stop_dma(host->dma_tx_event);
-	davinci_clean_channel(host->dma_tx_event);
-
-	davinci_stop_dma(host->dma_rx_event);
-	davinci_clean_channel(host->dma_rx_event);
-}
-
-static int mmc_davinci_send_dma_request(struct mmc_davinci_host *host,
-					struct mmc_request *req)
-{
-	int sync_dev;
-	unsigned char i, j;
-	unsigned short acnt, bcnt, ccnt;
-	unsigned int src_port, dst_port, temp_ccnt;
-	enum address_mode mode_src, mode_dst;
-	enum fifo_width fifo_width_src, fifo_width_dst;
-	unsigned short src_bidx, dst_bidx;
-	unsigned short src_cidx, dst_cidx;
-	unsigned short bcntrld;
-	enum sync_dimension sync_mode;
-	struct paramentry_descriptor temp;
-	int edma_chan_num;
-	struct mmc_data *data = host->data;
-	struct scatterlist *sg = &data->sg[0];
-	unsigned int count;
-	int num_frames, frame;
-
-#define MAX_C_CNT		64000
-
-	frame = data->blksz;
-	count = sg_dma_len(sg);
-
-	if ((data->blocks == 1) && (count > data->blksz))
-		count = frame;
-
-	if (count % host->rw_threshold == 0) {
-		acnt = 4;
-		bcnt = host->rw_threshold / 4;
-		num_frames = count / host->rw_threshold;
-	} else {
-		acnt = count;
-		bcnt = 1;
-		num_frames = 1;
-	}
-
-	if (num_frames > MAX_C_CNT) {
-		temp_ccnt = MAX_C_CNT;
-		ccnt = temp_ccnt;
-	} else {
-		ccnt = num_frames;
-		temp_ccnt = ccnt;
-	}
-
-	if (host->data_dir == DAVINCI_MMC_DATADIR_WRITE) {
-		/*AB Sync Transfer */
-		sync_dev = host->dma_tx_event;
-
-		src_port = (unsigned int)sg_dma_address(sg);
-		mode_src = INCR;
-		fifo_width_src = W8BIT;	/* It's not cared as modeDsr is INCR */
-		src_bidx = acnt;
-		src_cidx = acnt * bcnt;
-		dst_port = host->phys_base + DAVINCI_MMC_REG_DXR;
-		mode_dst = INCR;
-		fifo_width_dst = W8BIT;	/* It's not cared as modeDsr is INCR */
-		dst_bidx = 0;
-		dst_cidx = 0;
-		bcntrld = 8;
-		sync_mode = ABSYNC;
-	} else {
-		sync_dev = host->dma_rx_event;
-
-		src_port = host->phys_base + DAVINCI_MMC_REG_DRR;
-		mode_src = INCR;
-		fifo_width_src = W8BIT;
-		src_bidx = 0;
-		src_cidx = 0;
-		dst_port = (unsigned int)sg_dma_address(sg);
-		mode_dst = INCR;
-		fifo_width_dst = W8BIT;	/* It's not cared as modeDsr is INCR */
-		dst_bidx = acnt;
-		dst_cidx = acnt * bcnt;
-		bcntrld = 8;
-		sync_mode = ABSYNC;
-	}
-
-	if (host->pio_set_dmatrig)
-		davinci_dma_clear_event(sync_dev);
-	davinci_set_dma_src_params(sync_dev, src_port, mode_src,
-				   fifo_width_src);
-	davinci_set_dma_dest_params(sync_dev, dst_port, mode_dst,
-				    fifo_width_dst);
-	davinci_set_dma_src_index(sync_dev, src_bidx, src_cidx);
-	davinci_set_dma_dest_index(sync_dev, dst_bidx, dst_cidx);
-	davinci_set_dma_transfer_params(sync_dev, acnt, bcnt, ccnt, bcntrld,
-					sync_mode);
-
-	davinci_get_dma_params(sync_dev, &temp);
-	if (sync_dev == host->dma_tx_event) {
-		if (host->option_write == 0) {
-			host->option_write = temp.opt;
-		} else {
-			temp.opt = host->option_write;
-			davinci_set_dma_params(sync_dev, &temp);
-		}
-	}
-	if (sync_dev == host->dma_rx_event) {
-		if (host->option_read == 0) {
-			host->option_read = temp.opt;
-		} else {
-			temp.opt = host->option_read;
-			davinci_set_dma_params(sync_dev, &temp);
-		}
-	}
-
-	if (host->sg_len > 1) {
-		davinci_get_dma_params(sync_dev, &temp);
-		temp.opt &= ~TCINTEN;
-		davinci_set_dma_params(sync_dev, &temp);
-
-		for (i = 0; i < host->sg_len - 1; i++) {
-
-			sg = &data->sg[i + 1];
-
-			if (i != 0) {
-				j = i - 1;
-				davinci_get_dma_params(host->edma_ch_details.
-						       chanel_num[j], &temp);
-				temp.opt &= ~TCINTEN;
-				davinci_set_dma_params(host->edma_ch_details.
-						       chanel_num[j], &temp);
-			}
-
-			edma_chan_num = host->edma_ch_details.chanel_num[0];
-
-			frame = data->blksz;
-			count = sg_dma_len(sg);
-
-			if ((data->blocks == 1) && (count > data->blksz))
-				count = frame;
-
-			ccnt = count / host->rw_threshold;
-
-			if (sync_dev == host->dma_tx_event)
-				temp.src = (unsigned int)sg_dma_address(sg);
-			else
-				temp.dst = (unsigned int)sg_dma_address(sg);
-
-			temp.opt |= TCINTEN;
-
-			temp.ccnt = (temp.ccnt & 0xFFFF0000) | (ccnt);
-
-			davinci_set_dma_params(edma_chan_num, &temp);
-			if (i != 0) {
-				j = i - 1;
-				davinci_dma_link_lch(host->edma_ch_details.
-						     chanel_num[j],
-						     edma_chan_num);
-			}
-		}
-		davinci_dma_link_lch(sync_dev,
-				     host->edma_ch_details.chanel_num[0]);
-	}
-
-	davinci_start_dma(sync_dev);
-	return 0;
-}
-
-static int mmc_davinci_start_dma_transfer(struct mmc_davinci_host *host,
-					  struct mmc_request *req)
-{
-	int use_dma = 1, i;
-	struct mmc_data *data = host->data;
-	int block_size = (1 << data->blksz_bits);
-
-	host->sg_len = dma_map_sg(host->mmc->dev, data->sg, host->sg_len,
-				  ((data->
-				    flags & MMC_DATA_WRITE) ? DMA_TO_DEVICE :
-				   DMA_FROM_DEVICE));
-
-	/* Decide if we can use DMA */
-	for (i = 0; i < host->sg_len; i++) {
-		if ((data->sg[i].length % block_size) != 0) {
-			use_dma = 0;
-			break;
-		}
-	}
-
-	if (!use_dma) {
-		dma_unmap_sg(host->mmc->dev, data->sg, host->sg_len,
-			     (data->
-			      flags & MMC_DATA_WRITE) ? DMA_TO_DEVICE :
-			     DMA_FROM_DEVICE);
-		return -1;
-	}
-
-	host->do_dma = 1;
-
-	mmc_davinci_send_dma_request(host, req);
-
-	return 0;
-
-}
-
-static int davinci_release_dma_channels(struct mmc_davinci_host *host)
-{
-	davinci_free_dma(host->dma_tx_event);
-	davinci_free_dma(host->dma_rx_event);
-
-	if (host->edma_ch_details.cnt_chanel) {
-		davinci_free_dma(host->edma_ch_details.chanel_num[0]);
-		host->edma_ch_details.cnt_chanel = 0;
-	}
-
-	return 0;
-}
-
-static int davinci_acquire_dma_channels(struct mmc_davinci_host *host)
-{
-	int edma_chan_num, tcc = 0, r, sync_dev;
-	enum dma_event_q queue_no = EVENTQ_0;
-
-	/* Acquire master DMA write channel */
-	r = davinci_request_dma(host->dma_tx_event, "MMC_WRITE",
-				     mmc_davinci_dma_cb, host,
-				     &edma_chan_num, &tcc, queue_no);
-	if (r) {
-		dev_warn(host->mmc->dev,
-			 "MMC: davinci_request_dma() failed with %d\n", r);
-		return r;
-	}
-
-	/* Acquire master DMA read channel */
-	r = davinci_request_dma(host->dma_rx_event, "MMC_READ",
-				     mmc_davinci_dma_cb, host,
-				     &edma_chan_num, &tcc, queue_no);
-	if (r) {
-		dev_warn(host->mmc->dev,
-			 "MMC: davinci_request_dma() failed with %d\n", r);
-		goto free_master_write;
-	}
-
-	host->edma_ch_details.cnt_chanel = 0;
-
-	/* currently data Writes are done using single block mode,
-	 * so no DMA slave write channel is required for now */
-
-	/* Create a DMA slave read channel
-	 * (assuming max segments handled is 2) */
-	sync_dev = host->dma_rx_event;
-	r = davinci_request_dma(DAVINCI_EDMA_PARAM_ANY, "LINK",
-				     NULL, NULL, &edma_chan_num,
-				     &sync_dev, queue_no);
-	if (r) {
-		dev_warn(host->mmc->dev,
-			 "MMC: davinci_request_dma() failed with %d\n", r);
-		goto free_master_read;
-	}
-
-	host->edma_ch_details.cnt_chanel++;
-	host->edma_ch_details.chanel_num[0] = edma_chan_num;
-
-	return 0;
-
-free_master_read:
-	davinci_free_dma(host->dma_rx_event);
-free_master_write:
-	davinci_free_dma(host->dma_tx_event);
-
-	return r;
-}
-
-static void mmc_davinci_prepare_data(struct mmc_davinci_host *host,
-				     struct mmc_request *req)
-{
-	int timeout, sg_len;
-	u16 reg;
-	host->data = req->data;
-	if (req->data == NULL) {
-		host->data_dir = DAVINCI_MMC_DATADIR_NONE;
-		DAVINCI_MMC_WRITEW(host, BLEN, 0);
-		DAVINCI_MMC_WRITEW(host, NBLK, 0);
-		return;
-	}
-	/* Init idx */
-	host->sg_idx = 0;
-
-	dev_dbg(host->mmc->dev,
-		"MMCSD : Data xfer (%s %s), "
-		"DTO %d cycles + %d ns, %d blocks of %d bytes\n",
-		(req->data->flags & MMC_DATA_STREAM) ? "stream" : "block",
-		(req->data->flags & MMC_DATA_WRITE) ? "write" : "read",
-		req->data->timeout_clks, req->data->timeout_ns,
-		req->data->blocks, 1 << req->data->blksz_bits);
-
-	/* Convert ns to clock cycles by assuming 20MHz frequency
-	 * 1 cycle at 20MHz = 500 ns
-	 */
-	timeout = req->data->timeout_clks + req->data->timeout_ns / 500;
-	if (timeout > 0xffff)
-		timeout = 0xffff;
-
-	DAVINCI_MMC_WRITEW(host, TOD, timeout);
-	DAVINCI_MMC_WRITEW(host, NBLK, req->data->blocks);
-	DAVINCI_MMC_WRITEW(host, BLEN, (1 << req->data->blksz_bits));
-	host->data_dir = (req->data->flags & MMC_DATA_WRITE) ?
-	    DAVINCI_MMC_DATADIR_WRITE : DAVINCI_MMC_DATADIR_READ;
-
-	/* Configure the FIFO */
-	switch (host->data_dir) {
-	case DAVINCI_MMC_DATADIR_WRITE:
-		reg = DAVINCI_MMC_READW(host, FIFO_CTL);
-		reg |= 0x1;
-		DAVINCI_MMC_WRITEW(host, FIFO_CTL, reg);
-		DAVINCI_MMC_WRITEW(host, FIFO_CTL, 0x0);
-		reg = DAVINCI_MMC_READW(host, FIFO_CTL);
-		reg |= (1 << 1);
-		DAVINCI_MMC_WRITEW(host, FIFO_CTL, reg);
-		reg = DAVINCI_MMC_READW(host, FIFO_CTL);
-		reg |= (1 << 2);
-		DAVINCI_MMC_WRITEW(host, FIFO_CTL, reg);
-		break;
-	case DAVINCI_MMC_DATADIR_READ:
-		reg = DAVINCI_MMC_READW(host, FIFO_CTL);
-		reg |= 0x1;
-		DAVINCI_MMC_WRITEW(host, FIFO_CTL, reg);
-		DAVINCI_MMC_WRITEW(host, FIFO_CTL, 0x0);
-		reg = DAVINCI_MMC_READW(host, FIFO_CTL);
-		reg |= (1 << 2);
-		DAVINCI_MMC_WRITEW(host, FIFO_CTL, reg);
-		break;
-	default:
-		break;
-	}
-
-	sg_len = (req->data->blocks == 1) ? 1 : req->data->sg_len;
-	host->sg_len = sg_len;
-
-	host->bytes_left = req->data->blocks * (1 << req->data->blksz_bits);
-
-	if ((host->use_dma == 1) && (host->bytes_left % host->rw_threshold == 0)
-	    && (mmc_davinci_start_dma_transfer(host, req) == 0)) {
-		host->buffer = NULL;
-		host->bytes_left = 0;
-	} else {
-		/* Revert to CPU Copy */
-
-		host->do_dma = 0;
-		mmc_davinci_sg_to_buf(host);
-	}
-}
-
-static void mmc_davinci_request(struct mmc_host *mmc, struct mmc_request *req)
-{
-	struct mmc_davinci_host *host = mmc_priv(mmc);
-	unsigned long flags;
-
-	if (host->is_card_removed) {
-		if (req->cmd) {
-			req->cmd->error |= MMC_ERR_TIMEOUT;
-			mmc_request_done(mmc, req);
-		}
-		dev_dbg(host->mmc->dev,
-			"From code segment excuted when card removed\n");
-		return;
-	}
-
-	wait_on_data(host);
-
-	if (!host->is_card_detect_progress) {
-		spin_lock_irqsave(&host->mmc_lock, flags);
-		host->is_card_busy = 1;
-		spin_unlock_irqrestore(&host->mmc_lock, flags);
-		host->do_dma = 0;
-		mmc_davinci_prepare_data(host, req);
-		mmc_davinci_start_command(host, req->cmd);
-	} else {
-		/* Queue up the request as card dectection is being excuted */
-		host->que_mmc_host = mmc;
-		host->que_mmc_request = req;
-		spin_lock_irqsave(&host->mmc_lock, flags);
-		host->is_req_queued_up = 1;
-		spin_unlock_irqrestore(&host->mmc_lock, flags);
-	}
-}
-
-static unsigned int calculate_freq_for_card(struct mmc_davinci_host *host,
-			unsigned int mmc_req_freq)
-{
-	unsigned int mmc_freq, cpu_arm_clk, mmc_push_pull;
-
-	cpu_arm_clk = clk_get_rate(host->clk);
-
-	if (cpu_arm_clk > (2 * mmc_req_freq)) {
-		mmc_push_pull =
-		    ((unsigned int)cpu_arm_clk / (2 * mmc_req_freq)) - 1;
-	} else
-		mmc_push_pull = 0;
-
-	mmc_freq = (unsigned int)cpu_arm_clk / (2 * (mmc_push_pull + 1));
-
-	if (mmc_freq > mmc_req_freq)
-		mmc_push_pull = mmc_push_pull + 1;
-
-	return mmc_push_pull;
-}
-
-static void mmc_davinci_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
-{
-	unsigned short status;
-	unsigned int open_drain_freq, cpu_arm_clk;
-	unsigned int mmc_push_pull_freq;
-	u16 reg;
-	struct mmc_davinci_host *host = mmc_priv(mmc);
-
-	cpu_arm_clk = clk_get_rate(host->clk);
-	dev_dbg(host->mmc->dev, "clock %dHz busmode %d powermode %d \
-			Vdd %d.%02d\n",
-		ios->clock, ios->bus_mode, ios->power_mode,
-		ios->vdd / 100, ios->vdd % 100);
-
-	reg = DAVINCI_MMC_READW(host, CTL);
-	switch (ios->bus_width) {
-	case MMC_BUS_WIDTH_8:
-		dev_dbg(host->mmc->dev, "\nEnabling 8 bit mode\n");
-		reg |=	(1 << 8);
-		reg &= ~(1 << 2);
-		break;
-	case MMC_BUS_WIDTH_4:
-		dev_dbg(host->mmc->dev, "\nEnabling 4 bit mode\n");
-		reg &= ~(1 << 8);
-		reg |=	(1 << 2);
-		break;
-	default:
-		dev_dbg(host->mmc->dev, "\nEnabling 1 bit mode\n");
-		reg &= ~((1 << 8) | (1 << 2));
-	}
-	DAVINCI_MMC_WRITEW(host, CTL, reg);
-
-	if (ios->bus_mode == MMC_BUSMODE_OPENDRAIN) {
-		open_drain_freq =
-		    ((unsigned int)(cpu_arm_clk + 2*DAVINCI_MMC_INIT_CLOCK - 1)
-			/ (2 * DAVINCI_MMC_INIT_CLOCK)) - 1;
-		if (open_drain_freq > 0xff)
-			open_drain_freq = 0xff;
-		DAVINCI_MMC_WRITEW(host, CLK, open_drain_freq | 0x100);
-
-	} else {
-		mmc_push_pull_freq = calculate_freq_for_card(host, ios->clock);
-		reg = DAVINCI_MMC_READW(host, CLK);
-		reg &= ~(0x100);
-		DAVINCI_MMC_WRITEW(host, CLK, reg);
-		udelay(10);
-		DAVINCI_MMC_WRITEW(host, CLK, mmc_push_pull_freq | 0x100);
-		udelay(10);
-	}
-	host->bus_mode = ios->bus_mode;
-	if (ios->power_mode == MMC_POWER_UP) {
-		/* Send clock cycles, poll completion */
-		reg = DAVINCI_MMC_READW(host, IM);
-		DAVINCI_MMC_WRITEW(host, IM, 0);
-		DAVINCI_MMC_WRITEL(host, ARGHL, 0x0);
-		DAVINCI_MMC_WRITEL(host, CMD, 0x4000);
-		status = 0;
-		while (!(status & (DAVINCI_MMC_EVENT_EOFCMD)))
-			status = DAVINCI_MMC_READW(host, ST0);
-
-		DAVINCI_MMC_WRITEW(host, IM, reg);
-	}
-}
-
-static void mmc_davinci_xfer_done(struct mmc_davinci_host *host,
-				  struct mmc_data *data)
-{
-	unsigned long flags;
-	host->data = NULL;
-	host->data_dir = DAVINCI_MMC_DATADIR_NONE;
-	if (data->error == MMC_ERR_NONE)
-		data->bytes_xfered += data->blocks * (1 << data->blksz_bits);
-
-	if (host->do_dma) {
-		davinci_abort_dma(host);
-
-		dma_unmap_sg(host->mmc->dev, data->sg, host->sg_len,
-			     (data->
-			      flags & MMC_DATA_WRITE) ? DMA_TO_DEVICE :
-			     DMA_FROM_DEVICE);
-	}
-
-	if (data->error == MMC_ERR_TIMEOUT) {
-		spin_lock_irqsave(&host->mmc_lock, flags);
-		host->is_card_busy = 0;
-		spin_unlock_irqrestore(&host->mmc_lock, flags);
-		mmc_request_done(host->mmc, data->mrq);
-		return;
-	}
-
-	if (!data->stop) {
-		spin_lock_irqsave(&host->mmc_lock, flags);
-		host->is_card_busy = 0;
-		spin_unlock_irqrestore(&host->mmc_lock, flags);
-		mmc_request_done(host->mmc, data->mrq);
-		return;
-	}
-	mmc_davinci_start_command(host, data->stop);
-}
-
-static void mmc_davinci_cmd_done(struct mmc_davinci_host *host,
-				 struct mmc_command *cmd)
-{
-	unsigned long flags;
-	host->cmd = NULL;
-
-	if (!cmd) {
-		dev_warn(host->mmc->dev, "%s(): No cmd ptr\n", __func__);
-		return;
-	}
-
-	if (cmd->flags & MMC_RSP_PRESENT) {
-		if (cmd->flags & MMC_RSP_136) {
-			/* response type 2 */
-			cmd->resp[3] = DAVINCI_MMC_READL(host, RSP01);
-			cmd->resp[2] = DAVINCI_MMC_READL(host, RSP23);
-			cmd->resp[1] = DAVINCI_MMC_READL(host, RSP45);
-			cmd->resp[0] = DAVINCI_MMC_READL(host, RSP67);
-		} else {
-		/* response types 1, 1b, 3, 4, 5, 6 */
-		cmd->resp[0] = DAVINCI_MMC_READL(host, RSP67);
-		}
-	}
-
-	if (host->data == NULL || cmd->error != MMC_ERR_NONE) {
-		if (cmd->error == MMC_ERR_TIMEOUT)
-			cmd->mrq->cmd->retries = 0;
-		spin_lock_irqsave(&host->mmc_lock, flags);
-		host->is_card_busy = 0;
-		spin_unlock_irqrestore(&host->mmc_lock, flags);
-		mmc_request_done(host->mmc, cmd->mrq);
-	}
-
-}
-
-static irqreturn_t mmc_davinci_irq(int irq, void *dev_id, struct pt_regs *regs)
-{
-	struct mmc_davinci_host *host = (struct mmc_davinci_host *)dev_id;
-	u16 status;
-	int end_command;
-	int end_transfer;
-	unsigned long flags;
-	u16 reg;
-
-	if (host->is_core_command) {
-		if (host->cmd == NULL && host->data == NULL) {
-			status = DAVINCI_MMC_READW(host, ST0);
-			dev_dbg(host->mmc->dev, "Spurious interrupt 0x%04x\n",
-				status);
-			/* Disable the interrupt from mmcsd */
-			DAVINCI_MMC_WRITEW(host, IM, 0);
-			return IRQ_HANDLED;
-		}
-	}
-	end_command = 0;
-	end_transfer = 0;
-
-	status = DAVINCI_MMC_READW(host, ST0);
-	if (status == 0)
-		return IRQ_HANDLED;
-
-	if (host->is_core_command) {
-		if (host->is_card_initialized) {
-			if (host->new_card_state == 0) {
-				if (host->cmd) {
-					host->cmd->error |= MMC_ERR_TIMEOUT;
-					mmc_davinci_cmd_done(host, host->cmd);
-				}
-				dev_dbg(host->mmc->dev,
-					"From code segment excuted when card \
-					removed\n");
-				return IRQ_HANDLED;
-			}
-		}
-
-		while (status != 0) {
-			if (host->data_dir == DAVINCI_MMC_DATADIR_WRITE) {
-				if (status & DAVINCI_MMC_EVENT_WRITE) {
-					/* Buffer almost empty */
-					if (host->bytes_left > 0)
-						davinci_fifo_data_trans(host);
-				}
-			}
-
-			if (host->data_dir == DAVINCI_MMC_DATADIR_READ)
-				if (status & DAVINCI_MMC_EVENT_READ)
-					/* Buffer almost empty */
-					if (host->bytes_left > 0)
-						davinci_fifo_data_trans(host);
-
-			if (status & DAVINCI_MMC_EVENT_BLOCK_XFERRED) {
-				/* Block sent/received */
-				if (host->data != NULL) {
-					if (host->do_dma == 1)
-						end_transfer = 1;
-					else {
-						/* if datasize <
-						 * host_rw_threshold no RX ints
-						 * are generated */
-						if (host->bytes_left > 0)
-							davinci_fifo_data_trans
-							    (host);
-						end_transfer = 1;
-					}
-				} else
-					dev_warn(host->mmc->dev,
-						 "TC:host->data is NULL\n");
-			}
-
-			if (status & DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT) {
-				/* Data timeout */
-				if ((host->data) &&
-						(host->new_card_state != 0)) {
-					host->data->error |= MMC_ERR_TIMEOUT;
-					spin_lock_irqsave(&host->mmc_lock,
-							flags);
-					host->is_card_removed = 1;
-					host->new_card_state = 0;
-					host->is_card_initialized = 0;
-					spin_unlock_irqrestore(&host->mmc_lock,
-							       flags);
-					dev_dbg(host->mmc->dev,
-						"MMCSD: Data timeout, CMD%d \
-						and status is %x\n",
-						host->cmd->opcode, status);
-
-					if (host->cmd)
-						host->cmd->error |=
-						    MMC_ERR_TIMEOUT;
-					end_transfer = 1;
-				}
-			}
-
-			if (status & DAVINCI_MMC_EVENT_ERROR_DATACRC) {
-				/* DAT line portion is diabled and in reset
-				 * state */
-				reg = DAVINCI_MMC_READW(host, CTL);
-				reg |= (1 << 1);
-				DAVINCI_MMC_WRITEW(host, CTL, reg);
-				udelay(10);
-				reg = DAVINCI_MMC_READW(host, CTL);
-				reg &= ~(1 << 1);
-				DAVINCI_MMC_WRITEW(host, CTL, reg);
-
-				/* Data CRC error */
-				if (host->data) {
-					host->data->error |= MMC_ERR_BADCRC;
-					dev_dbg(host->mmc->dev,
-						"MMCSD: Data CRC error, bytes \
-						left %d\n",
-						host->bytes_left);
-					end_transfer = 1;
-				} else
-					dev_dbg(host->mmc->dev,
-						"MMCSD: Data CRC error\n");
-			}
-
-			if (status & DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT) {
-				if (host->do_dma)
-					davinci_abort_dma(host);
-
-				/* Command timeout */
-				if (host->cmd) {
-					/* Timeouts are normal in case of
-					 * MMC_SEND_STATUS
-					 */
-					if (host->cmd->opcode !=
-					    MMC_ALL_SEND_CID) {
-						dev_dbg(host->mmc->dev,
-							"MMCSD: Command \
-							timeout, CMD%d and \
-							status is %x\n",
-							host->cmd->opcode,
-							status);
-						spin_lock_irqsave(
-								&host->mmc_lock,
-								  flags);
-						host->new_card_state = 0;
-						host->is_card_initialized = 0;
-						spin_unlock_irqrestore
-						    (&host->mmc_lock, flags);
-					}
-					host->cmd->error |= MMC_ERR_TIMEOUT;
-					end_command = 1;
-
-				}
-			}
-
-			if (status & DAVINCI_MMC_EVENT_ERROR_CMDCRC) {
-				/* Command CRC error */
-				dev_dbg(host->mmc->dev, "Command CRC error\n");
-				if (host->cmd) {
-					/* Ignore CMD CRC errors during high
-					 * speed operation */
-					if (host->mmc->ios.clock <= 25000000) {
-						host->cmd->error |=
-						    MMC_ERR_BADCRC;
-					}
-					end_command = 1;
-				}
-			}
-
-			if (status & DAVINCI_MMC_EVENT_EOFCMD)
-				end_command = 1;
-
-			if (host->data == NULL) {
-				status = DAVINCI_MMC_READW(host, ST0);
-				if (status != 0) {
-					dev_dbg(host->mmc->dev,
-						"Status is %x at end of ISR \
-						when host->data is NULL",
-						status);
-					status = 0;
-
-				}
-			} else
-				status = DAVINCI_MMC_READW(host, ST0);
-		}
-
-		if (end_command)
-			mmc_davinci_cmd_done(host, host->cmd);
-
-		if (end_transfer)
-			mmc_davinci_xfer_done(host, host->data);
-	} else {
-		if (host->cmd_code == 13) {
-			if (status & DAVINCI_MMC_EVENT_EOFCMD) {
-				spin_lock_irqsave(&host->mmc_lock, flags);
-				host->new_card_state = 1;
-				spin_unlock_irqrestore(&host->mmc_lock, flags);
-
-			} else {
-				spin_lock_irqsave(&host->mmc_lock, flags);
-				host->is_card_removed = 1;
-				host->new_card_state = 0;
-				host->is_card_initialized = 0;
-				spin_unlock_irqrestore(&host->mmc_lock, flags);
-			}
-
-			spin_lock_irqsave(&host->mmc_lock, flags);
-			host->is_card_detect_progress = 0;
-			spin_unlock_irqrestore(&host->mmc_lock, flags);
-
-			if (host->is_req_queued_up) {
-				mmc_davinci_request(host->que_mmc_host,
-						    host->que_mmc_request);
-				spin_lock_irqsave(&host->mmc_lock, flags);
-				host->is_req_queued_up = 0;
-				spin_unlock_irqrestore(&host->mmc_lock, flags);
-			}
-
-		}
-
-		if (host->cmd_code == 1 || host->cmd_code == 55) {
-			if (status & DAVINCI_MMC_EVENT_EOFCMD) {
-				spin_lock_irqsave(&host->mmc_lock, flags);
-				host->is_card_removed = 0;
-				host->new_card_state = 1;
-				host->is_card_initialized = 0;
-				spin_unlock_irqrestore(&host->mmc_lock, flags);
-			} else {
-
-				spin_lock_irqsave(&host->mmc_lock, flags);
-				host->is_card_removed = 1;
-				host->new_card_state = 0;
-				host->is_card_initialized = 0;
-				spin_unlock_irqrestore(&host->mmc_lock, flags);
-			}
-
-			spin_lock_irqsave(&host->mmc_lock, flags);
-			host->is_card_detect_progress = 0;
-			spin_unlock_irqrestore(&host->mmc_lock, flags);
-
-			if (host->is_req_queued_up) {
-				mmc_davinci_request(host->que_mmc_host,
-						    host->que_mmc_request);
-				spin_lock_irqsave(&host->mmc_lock, flags);
-				host->is_req_queued_up = 0;
-				spin_unlock_irqrestore(&host->mmc_lock, flags);
-			}
-		}
-
-		if (host->cmd_code == 0) {
-			if (status & DAVINCI_MMC_EVENT_EOFCMD) {
-				host->is_core_command = 0;
-
-				if (host->flag_sd_mmc) {
-					host->flag_sd_mmc = 0;
-					host->cmd_code = 1;
-					/* Issue cmd1 */
-					DAVINCI_MMC_WRITEL(host, ARGHL,
-							0x80300000);
-					DAVINCI_MMC_WRITEL(host, CMD,
-							0x00000601);
-				} else {
-					host->flag_sd_mmc = 1;
-					host->cmd_code = 55;
-					/* Issue cmd55 */
-					DAVINCI_MMC_WRITEL(host, ARGHL, 0x0);
-					DAVINCI_MMC_WRITEL(host, CMD,
-					    ((0x0 | (1 << 9) | 55)));
-				}
-
-				dev_dbg(host->mmc->dev,
-					"MMC-Probing mmc with cmd%d\n",
-					host->cmd_code);
-			} else {
-				spin_lock_irqsave(&host->mmc_lock, flags);
-				host->new_card_state = 0;
-				host->is_card_initialized = 0;
-				host->is_card_detect_progress = 0;
-				spin_unlock_irqrestore(&host->mmc_lock, flags);
-			}
-		}
-
-	}
-	return IRQ_HANDLED;
-}
-
-static int mmc_davinci_get_ro(struct mmc_host *mmc)
-{
-	struct mmc_davinci_host *host = mmc_priv(mmc);
-
-	return host->get_ro ? host->get_ro(mmc->index) : 0;
-}
-
-static struct mmc_host_ops mmc_davinci_ops = {
-	.request = mmc_davinci_request,
-	.set_ios = mmc_davinci_set_ios,
-	.get_ro = mmc_davinci_get_ro
-};
-
-void mmc_check_card(unsigned long data)
-{
-	struct mmc_davinci_host *host = (struct mmc_davinci_host *)data;
-	unsigned long flags;
-	struct mmc_card *card = NULL;
-
-	if (host->mmc && host->mmc->card_selected)
-		card = host->mmc->card_selected;
-
-	if ((!host->is_card_detect_progress) || (!host->is_init_progress)) {
-		if (host->is_card_initialized) {
-			host->is_core_command = 0;
-			host->cmd_code = 13;
-			spin_lock_irqsave(&host->mmc_lock, flags);
-			host->is_card_detect_progress = 1;
-			spin_unlock_irqrestore(&host->mmc_lock, flags);
-			/* Issue cmd13 */
-			DAVINCI_MMC_WRITEL(host, ARGHL, (card && (card->state
-							 & MMC_STATE_SDCARD))
-					? (card->rca << 16) : 0x10000);
-			DAVINCI_MMC_WRITEL(host, CMD, 0x0000028D);
-		} else {
-			host->is_core_command = 0;
-			host->cmd_code = 0;
-			spin_lock_irqsave(&host->mmc_lock, flags);
-			host->is_card_detect_progress = 1;
-			spin_unlock_irqrestore(&host->mmc_lock, flags);
-			/* Issue cmd0 */
-			DAVINCI_MMC_WRITEL(host, ARGHL, 0);
-			DAVINCI_MMC_WRITEL(host, CMD, 0x4000);
-		}
-		DAVINCI_MMC_WRITEW(host, IM, (DAVINCI_MMC_EVENT_EOFCMD |
-				      DAVINCI_MMC_EVENT_ERROR_CMDCRC |
-				      DAVINCI_MMC_EVENT_ERROR_DATACRC |
-				      DAVINCI_MMC_EVENT_ERROR_CMDTIMEOUT |
-				      DAVINCI_MMC_EVENT_ERROR_DATATIMEOUT));
-
-	}
-}
-
-static void init_mmcsd_host(struct mmc_davinci_host *host)
-{
-	u16 reg;
-	/* CMD line portion is disabled and in reset state */
-	reg = DAVINCI_MMC_READW(host, CTL);
-	reg |= 0x1;
-	DAVINCI_MMC_WRITEW(host, CTL, reg);
-	/* DAT line portion is disabled and in reset state */
-	reg = DAVINCI_MMC_READW(host, CTL);
-	reg |= (1 << 1);
-	DAVINCI_MMC_WRITEW(host, CTL, reg);
-	udelay(10);
-
-	DAVINCI_MMC_WRITEW(host, CLK, 0x0);
-	reg = DAVINCI_MMC_READW(host, CLK);
-	reg |= (1 << 8);
-	DAVINCI_MMC_WRITEW(host, CLK, reg);
-
-	DAVINCI_MMC_WRITEW(host, TOR, 0xFFFF);
-	DAVINCI_MMC_WRITEW(host, TOD, 0xFFFF);
-
-	reg = DAVINCI_MMC_READW(host, CTL);
-	reg &= ~(0x1);
-	DAVINCI_MMC_WRITEW(host, CTL, reg);
-	reg = DAVINCI_MMC_READW(host, CTL);
-	reg &= ~(1 << 1);
-	DAVINCI_MMC_WRITEW(host, CTL, reg);
-	udelay(10);
-}
-
-static void davinci_mmc_check_status(unsigned long data)
-{
-	unsigned long flags;
-	struct mmc_davinci_host *host = (struct mmc_davinci_host *)data;
-	if (!host->is_card_busy) {
-		if (host->old_card_state ^ host->new_card_state) {
-			davinci_reinit_chan(host);
-			init_mmcsd_host(host);
-			mmc_detect_change(host->mmc, 0);
-			spin_lock_irqsave(&host->mmc_lock, flags);
-			host->old_card_state = host->new_card_state;
-			spin_unlock_irqrestore(&host->mmc_lock, flags);
-		} else {
-			mmc_check_card(data);
-		}
-
-	}
-	mod_timer(&host->timer, jiffies + MULTIPLIER_TO_HZ * HZ);
-}
-
-static int davinci_mmc_probe(struct platform_device *pdev)
-{
-	struct davinci_mmc_platform_data *minfo = pdev->dev.platform_data;
-	struct mmc_host *mmc;
-	struct mmc_davinci_host *host = NULL;
-	struct resource *res;
-	int ret = 0;
-	int irq;
-
-	if (minfo == NULL) {
-		dev_err(&pdev->dev, "platform data missing\n");
-		return -ENODEV;
-	}
-
-	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-	irq = platform_get_irq(pdev, 0);
-	if (res == NULL || irq < 0)
-		return -ENODEV;
-
-	res = request_mem_region(res->start, res->end - res->start + 1,
-				 pdev->name);
-	if (res == NULL)
-		return -EBUSY;
-
-	mmc = mmc_alloc_host(sizeof(struct mmc_davinci_host), &pdev->dev);
-	if (mmc == NULL) {
-		ret = -ENOMEM;
-		goto err_free_mem_region;
-	}
-
-	host = mmc_priv(mmc);
-	host->mmc = mmc;
-
-	spin_lock_init(&host->mmc_lock);
-
-	host->mem_res = res;
-	host->irq = irq;
-
-	host->phys_base = host->mem_res->start;
-	host->virt_base = (void __iomem *) IO_ADDRESS(host->phys_base);
-
-	host->use_dma = 0;
-
-	res = platform_get_resource(pdev, IORESOURCE_DMA, 0);
-	if (res > 0) {
-		host->dma_rx_event = res->start;
-		res = platform_get_resource(pdev, IORESOURCE_DMA, 1);
-		if (res > 0) {
-			host->dma_tx_event = res->start;
-			host->use_dma = 1;
-		} else
-			host->dma_rx_event = 0;
-	}
-
-	host->clk = clk_get(&pdev->dev, minfo->mmc_clk);
-	if (IS_ERR(host->clk)) {
-		ret = -ENODEV;
-		goto err_free_mmc_host;
-	}
-
-	ret = clk_enable(host->clk);
-	if (ret)
-		goto err_put_clk;
-
-	init_mmcsd_host(host);
-
-	if (minfo->use_8bit_mode) {
-		dev_info(mmc->dev, "Supporting 8-bit mode\n");
-		mmc->caps |= MMC_CAP_8_BIT_DATA;
-	}
-
-	if (minfo->use_4bit_mode) {
-		dev_info(mmc->dev, "Supporting 4-bit mode\n");
-		mmc->caps |= MMC_CAP_4_BIT_DATA;
-	}
-
-	if (!minfo->use_8bit_mode && !minfo->use_4bit_mode)
-		dev_info(mmc->dev, "Supporting 1-bit mode\n");
-
-	host->get_ro = minfo->get_ro;
-
-	host->pio_set_dmatrig = minfo->pio_set_dmatrig;
-
-	host->rw_threshold = minfo->rw_threshold;
-
-	mmc->ops = &mmc_davinci_ops;
-	mmc->f_min = 312500;
-	if (minfo->max_frq)
-		mmc->f_max = minfo->max_frq;
-	else
-		mmc->f_max = 25000000;
-	mmc->ocr_avail = MMC_VDD_32_33;
-
-	mmc->max_phys_segs = 2;
-	mmc->max_hw_segs = 2;
-	mmc->max_sectors = 256;
-
-	/* Restrict the max size of seg we can handle */
-	mmc->max_seg_size = mmc->max_sectors * 512;
-
-	dev_dbg(mmc->dev, "max_phys_segs=%d\n", mmc->max_phys_segs);
-	dev_dbg(mmc->dev, "max_hw_segs=%d\n", mmc->max_hw_segs);
-	dev_dbg(mmc->dev, "max_sect=%d\n", mmc->max_sectors);
-	dev_dbg(mmc->dev, "max_seg_size=%d\n", mmc->max_seg_size);
-
-	if (host->use_dma) {
-		dev_info(mmc->dev, "Using DMA mode\n");
-		ret = davinci_acquire_dma_channels(host);
-		if (ret)
-			goto err_release_clk;
-	} else {
-		dev_info(mmc->dev, "Not Using DMA mode\n");
-	}
-
-	host->sd_support = 1;
-	ret = request_irq(host->irq, mmc_davinci_irq, 0, DRIVER_NAME, host);
-	if (ret)
-		goto err_release_dma;
-
-	host->dev = &pdev->dev;
-	platform_set_drvdata(pdev, host);
-	mmc_add_host(mmc);
-
-	init_timer(&host->timer);
-	host->timer.data = (unsigned long)host;
-	host->timer.function = davinci_mmc_check_status;
-	host->timer.expires = jiffies + MULTIPLIER_TO_HZ * HZ;
-	add_timer(&host->timer);
-
-	return 0;
-
-err_release_dma:
-	davinci_release_dma_channels(host);
-err_release_clk:
-	clk_disable(host->clk);
-err_put_clk:
-	clk_put(host->clk);
-err_free_mmc_host:
-	mmc_free_host(mmc);
-err_free_mem_region:
-	release_mem_region(res->start, res->end - res->start + 1);
-
-	return ret;
-}
-
-static int davinci_mmcsd_remove(struct platform_device *dev)
-{
-	struct mmc_davinci_host *host = platform_get_drvdata(dev);
-	unsigned long flags;
-
-	if (host) {
-		spin_lock_irqsave(&host->mmc_lock, flags);
-		del_timer(&host->timer);
-		spin_unlock_irqrestore(&host->mmc_lock, flags);
-
-		mmc_remove_host(host->mmc);
-		platform_set_drvdata(dev, NULL);
-		free_irq(host->irq, host);
-		davinci_release_dma_channels(host);
-		clk_disable(host->clk);
-		clk_put(host->clk);
-		release_resource(host->mem_res);
-		kfree(host->mem_res);
-		mmc_free_host(host->mmc);
-	}
-
-	return 0;
-}
-
-#ifdef CONFIG_PM
-static int davinci_mmcsd_suspend(struct platform_device *pdev,
-		pm_message_t state)
-{
-	struct mmc_davinci_host *host = platform_get_drvdata(pdev);
-	int ret = 0;
-
-	if (host && host->mmc)
-		ret = mmc_suspend_host(host->mmc, state);
-
-	return ret;
-}
-
-static int davinci_mmcsd_resume(struct platform_device *pdev)
-{
-	struct mmc_davinci_host *host = platform_get_drvdata(pdev);
-	int ret = 0;
-
-	if (host && host->mmc)
-		ret = mmc_resume_host(host->mmc);
-
-	return ret;
-}
-#else
-#define davinci_mmcsd_suspend	NULL
-#define davinci_mmcsd_resume	NULL
-#endif
-
-static struct platform_driver davinci_mmcsd_driver = {
-	.probe 		= davinci_mmc_probe,
-	.remove		= davinci_mmcsd_remove,
-	.suspend	= davinci_mmcsd_suspend,
-	.resume		= davinci_mmcsd_resume,
-	.driver		= {
-		.name	= DRIVER_NAME,
-	},
-};
-
-
-static int davinci_mmcsd_init(void)
-{
-	return platform_driver_register(&davinci_mmcsd_driver);
-}
-
-static void __exit davinci_mmcsd_exit(void)
-{
-	platform_driver_unregister(&davinci_mmcsd_driver);
-}
-
-module_init(davinci_mmcsd_init);
-module_exit(davinci_mmcsd_exit);
-
-MODULE_DESCRIPTION("DAVINCI Multimedia Card driver");
-MODULE_LICENSE("GPL");
-MODULE_ALIAS(DRIVER_NAME);
-MODULE_AUTHOR("Texas Instruments");
Index: linux-2.6.18/drivers/mtd/nand/Makefile
===================================================================
--- linux-2.6.18.orig/drivers/mtd/nand/Makefile
+++ linux-2.6.18/drivers/mtd/nand/Makefile
@@ -22,7 +22,7 @@ obj-$(CONFIG_MTD_NAND_TS7250)		+= ts7250
 obj-$(CONFIG_MTD_NAND_NANDSIM)		+= nandsim.o
 obj-$(CONFIG_MTD_NAND_CS553X)		+= cs553x_nand.o
 obj-$(CONFIG_MTD_NAND_NDFC)		+= ndfc.o
-obj-$(CONFIG_MTD_NAND_DAVINCI)		+= davinci.o
+obj-$(CONFIG_MTD_NAND_DAVINCI)		+= davinci-nand.o
 obj-$(CONFIG_MTD_NAND_OMAP) 		+= omap-nand-flash.o
 obj-$(CONFIG_MTD_NAND_OMAP_HW)		+= omap-hw.o
 obj-$(CONFIG_MTD_NAND_PLATFORM)		+= plat_nand.o
Index: linux-2.6.18/drivers/mtd/nand/davinci-nand.c
===================================================================
--- /dev/null
+++ linux-2.6.18/drivers/mtd/nand/davinci-nand.c
@@ -0,0 +1,1136 @@
+/*
+ * linux/drivers/mtd/nand/davinci.c
+ *
+ * NAND Flash Driver
+ *
+ * Copyright (C) 2006 Texas Instruments.
+ *
+ * ----------------------------------------------------------------------------
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ * ----------------------------------------------------------------------------
+ *
+ *  Overview:
+ *   This is a device driver for the NAND flash device found on the
+ *   DaVinci board which utilizes the Samsung k9k2g08 part.
+ *
+ Modifications:
+ ver. 1.0: Feb 2005, Vinod/Sudhakar
+ -
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/err.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/nand.h>
+#include <linux/mtd/map.h>
+#include <linux/mtd/partitions.h>
+#include <linux/delay.h>
+#include <linux/clk.h>
+#include <linux/io.h>
+#include <asm/arch/hardware.h>
+#include <asm/arch/nand.h>
+
+#ifdef CONFIG_MTD_PARTITIONS
+static const char *part_probes[] = { "cmdlinepart", NULL };
+#endif
+
+/*
+ * Some NAND devices have two chip selects on the same device.  The driver
+ * supports devices with either one or two chip selects.
+ */
+#define MAX_CHIPS 2
+
+/*
+ * Convert a physical EMIF address to the corresponding chip enable.
+ *
+ *	address range			chip enable
+ *	-----------------------		-----------
+ *	0x02000000 - 0x03FFFFFF		0
+ *	0x04000000 - 0x05FFFFFF		1
+ *	0x06000000 - 0x07FFFFFF		2
+ *	0x08000000 - 0x09FFFFFF		3
+ */
+#define EMIF_ADDR_TO_CE(a) ((((a) >> 25) - 1) & 3)
+#define MAX_EMIF_CHIP_ENABLES 4
+
+struct nand_davinci_info {
+	struct resource *reg_res;
+	void __iomem *emifregs;
+	unsigned ce;		/* emif chip enable */
+	unsigned cle_mask;
+	unsigned ale_mask;
+	struct mtd_info *mtd;
+	struct mtd_partition *parts;
+	struct resource *data_res[MAX_CHIPS];
+	void __iomem *ioaddr[MAX_CHIPS];
+	struct clk *clk;
+};
+
+#define NAND_READ_START    0x00
+#define NAND_READ_END      0x30
+#define NAND_STATUS        0x70
+
+/* EMIF Register Offsets */
+#define NANDFCR			0x60
+#define NANDFSR			0x64
+#define NANDF1ECC		0x70
+#define NANDF2ECC		0x74
+#define NANDF3ECC		0x78
+#define NANDF4ECC		0x7C
+#define NAND4BITECCLOAD		0xBC
+#define NAND4BITECC1		0xC0
+#define NAND4BITECC2		0xC4
+#define NAND4BITECC3		0xC8
+#define NAND4BITECC4		0xCC
+#define NANDERRADD1		0xD0
+#define NANDERRADD2		0xD4
+#define NANDERRVAL1		0xD8
+#define NANDERRVAL2		0xDC
+#define EMIF_REG_SIZE		0x1000
+
+/* Definitions for 1-bit hardware ECC */
+#define NAND_Ecc_P1e		(1 << 0)
+#define NAND_Ecc_P2e		(1 << 1)
+#define NAND_Ecc_P4e		(1 << 2)
+#define NAND_Ecc_P8e		(1 << 3)
+#define NAND_Ecc_P16e		(1 << 4)
+#define NAND_Ecc_P32e		(1 << 5)
+#define NAND_Ecc_P64e		(1 << 6)
+#define NAND_Ecc_P128e		(1 << 7)
+#define NAND_Ecc_P256e		(1 << 8)
+#define NAND_Ecc_P512e		(1 << 9)
+#define NAND_Ecc_P1024e		(1 << 10)
+#define NAND_Ecc_P2048e		(1 << 11)
+
+#define NAND_Ecc_P1o            (1 << 16)
+#define NAND_Ecc_P2o            (1 << 17)
+#define NAND_Ecc_P4o            (1 << 18)
+#define NAND_Ecc_P8o            (1 << 19)
+#define NAND_Ecc_P16o           (1 << 20)
+#define NAND_Ecc_P32o           (1 << 21)
+#define NAND_Ecc_P64o           (1 << 22)
+#define NAND_Ecc_P128o          (1 << 23)
+#define NAND_Ecc_P256o          (1 << 24)
+#define NAND_Ecc_P512o          (1 << 25)
+#define NAND_Ecc_P1024o         (1 << 26)
+#define NAND_Ecc_P2048o         (1 << 27)
+
+#define TF(value)       (value ? 1 : 0)
+
+#define P2048e(a)       (TF(a & NAND_Ecc_P2048e)        << 0)
+#define P2048o(a)       (TF(a & NAND_Ecc_P2048o)        << 1)
+#define P1e(a)		(TF(a & NAND_Ecc_P1e)           << 2)
+#define P1o(a)		(TF(a & NAND_Ecc_P1o)           << 3)
+#define P2e(a)		(TF(a & NAND_Ecc_P2e)           << 4)
+#define P2o(a)		(TF(a & NAND_Ecc_P2o)           << 5)
+#define P4e(a)		(TF(a & NAND_Ecc_P4e)           << 6)
+#define P4o(a)		(TF(a & NAND_Ecc_P4o)           << 7)
+
+#define P8e(a)          (TF(a & NAND_Ecc_P8e)           << 0)
+#define P8o(a)          (TF(a & NAND_Ecc_P8o)           << 1)
+#define P16e(a)         (TF(a & NAND_Ecc_P16e)          << 2)
+#define P16o(a)         (TF(a & NAND_Ecc_P16o)          << 3)
+#define P32e(a)         (TF(a & NAND_Ecc_P32e)          << 4)
+#define P32o(a)         (TF(a & NAND_Ecc_P32o)          << 5)
+#define P64e(a)         (TF(a & NAND_Ecc_P64e)          << 6)
+#define P64o(a)         (TF(a & NAND_Ecc_P64o)          << 7)
+
+#define P128e(a)        (TF(a & NAND_Ecc_P128e)         << 0)
+#define P128o(a)        (TF(a & NAND_Ecc_P128o)         << 1)
+#define P256e(a)        (TF(a & NAND_Ecc_P256e)         << 2)
+#define P256o(a)        (TF(a & NAND_Ecc_P256o)         << 3)
+#define P512e(a)        (TF(a & NAND_Ecc_P512e)         << 4)
+#define P512o(a)        (TF(a & NAND_Ecc_P512o)         << 5)
+#define P1024e(a)       (TF(a & NAND_Ecc_P1024e)        << 6)
+#define P1024o(a)       (TF(a & NAND_Ecc_P1024o)        << 7)
+
+#define P8e_s(a)        (TF(a & NAND_Ecc_P8e)           << 0)
+#define P8o_s(a)        (TF(a & NAND_Ecc_P8o)           << 1)
+#define P16e_s(a)       (TF(a & NAND_Ecc_P16e)          << 2)
+#define P16o_s(a)       (TF(a & NAND_Ecc_P16o)          << 3)
+#define P1e_s(a)        (TF(a & NAND_Ecc_P1e)           << 4)
+#define P1o_s(a)        (TF(a & NAND_Ecc_P1o)           << 5)
+#define P2e_s(a)        (TF(a & NAND_Ecc_P2e)           << 6)
+#define P2o_s(a)        (TF(a & NAND_Ecc_P2o)           << 7)
+
+#define P4e_s(a)		(TF(a & NAND_Ecc_P4e)           << 0)
+#define P4o_s(a)		(TF(a & NAND_Ecc_P4o)           << 1)
+
+/* Definitions for 4-bit hardware ECC */
+#define NAND_STATUS_RETRY		5
+#define NAND_TIMEOUT			100
+#define NAND_ECC_BUSY			0xC
+#define NAND_4BITECC_MASK		0x03FF03FF
+#define EMIF_NANDFSR_ECC_STATE_MASK  	0x00000F00
+#define ECC_STATE_NO_ERR		0x0
+#define ECC_STATE_TOO_MANY_ERRS		0x1
+#define ECC_STATE_ERR_CORR_COMP_P	0x2
+#define ECC_STATE_ERR_CORR_COMP_N	0x3
+#define ECC_MAX_CORRECTABLE_ERRORS	0x4
+
+/*
+ * nand_davinci_select_chip
+ * Select a chip in a multi-chip device
+ */
+static void nand_davinci_select_chip(struct mtd_info *mtd, int chip)
+{
+	struct nand_chip *this = mtd->priv;
+	struct nand_davinci_info *info = this->priv;
+
+	switch (chip) {
+	case -1:
+		/* deselect all chips */
+		break;
+	case 0:
+	case 1:
+		this->IO_ADDR_R = info->ioaddr[chip];
+		this->IO_ADDR_W = info->ioaddr[chip];
+		break;
+	default:
+		BUG();
+	}
+}
+
+/*
+ *      hardware specific access to control-lines
+ */
+static void
+nand_davinci_hwcontrol(struct mtd_info *mtd, int cmd, unsigned int ctrl)
+{
+	int i;
+	struct nand_chip *this = mtd->priv;
+	struct nand_davinci_info *info = this->priv;
+	u32 IO_ADDR_W = (u32) this->IO_ADDR_W;
+
+	/* reset to original value */
+	for (i = 0; i < MAX_CHIPS; i++) {
+		/*
+		 * If the chip select is correct, IO_ADDR_W must be
+		 * info->ioaddr[i] + cle_mask, info->ioaddr[i] +
+		 * ale_mask or info->ioaddr[i].  In other words,
+		 * IO_ADDR_W - info->ioaddr[i], must be cle_mask, ale_mask,
+		 * or 0, so if we ignore cle_mask and ale_mask, all other
+		 * bits must be 0 for address match. If the other bits are
+		 * not 0, address does not match, and we try the next entry.
+		 */
+		if (((IO_ADDR_W - (u32) info->ioaddr[i]) &
+		    ~(info->cle_mask | info->ale_mask)) == 0) {
+			IO_ADDR_W = (u32) info->ioaddr[i];
+			break;
+		}
+	}
+
+	/*
+	 * Please note that "+" is used to get the offset instead of the
+	 * typical "|".  The reason is DM646x uses a NAND chip with cle_mask =
+	 * 0x80000.  Due to the high bit position, it interferes with the IO
+	 * address (kernel assigned 0xc8080000).  Therefore, the "|" has no
+	 * affect on getting the offset, and "+" is used.
+	 */
+	if (ctrl & NAND_CLE)
+		IO_ADDR_W += info->cle_mask;
+	else if (ctrl & NAND_ALE)
+		IO_ADDR_W += info->ale_mask;
+
+	this->IO_ADDR_W = (void __iomem *)IO_ADDR_W;
+
+	if (cmd == NAND_CMD_NONE)
+		return;
+
+	__raw_writeb(cmd, this->IO_ADDR_W);
+}
+
+/*
+ * 1-bit ECC routines
+ */
+
+static void nand_davinci_1bit_enable_hwecc(struct mtd_info *mtd, int mode)
+{
+	struct nand_chip *this = mtd->priv;
+	struct nand_davinci_info *info = this->priv;
+	void __iomem *nandfcr = info->emifregs + NANDFCR;
+
+	switch (mode) {
+	case NAND_ECC_WRITE:
+	case NAND_ECC_READ:
+		__raw_writel(__raw_readl(nandfcr) | (1 << (8 + info->ce)),
+			     nandfcr);
+		break;
+	default:
+		break;
+	}
+}
+
+/*
+ * Read the NAND ECC register corresponding to chip enable ce, where 0<=ce<=3.
+ */
+static u32 nand_davinci_1bit_readecc(struct mtd_info *mtd, u32 ce)
+{
+	struct nand_chip *this = mtd->priv;
+	struct nand_davinci_info *info = this->priv;
+
+	return __raw_readl(info->emifregs + NANDF1ECC + 4 * ce);
+}
+
+static int nand_davinci_1bit_calculate_ecc(struct mtd_info *mtd,
+					   const uint8_t *dat,
+					   uint8_t *ecc_code)
+{
+	unsigned int l;
+	struct nand_chip *this = mtd->priv;
+	struct nand_davinci_info *info = this->priv;
+
+	l = nand_davinci_1bit_readecc(mtd, info->ce);
+	*ecc_code++ = l;	/* P128e, ..., P1e */
+	*ecc_code++ = l >> 16;	/* P128o, ..., P1o */
+	/* P2048o, P1024o, P512o, P256o, P2048e, P1024e, P512e, P256e */
+	*ecc_code++ = ((l >> 8) & 0x0f) | ((l >> 20) & 0xf0);
+
+	return 0;
+}
+
+static void nand_davinci_1bit_gen_true_ecc(uint8_t *ecc_buf)
+{
+	u32 tmp =
+	    ecc_buf[0] | (ecc_buf[1] << 16) | ((ecc_buf[2] & 0xF0) << 20) |
+	    ((ecc_buf[2] & 0x0F) << 8);
+
+	ecc_buf[0] =
+	    ~(P64o(tmp) | P64e(tmp) | P32o(tmp) | P32e(tmp) | P16o(tmp) |
+	      P16e(tmp) | P8o(tmp) | P8e(tmp));
+	ecc_buf[1] =
+	    ~(P1024o(tmp) | P1024e(tmp) | P512o(tmp) | P512e(tmp) | P256o(tmp) |
+	      P256e(tmp) | P128o(tmp) | P128e(tmp));
+	ecc_buf[2] =
+	    ~(P4o(tmp) | P4e(tmp) | P2o(tmp) | P2e(tmp) | P1o(tmp) | P1e(tmp) |
+	      P2048o(tmp) | P2048e(tmp));
+}
+
+/**
+ * nand_davinci_1bit_compare_ecc
+ * @ecc_data1	read from NAND memory
+ * @ecc_data2	read from register
+ * @page_data	data
+ */
+
+static int
+nand_davinci_1bit_compare_ecc(uint8_t *ecc_data1, uint8_t *ecc_data2,
+				uint8_t *page_data)
+{
+	u32 i;
+	u8 tmp0_bit[8], tmp1_bit[8], tmp2_bit[8];
+	u8 comp0_bit[8], comp1_bit[8], comp2_bit[8];
+	u8 ecc_bit[24];
+	u8 ecc_sum = 0;
+	u8 find_bit = 0;
+	u32 find_byte = 0;
+	int isEccFF;
+
+	isEccFF = ((*(u32 *) ecc_data1 & 0xFFFFFF) == 0xFFFFFF);
+
+	nand_davinci_1bit_gen_true_ecc(ecc_data1);
+	nand_davinci_1bit_gen_true_ecc(ecc_data2);
+
+	for (i = 0; i <= 2; i++) {
+		*(ecc_data1 + i) = ~(*(ecc_data1 + i));
+		*(ecc_data2 + i) = ~(*(ecc_data2 + i));
+	}
+
+	for (i = 0; i < 8; i++) {
+		tmp0_bit[i] = *ecc_data1 % 2;
+		*ecc_data1 = *ecc_data1 / 2;
+	}
+
+	for (i = 0; i < 8; i++) {
+		tmp1_bit[i] = *(ecc_data1 + 1) % 2;
+		*(ecc_data1 + 1) = *(ecc_data1 + 1) / 2;
+	}
+
+	for (i = 0; i < 8; i++) {
+		tmp2_bit[i] = *(ecc_data1 + 2) % 2;
+		*(ecc_data1 + 2) = *(ecc_data1 + 2) / 2;
+	}
+
+	for (i = 0; i < 8; i++) {
+		comp0_bit[i] = *ecc_data2 % 2;
+		*ecc_data2 = *ecc_data2 / 2;
+	}
+
+	for (i = 0; i < 8; i++) {
+		comp1_bit[i] = *(ecc_data2 + 1) % 2;
+		*(ecc_data2 + 1) = *(ecc_data2 + 1) / 2;
+	}
+
+	for (i = 0; i < 8; i++) {
+		comp2_bit[i] = *(ecc_data2 + 2) % 2;
+		*(ecc_data2 + 2) = *(ecc_data2 + 2) / 2;
+	}
+
+	for (i = 0; i < 6; i++)
+		ecc_bit[i] = tmp2_bit[i + 2] ^ comp2_bit[i + 2];
+
+	for (i = 0; i < 8; i++)
+		ecc_bit[i + 6] = tmp0_bit[i] ^ comp0_bit[i];
+
+	for (i = 0; i < 8; i++)
+		ecc_bit[i + 14] = tmp1_bit[i] ^ comp1_bit[i];
+
+	ecc_bit[22] = tmp2_bit[0] ^ comp2_bit[0];
+	ecc_bit[23] = tmp2_bit[1] ^ comp2_bit[1];
+
+	for (i = 0; i < 24; i++)
+		ecc_sum += ecc_bit[i];
+
+	switch (ecc_sum) {
+	case 0:
+		/* Not reached because this function is not called if
+		   ECC values are equal */
+		return 0;
+
+	case 1:
+		/*
+		 * This case corresponds to a 1-bit error in the ECC code
+		 * itself.  We'll return 1 to indicate that a 1-bit error was
+		 * detected and corrected, but there is no need to correct
+		 * anything.
+		 */
+		DEBUG(MTD_DEBUG_LEVEL0, "Detected single-bit error in ECC\n");
+		return 1;
+
+	case 12:
+		/* Correctable error */
+		find_byte = (ecc_bit[23] << 8) +
+		    (ecc_bit[21] << 7) +
+		    (ecc_bit[19] << 6) +
+		    (ecc_bit[17] << 5) +
+		    (ecc_bit[15] << 4) +
+		    (ecc_bit[13] << 3) +
+		    (ecc_bit[11] << 2) + (ecc_bit[9] << 1) + ecc_bit[7];
+
+		find_bit = (ecc_bit[5] << 2) + (ecc_bit[3] << 1) + ecc_bit[1];
+
+		DEBUG(MTD_DEBUG_LEVEL0,
+		      "Correcting single bit ECC error at offset: %d, "
+		      "bit: %d\n", find_byte, find_bit);
+
+		page_data[find_byte] ^= (1 << find_bit);
+
+		return 1;
+
+	default:
+		if (isEccFF) {
+			if (ecc_data2[0] == 0 && ecc_data2[1] == 0
+			    && ecc_data2[2] == 0)
+				return 0;
+		}
+		DEBUG(MTD_DEBUG_LEVEL0, "UNCORRECTED_ERROR default\n");
+		return -1;
+	}
+}
+
+static int nand_davinci_1bit_correct_data(struct mtd_info *mtd, uint8_t *dat,
+					  uint8_t *read_ecc, uint8_t *calc_ecc)
+{
+	int r = 0;
+
+	if (memcmp(read_ecc, calc_ecc, 3) != 0) {
+		u_char read_ecc_copy[3], calc_ecc_copy[3];
+		int i;
+
+		for (i = 0; i < 3; i++) {
+			read_ecc_copy[i] = read_ecc[i];
+			calc_ecc_copy[i] = calc_ecc[i];
+		}
+		r = nand_davinci_1bit_compare_ecc(read_ecc_copy, calc_ecc_copy,
+						  dat);
+	}
+
+	return r;
+}
+
+/*
+ * We should always have a flash-based bad block table.  However, if one isn't
+ * found then all blocks will be scanned to look for factory-marked bad blocks.
+ * We supply a null pattern so that no blocks will be detected as bad.
+ */
+static struct nand_bbt_descr nand_davinci_4bit_badblock_pattern = {
+	.options = 0,
+	.offs = 0,
+	.len = 0,
+	.pattern = NULL,
+};
+
+static struct nand_ecclayout nand_davinci_4bit_layout = {
+	.eccbytes = 10,
+	.eccpos = {6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
+		   22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
+		   38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
+		   54, 55, 56, 57, 58, 59, 60, 61, 62, 63,
+		   },
+	.oobfree = {{0, 6}, {16, 6}, {32, 6}, {48, 6} },
+};
+
+/*
+ * When using 4-bit ECC with a 2048-byte data + 64-byte spare page size, the
+ * oob is scattered throughout the page in 4 16-byte chunks instead of being
+ * grouped together at the end of the page.  This means that the factory
+ * bad-block markers at offsets 2048 and 2049 will be overwritten when data
+ * is written to the flash.  Thus, we cannot use the factory method to mark
+ * or detect bad blocks and must rely on a flash-based bad block table instead.
+ *
+ */
+static int
+nand_davinci_4bit_block_bad(struct mtd_info *mtd, loff_t ofs, int getchip)
+{
+	return 0;
+}
+
+static void nand_davinci_4bit_enable_hwecc(struct mtd_info *mtd, int mode)
+{
+	struct nand_chip *this = mtd->priv;
+	struct nand_davinci_info *info = this->priv;
+	void __iomem *nandfcr;
+	u32 val;
+
+	switch (mode) {
+	case NAND_ECC_WRITE:
+	case NAND_ECC_READ:
+		/*
+		 * Start a new ECC calculation for reading or writing 512 bytes
+		 *  of data.
+		 */
+		nandfcr = info->emifregs + NANDFCR;
+		val = (__raw_readl(nandfcr) & ~(3 << 4))
+		    | (info->ce << 4) | (1 << 12);
+		__raw_writel(val, nandfcr);
+		break;
+	case NAND_ECC_READSYN:
+		__raw_readl(info->emifregs + NAND4BITECC1);
+		break;
+	default:
+		break;
+	}
+}
+
+static u32 nand_davinci_4bit_readecc(struct mtd_info *mtd, unsigned int ecc[4])
+{
+	struct nand_chip *this = mtd->priv;
+	struct nand_davinci_info *info = this->priv;
+
+	ecc[0] = __raw_readl(info->emifregs + NAND4BITECC1) & NAND_4BITECC_MASK;
+	ecc[1] = __raw_readl(info->emifregs + NAND4BITECC2) & NAND_4BITECC_MASK;
+	ecc[2] = __raw_readl(info->emifregs + NAND4BITECC3) & NAND_4BITECC_MASK;
+	ecc[3] = __raw_readl(info->emifregs + NAND4BITECC4) & NAND_4BITECC_MASK;
+
+	return 0;
+}
+
+static int nand_davinci_4bit_calculate_ecc(struct mtd_info *mtd,
+					   const uint8_t *dat,
+					   uint8_t *ecc_code)
+{
+	unsigned int hw_4ecc[4] = { 0, 0, 0, 0 };
+	unsigned int const1 = 0, const2 = 0;
+	unsigned char count1 = 0;
+
+	/*
+	 * Since the NAND_HWECC_SYNDROME option is enabled, this routine is
+	 * only called just after the data and oob have been written.  The
+	 * ECC value calculated by the hardware ECC generator is available
+	 * for us to read.
+	 */
+	nand_davinci_4bit_readecc(mtd, hw_4ecc);
+
+	/*Convert 10 bit ecc value to 8 bit */
+	for (count1 = 0; count1 < 2; count1++) {
+		const2 = count1 * 5;
+		const1 = count1 * 2;
+
+		/* Take first 8 bits from val1 (count1=0) or val5 (count1=1) */
+		ecc_code[const2] = hw_4ecc[const1] & 0xFF;
+
+		/*
+		 * Take 2 bits as LSB bits from val1 (count1=0) or val5
+		 * (count1=1) and 6 bits from val2 (count1=0) or val5 (count1=1)
+		 */
+		ecc_code[const2 + 1] =
+		    ((hw_4ecc[const1] >> 8) & 0x3) | ((hw_4ecc[const1] >> 14) &
+						      0xFC);
+
+		/*
+		 * Take 4 bits from val2 (count1=0) or val5 (count1=1) and
+		 * 4 bits from val3 (count1=0) or val6 (count1=1)
+		 */
+		ecc_code[const2 + 2] =
+		    ((hw_4ecc[const1] >> 22) & 0xF) |
+		    ((hw_4ecc[const1 + 1] << 4) & 0xF0);
+
+		/*
+		 * Take 6 bits from val3(count1=0) or val6 (count1=1) and
+		 * 2 bits from val4 (count1=0) or  val7 (count1=1)
+		 */
+		ecc_code[const2 + 3] =
+		    ((hw_4ecc[const1 + 1] >> 4) & 0x3F) |
+		    ((hw_4ecc[const1 + 1] >> 10) & 0xC0);
+
+		/* Take 8 bits from val4 (count1=0) or val7 (count1=1) */
+		ecc_code[const2 + 4] = (hw_4ecc[const1 + 1] >> 18) & 0xFF;
+	}
+	return 0;
+}
+
+static int nand_davinci_4bit_compare_ecc(struct mtd_info *mtd,
+					 uint8_t *read_ecc, /* read from NAND */
+					 uint8_t *page_data)
+{
+	struct nand_chip *this = mtd->priv;
+	struct nand_davinci_info *info = this->priv;
+	unsigned short ecc_10bit[8] = { 0, 0, 0, 0, 0, 0, 0, 0 };
+	int i;
+	unsigned int hw_4ecc[4] = { 0, 0, 0, 0 }, iserror = 0;
+	unsigned short *pspare = NULL, *pspare1 = NULL;
+	unsigned int numErrors, errorAddress, errorValue;
+	u32 val;
+
+	/*
+	 * Check for an ECC where all bytes are 0xFF.  If this is the case, we
+	 * will assume we are looking at an erased page and we should ignore the
+	 * ECC.
+	 */
+	for (i = 0; i < 10; i++) {
+		if (read_ecc[i] != 0xFF)
+			break;
+	}
+	if (i == 10)
+		return 0;
+
+	/* Convert 8 bit in to 10 bit */
+	pspare = (unsigned short *)&read_ecc[2];
+	pspare1 = (unsigned short *)&read_ecc[0];
+	/* Take 10 bits from 0th and 1st bytes */
+	ecc_10bit[0] = (*pspare1) & 0x3FF;	/* 10 */
+	/* Take 6 bits from 1st byte and 4 bits from 2nd byte */
+	ecc_10bit[1] = (((*pspare1) >> 10) & 0x3F)
+	    | (((pspare[0]) << 6) & 0x3C0);	/* 6 + 4 */
+	/* Take 4 bits form 2nd bytes and 6 bits from 3rd bytes */
+	ecc_10bit[2] = ((pspare[0]) >> 4) & 0x3FF;	/* 10 */
+	/*Take 2 bits from 3rd byte and 8 bits from 4th byte */
+	ecc_10bit[3] = (((pspare[0]) >> 14) & 0x3)
+	    | ((((pspare[1])) << 2) & 0x3FC);	/* 2 + 8 */
+	/* Take 8 bits from 5th byte and 2 bits from 6th byte */
+	ecc_10bit[4] = ((pspare[1]) >> 8)
+	    | ((((pspare[2])) << 8) & 0x300);	/* 8 + 2 */
+	/* Take 6 bits from 6th byte and 4 bits from 7th byte */
+	ecc_10bit[5] = (pspare[2] >> 2) & 0x3FF;	/* 10 */
+	/* Take 4 bits from 7th byte and 6 bits from 8th byte */
+	ecc_10bit[6] = (((pspare[2]) >> 12) & 0xF)
+	    | ((((pspare[3])) << 4) & 0x3F0);	/* 4 + 6 */
+	/*Take 2 bits from 8th byte and 8 bits from 9th byte */
+	ecc_10bit[7] = ((pspare[3]) >> 6) & 0x3FF;	/* 10 */
+
+	/*
+	 * Write the parity values in the NAND Flash 4-bit ECC Load register.
+	 * Write each parity value one at a time starting from 4bit_ecc_val8
+	 * to 4bit_ecc_val1.
+	 */
+	for (i = 7; i >= 0; i--)
+		__raw_writel(ecc_10bit[i], info->emifregs + NAND4BITECCLOAD);
+
+	/*
+	 * Perform a dummy read to the EMIF Revision Code and Status register.
+	 * This is required to ensure time for syndrome calculation after
+	 * writing the ECC values in previous step.
+	 */
+	__raw_readl(info->emifregs + NANDFSR);
+
+	/*
+	 * Read the syndrome from the NAND Flash 4-Bit ECC 1-4 registers.
+	 * A syndrome value of 0 means no bit errors. If the syndrome is
+	 * non-zero then go further otherwise return.
+	 */
+	nand_davinci_4bit_readecc(mtd, hw_4ecc);
+
+	if (hw_4ecc[0] == ECC_STATE_NO_ERR && hw_4ecc[1] == ECC_STATE_NO_ERR &&
+	    hw_4ecc[2] == ECC_STATE_NO_ERR && hw_4ecc[3] == ECC_STATE_NO_ERR)
+		return 0;
+
+	/*
+	 * Clear any previous address calculation by doing a dummy read of an
+	 * error address register.
+	 */
+	__raw_readl(info->emifregs + NANDERRADD1);
+
+	/*
+	 * Set the addr_calc_st bit(bit no 13) in the NAND Flash Control
+	 * register to 1.
+	 */
+	__raw_writel(__raw_readl(info->emifregs + NANDFCR) | (1 << 13),
+		     info->emifregs + NANDFCR);
+
+	/*
+	 * Wait for the corr_state field (bits 8 to 11)in the
+	 * NAND Flash Status register to be equal to 0x0, 0x1, 0x2, or 0x3.
+	 */
+	i = NAND_TIMEOUT;
+	val = NAND_STATUS_RETRY;
+	do {
+		iserror = __raw_readl(info->emifregs + NANDFSR);
+		iserror &= EMIF_NANDFSR_ECC_STATE_MASK;
+		iserror = iserror >> 8;
+		if (iserror & NAND_ECC_BUSY && val != NAND_STATUS_RETRY)
+			val = NAND_STATUS_RETRY;
+		else
+			val--;
+		i--;
+	} while ((i > 0) && (val > 0));
+
+
+	/*
+	 * ECC_STATE_TOO_MANY_ERRS (0x1) means errors cannot be
+	 * corrected (five or more errors).  The number of errors
+	 * calculated (err_num field) differs from the number of errors
+	 * searched.  ECC_STATE_ERR_CORR_COMP_P (0x2) means error
+	 * correction complete (errors on bit 8 or 9).
+	 * ECC_STATE_ERR_CORR_COMP_N (0x3) means error correction
+	 * complete (error exists).
+	 */
+
+	if (iserror == ECC_STATE_NO_ERR)
+		return 0;
+	else if (iserror == ECC_STATE_TOO_MANY_ERRS) {
+		printk(KERN_ERR "%s Too many errors to be corrected!\n"
+				, __func__);
+		return -1;
+	}
+
+	numErrors = ((__raw_readl(info->emifregs + NANDFSR) >> 16) & 0x3) + 1;
+
+	/* Read the error address, error value and correct */
+	for (i = 0; i < numErrors; i++) {
+		if (i > 1) {
+			errorAddress =
+			    ((__raw_readl(info->emifregs + NANDERRADD2) >>
+			      (16 * (i & 1))) & 0x3FF);
+			errorAddress = ((512 + 7) - errorAddress);
+			errorValue =
+			    ((__raw_readl(info->emifregs + NANDERRVAL2) >>
+			      (16 * (i & 1))) & 0xFF);
+		} else {
+			errorAddress =
+			    ((__raw_readl(info->emifregs + NANDERRADD1) >>
+			      (16 * (i & 1))) & 0x3FF);
+			errorAddress = ((512 + 7) - errorAddress);
+			errorValue =
+			    ((__raw_readl(info->emifregs + NANDERRVAL1) >>
+			      (16 * (i & 1))) & 0xFF);
+		}
+		/* xor the corrupt data with error value */
+		if (errorAddress < 512)
+			page_data[errorAddress] ^= errorValue;
+	}
+
+	return numErrors;
+}
+
+static int nand_davinci_4bit_correct_data(struct mtd_info *mtd, uint8_t *dat,
+					  uint8_t *read_ecc, uint8_t *calc_ecc)
+{
+	int r;
+
+	/*
+	 * dat points to 512 bytes of data.  read_ecc points to the start of the
+	 * ECC code exactly...  The calc_ecc pointer is not needed since
+	 * our caclulated ECC is already latched in the hardware ECC generator.
+	 */
+	r = nand_davinci_4bit_compare_ecc(mtd, read_ecc, dat);
+
+	return r;
+}
+
+static int
+davinci_read_page_syndrome(struct mtd_info *mtd, struct nand_chip *chip,
+				   uint8_t *buf)
+{
+	int i, eccsize = chip->ecc.size;
+	int eccbytes = chip->ecc.bytes;
+	int eccsteps = chip->ecc.steps;
+	uint8_t *p = buf;
+	uint8_t *oob = chip->oob_poi;
+
+	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
+		int stat;
+
+		chip->ecc.hwctl(mtd, NAND_ECC_READ);
+		chip->read_buf(mtd, p, eccsize);
+
+		chip->ecc.hwctl(mtd, NAND_ECC_READSYN);
+
+		if (chip->ecc.prepad) {
+			chip->read_buf(mtd, oob, chip->ecc.prepad);
+			oob += chip->ecc.prepad;
+		}
+
+		chip->read_buf(mtd, oob, eccbytes);
+		stat = chip->ecc.correct(mtd, p, oob, NULL);
+
+		if (stat == -1)
+			mtd->ecc_stats.failed++;
+		else
+			mtd->ecc_stats.corrected += stat;
+
+		oob += eccbytes;
+
+		if (chip->ecc.postpad) {
+			chip->read_buf(mtd, oob, chip->ecc.postpad);
+			oob += chip->ecc.postpad;
+		}
+	}
+
+	/* Calculate remaining oob bytes */
+	i = mtd->oobsize - (oob - chip->oob_poi);
+	if (i)
+		chip->read_buf(mtd, oob, i);
+
+	return 0;
+}
+
+static void davinci_write_page_syndrome(struct mtd_info *mtd,
+				    struct nand_chip *chip, const uint8_t *buf)
+{
+	int i, eccsize = chip->ecc.size;
+	int eccbytes = chip->ecc.bytes;
+	int eccsteps = chip->ecc.steps;
+	const uint8_t *p = buf;
+	uint8_t *oob = chip->oob_poi;
+
+	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
+
+		chip->ecc.hwctl(mtd, NAND_ECC_WRITE);
+		chip->write_buf(mtd, p, eccsize);
+
+		/* Calculate ECC without prepad */
+		chip->ecc.calculate(mtd, p, oob + chip->ecc.prepad);
+
+		if (chip->ecc.prepad) {
+			chip->write_buf(mtd, oob, chip->ecc.prepad);
+			oob += chip->ecc.prepad;
+		}
+		chip->write_buf(mtd, oob, eccbytes);
+		oob += eccbytes;
+
+		if (chip->ecc.postpad) {
+			chip->write_buf(mtd, oob, chip->ecc.postpad);
+			oob += chip->ecc.postpad;
+		}
+	}
+
+	/* Calculate remaining oob bytes */
+	i = mtd->oobsize - (oob - chip->oob_poi);
+	if (i)
+		chip->write_buf(mtd, oob, i);
+}
+static int nand_flash_init(struct nand_davinci_info *info)
+{
+	__raw_writel((1 << info->ce), info->emifregs + NANDFCR);
+
+	return 0;
+}
+
+#define res_size(_r) (((_r)->end - (_r)->start) + 1)
+
+static int __devinit nand_davinci_probe(struct device *dev)
+{
+	int err = 0, cs;
+	struct nand_davinci_info *info;
+	struct platform_device *pdev = to_platform_device(dev);
+	struct nand_davinci_platform_data *pdata = pdev->dev.platform_data;
+	struct nand_chip *this;
+	struct resource *res;
+	u32 rev_code;
+
+	info = kzalloc(sizeof(struct nand_davinci_info), GFP_KERNEL);
+	if (!info) {
+		err = -ENOMEM;
+		goto out;
+	}
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res || (res_size(res) < EMIF_REG_SIZE)) {
+		dev_err(dev, "insufficient resources\n");
+		err = -ENOENT;
+		goto out_free_info;
+	}
+
+	/*
+	 * We exclude the EMIF registers prior to NANDFCR (the chip select
+	 * timing registers) from our resource reservation request because we
+	 * don't use them and another module might need them.
+	 */
+	info->reg_res = request_mem_region(res->start + NANDFCR,
+					   res_size(res) - NANDFCR, pdev->name);
+	if (!info->reg_res) {
+		dev_err(dev, "cannot claim register memory region\n");
+		err = -EIO;
+		goto out_free_info;
+	}
+	info->emifregs = ioremap_nocache(res->start, res_size(res));
+
+	for (cs = 0; cs < MAX_CHIPS; cs++) {
+		res = platform_get_resource(pdev, IORESOURCE_MEM, cs + 1);
+		if (!res)
+			break;
+
+		if (cs == 0)
+			info->ce = EMIF_ADDR_TO_CE(res->start);
+		else {
+			if (info->ce != EMIF_ADDR_TO_CE(res->start)) {
+				dev_err(dev,
+					"bad secondary nand address 0x%08lx\n",
+					(unsigned long) res->start);
+				err = -EIO;
+				goto out_release_mem;
+			}
+		}
+
+		info->data_res[cs] = request_mem_region(res->start,
+							res_size(res),
+							pdev->name);
+		if (!info->data_res[cs]) {
+			dev_err(dev,
+				"cannot claim nand memory region at 0x%08lx\n",
+				(unsigned long) res->start);
+			err = -EIO;
+			goto out_release_mem;
+		}
+
+		info->ioaddr[cs] = ioremap_nocache(res->start, res_size(res));
+		if (!info->ioaddr[cs]) {
+			dev_err(dev,
+				"cannot ioremap nand memory region "
+				"at 0x%08lx\n", (unsigned long) res->start);
+			err = -ENOMEM;
+			goto out_release_mem;
+		}
+	}
+	if (!info->data_res[0]) {
+		dev_err(dev, "insufficient resources\n");
+		err = -ENOENT;
+		goto out_release_mem;
+	}
+
+	/* Allocate memory for the MTD device structure */
+	info->mtd = kzalloc(sizeof(struct mtd_info) +
+			    sizeof(struct nand_chip), GFP_KERNEL);
+	if (!info->mtd) {
+		err = -ENOMEM;
+		goto out_release_mem;
+	}
+
+	/* Get pointer to the nand private data */
+	this = (struct nand_chip *)(&info->mtd[1]);
+	/* Link the nand private data with the MTD structure */
+	info->mtd->priv = this;
+	/* Link our driver private data with the nand private data */
+	this->priv = info;
+
+	this->select_chip = nand_davinci_select_chip;
+	this->cmd_ctrl = nand_davinci_hwcontrol;
+	this->options = pdata->options;
+	this->bbt_td = pdata->bbt_td;
+	this->bbt_md = pdata->bbt_md;
+	this->chip_delay = 25;
+
+	info->cle_mask = pdata->cle_mask;
+	info->ale_mask = pdata->ale_mask;
+
+	this->ecc.mode = pdata->ecc_mode;
+
+	switch (this->ecc.mode) {
+	case NAND_ECC_NONE:
+		dev_warn(dev, "Warning: NAND ECC is disabled\n");
+		break;
+	case NAND_ECC_SOFT:
+		dev_info(dev, "Using soft ECC\n");
+		break;
+	case NAND_ECC_HW:
+			dev_info(dev, "Using 1-bit hardware ECC\n");
+		this->ecc.size = 512;
+		this->ecc.bytes = 3;
+			this->ecc.calculate = nand_davinci_1bit_calculate_ecc;
+			this->ecc.correct = nand_davinci_1bit_correct_data;
+			this->ecc.hwctl = nand_davinci_1bit_enable_hwecc;
+		break;
+	case NAND_ECC_HW_SYNDROME:
+		dev_info(dev, "Using 4-bit hardware ECC\n");
+		this->ecc.size = 512;
+		this->ecc.bytes = 10;
+		this->ecc.prepad = 6;
+		this->ecc.layout = &nand_davinci_4bit_layout;
+		this->ecc.calculate = nand_davinci_4bit_calculate_ecc;
+		this->ecc.correct = nand_davinci_4bit_correct_data;
+		this->ecc.hwctl = nand_davinci_4bit_enable_hwecc;
+		this->ecc.read_page = davinci_read_page_syndrome;
+		this->ecc.write_page = davinci_write_page_syndrome;
+		/* we also need special bad block table because
+		 * factory marks are overwritten */
+		this->options |= (NAND_USE_FLASH_BBT
+				| NAND_USE_DATA_ADJACENT_OOB);
+		this->badblock_pattern = &nand_davinci_4bit_badblock_pattern;
+		this->block_bad = nand_davinci_4bit_block_bad;
+		break;
+	default:
+		dev_err(dev, "Unsupported ECC mode %d requested\n",
+			this->ecc.mode);
+		goto out_release_mem;
+	}
+
+	info->mtd->name = pdev->dev.bus_id;
+	info->mtd->owner = THIS_MODULE;
+
+	info->clk = clk_get(dev, "AEMIFCLK");
+	if (IS_ERR(info->clk)) {
+		err = -ENXIO;
+		goto out_free_mtd;
+	}
+	clk_enable(info->clk);
+
+	nand_flash_init(info);
+
+	/* Scan for the device */
+	if (nand_scan(info->mtd, info->data_res[1] ? 2 : 1)) {
+		dev_err(dev, "no nand device detected\n");
+		err = -ENODEV;
+		goto out_unuse_clk;
+	}
+
+	/* Terminate any ECC calculation already in progress */
+	switch (this->ecc.mode) {
+	case NAND_ECC_HW:
+		nand_davinci_1bit_enable_hwecc(info->mtd, NAND_ECC_WRITE);
+		nand_davinci_1bit_readecc(info->mtd, info->ce);
+		break;
+	case NAND_ECC_HW_SYNDROME:
+		{
+			unsigned int ecc[4];
+			nand_davinci_4bit_enable_hwecc(info->mtd,
+					NAND_ECC_WRITE);
+			nand_davinci_4bit_readecc(info->mtd, ecc);
+		}
+	default:
+		break;
+	}
+
+#ifdef CONFIG_MTD_PARTITIONS
+	err = parse_mtd_partitions(info->mtd, part_probes, &info->parts, 0);
+	if (err > 0)
+		add_mtd_partitions(info->mtd, info->parts, err);
+	else if (err < 0 && pdata->parts)
+		add_mtd_partitions(info->mtd, pdata->parts, pdata->nr_parts);
+	else
+#endif
+		add_mtd_device(info->mtd);
+
+	dev_set_drvdata(dev, info);
+
+	/* show rev code */
+	rev_code = __raw_readl(info->emifregs);
+	dev_info(dev, "hardware revision: %d.%d\n",
+		 (rev_code >> 8) & 0xff, rev_code & 0xff);
+
+	return 0;
+
+out_unuse_clk:
+	clk_disable(info->clk);
+out_free_mtd:
+	kfree(info->mtd);
+out_release_mem:
+	for (cs = 0; cs < MAX_CHIPS; cs++) {
+		if (info->ioaddr[cs])
+			iounmap(info->ioaddr[cs]);
+		if (info->data_res[cs]) {
+			release_resource(info->data_res[cs]);
+			kfree(info->data_res[cs]);
+		}
+	}
+	release_resource(info->reg_res);
+	kfree(info->reg_res);
+out_free_info:
+	kfree(info);
+out:
+	return err;
+}
+
+static int __devexit nand_davinci_remove(struct device *dev)
+{
+	struct nand_davinci_info *info = dev_get_drvdata(dev);
+	int cs;
+
+	if (info) {
+		/* Release NAND device, internal structures, and partitions */
+		nand_release(info->mtd);
+
+		clk_disable(info->clk);
+
+		kfree(info->mtd);
+
+		for (cs = 0; cs < MAX_CHIPS; cs++) {
+			if (info->ioaddr[cs])
+				iounmap(info->ioaddr[cs]);
+			if (info->data_res[cs]) {
+				release_resource(info->data_res[cs]);
+				kfree(info->data_res[cs]);
+			}
+		}
+
+		release_resource(info->reg_res);
+		kfree(info->reg_res);
+
+		kfree(info);
+
+		dev_set_drvdata(dev, NULL);
+	}
+
+	return 0;
+}
+
+static struct device_driver nand_davinci_driver = {
+	.name = "nand_davinci",
+	.bus = &platform_bus_type,
+	.probe = nand_davinci_probe,
+	.remove = __devexit_p(nand_davinci_remove),
+};
+
+static int __init nand_davinci_init(void)
+{
+	return driver_register(&nand_davinci_driver);
+}
+
+static void __exit nand_davinci_exit(void)
+{
+	driver_unregister(&nand_davinci_driver);
+}
+
+module_init(nand_davinci_init);
+module_exit(nand_davinci_exit);
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Texas Instruments");
+MODULE_DESCRIPTION("Board-specific driver for NAND flash on davinci board");
Index: linux-2.6.18/drivers/mtd/nand/davinci.c
===================================================================
--- linux-2.6.18.orig/drivers/mtd/nand/davinci.c
+++ /dev/null
@@ -1,1136 +0,0 @@
-/*
- * linux/drivers/mtd/nand/davinci.c
- *
- * NAND Flash Driver
- *
- * Copyright (C) 2006 Texas Instruments.
- *
- * ----------------------------------------------------------------------------
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- *  You should have received a copy of the GNU General Public License
- *  along with this program; if not, write to the Free Software
- *  Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
- * ----------------------------------------------------------------------------
- *
- *  Overview:
- *   This is a device driver for the NAND flash device found on the
- *   DaVinci board which utilizes the Samsung k9k2g08 part.
- *
- Modifications:
- ver. 1.0: Feb 2005, Vinod/Sudhakar
- -
- *
- */
-
-#include <linux/kernel.h>
-#include <linux/init.h>
-#include <linux/slab.h>
-#include <linux/module.h>
-#include <linux/err.h>
-#include <linux/device.h>
-#include <linux/platform_device.h>
-#include <linux/mtd/mtd.h>
-#include <linux/mtd/nand.h>
-#include <linux/mtd/map.h>
-#include <linux/mtd/partitions.h>
-#include <linux/delay.h>
-#include <linux/clk.h>
-#include <linux/io.h>
-#include <asm/arch/hardware.h>
-#include <asm/arch/nand.h>
-
-#ifdef CONFIG_MTD_PARTITIONS
-static const char *part_probes[] = { "cmdlinepart", NULL };
-#endif
-
-/*
- * Some NAND devices have two chip selects on the same device.  The driver
- * supports devices with either one or two chip selects.
- */
-#define MAX_CHIPS 2
-
-/*
- * Convert a physical EMIF address to the corresponding chip enable.
- *
- *	address range			chip enable
- *	-----------------------		-----------
- *	0x02000000 - 0x03FFFFFF		0
- *	0x04000000 - 0x05FFFFFF		1
- *	0x06000000 - 0x07FFFFFF		2
- *	0x08000000 - 0x09FFFFFF		3
- */
-#define EMIF_ADDR_TO_CE(a) ((((a) >> 25) - 1) & 3)
-#define MAX_EMIF_CHIP_ENABLES 4
-
-struct nand_davinci_info {
-	struct resource *reg_res;
-	void __iomem *emifregs;
-	unsigned ce;		/* emif chip enable */
-	unsigned cle_mask;
-	unsigned ale_mask;
-	struct mtd_info *mtd;
-	struct mtd_partition *parts;
-	struct resource *data_res[MAX_CHIPS];
-	void __iomem *ioaddr[MAX_CHIPS];
-	struct clk *clk;
-};
-
-#define NAND_READ_START    0x00
-#define NAND_READ_END      0x30
-#define NAND_STATUS        0x70
-
-/* EMIF Register Offsets */
-#define NANDFCR			0x60
-#define NANDFSR			0x64
-#define NANDF1ECC		0x70
-#define NANDF2ECC		0x74
-#define NANDF3ECC		0x78
-#define NANDF4ECC		0x7C
-#define NAND4BITECCLOAD		0xBC
-#define NAND4BITECC1		0xC0
-#define NAND4BITECC2		0xC4
-#define NAND4BITECC3		0xC8
-#define NAND4BITECC4		0xCC
-#define NANDERRADD1		0xD0
-#define NANDERRADD2		0xD4
-#define NANDERRVAL1		0xD8
-#define NANDERRVAL2		0xDC
-#define EMIF_REG_SIZE		0x1000
-
-/* Definitions for 1-bit hardware ECC */
-#define NAND_Ecc_P1e		(1 << 0)
-#define NAND_Ecc_P2e		(1 << 1)
-#define NAND_Ecc_P4e		(1 << 2)
-#define NAND_Ecc_P8e		(1 << 3)
-#define NAND_Ecc_P16e		(1 << 4)
-#define NAND_Ecc_P32e		(1 << 5)
-#define NAND_Ecc_P64e		(1 << 6)
-#define NAND_Ecc_P128e		(1 << 7)
-#define NAND_Ecc_P256e		(1 << 8)
-#define NAND_Ecc_P512e		(1 << 9)
-#define NAND_Ecc_P1024e		(1 << 10)
-#define NAND_Ecc_P2048e		(1 << 11)
-
-#define NAND_Ecc_P1o            (1 << 16)
-#define NAND_Ecc_P2o            (1 << 17)
-#define NAND_Ecc_P4o            (1 << 18)
-#define NAND_Ecc_P8o            (1 << 19)
-#define NAND_Ecc_P16o           (1 << 20)
-#define NAND_Ecc_P32o           (1 << 21)
-#define NAND_Ecc_P64o           (1 << 22)
-#define NAND_Ecc_P128o          (1 << 23)
-#define NAND_Ecc_P256o          (1 << 24)
-#define NAND_Ecc_P512o          (1 << 25)
-#define NAND_Ecc_P1024o         (1 << 26)
-#define NAND_Ecc_P2048o         (1 << 27)
-
-#define TF(value)       (value ? 1 : 0)
-
-#define P2048e(a)       (TF(a & NAND_Ecc_P2048e)        << 0)
-#define P2048o(a)       (TF(a & NAND_Ecc_P2048o)        << 1)
-#define P1e(a)		(TF(a & NAND_Ecc_P1e)           << 2)
-#define P1o(a)		(TF(a & NAND_Ecc_P1o)           << 3)
-#define P2e(a)		(TF(a & NAND_Ecc_P2e)           << 4)
-#define P2o(a)		(TF(a & NAND_Ecc_P2o)           << 5)
-#define P4e(a)		(TF(a & NAND_Ecc_P4e)           << 6)
-#define P4o(a)		(TF(a & NAND_Ecc_P4o)           << 7)
-
-#define P8e(a)          (TF(a & NAND_Ecc_P8e)           << 0)
-#define P8o(a)          (TF(a & NAND_Ecc_P8o)           << 1)
-#define P16e(a)         (TF(a & NAND_Ecc_P16e)          << 2)
-#define P16o(a)         (TF(a & NAND_Ecc_P16o)          << 3)
-#define P32e(a)         (TF(a & NAND_Ecc_P32e)          << 4)
-#define P32o(a)         (TF(a & NAND_Ecc_P32o)          << 5)
-#define P64e(a)         (TF(a & NAND_Ecc_P64e)          << 6)
-#define P64o(a)         (TF(a & NAND_Ecc_P64o)          << 7)
-
-#define P128e(a)        (TF(a & NAND_Ecc_P128e)         << 0)
-#define P128o(a)        (TF(a & NAND_Ecc_P128o)         << 1)
-#define P256e(a)        (TF(a & NAND_Ecc_P256e)         << 2)
-#define P256o(a)        (TF(a & NAND_Ecc_P256o)         << 3)
-#define P512e(a)        (TF(a & NAND_Ecc_P512e)         << 4)
-#define P512o(a)        (TF(a & NAND_Ecc_P512o)         << 5)
-#define P1024e(a)       (TF(a & NAND_Ecc_P1024e)        << 6)
-#define P1024o(a)       (TF(a & NAND_Ecc_P1024o)        << 7)
-
-#define P8e_s(a)        (TF(a & NAND_Ecc_P8e)           << 0)
-#define P8o_s(a)        (TF(a & NAND_Ecc_P8o)           << 1)
-#define P16e_s(a)       (TF(a & NAND_Ecc_P16e)          << 2)
-#define P16o_s(a)       (TF(a & NAND_Ecc_P16o)          << 3)
-#define P1e_s(a)        (TF(a & NAND_Ecc_P1e)           << 4)
-#define P1o_s(a)        (TF(a & NAND_Ecc_P1o)           << 5)
-#define P2e_s(a)        (TF(a & NAND_Ecc_P2e)           << 6)
-#define P2o_s(a)        (TF(a & NAND_Ecc_P2o)           << 7)
-
-#define P4e_s(a)		(TF(a & NAND_Ecc_P4e)           << 0)
-#define P4o_s(a)		(TF(a & NAND_Ecc_P4o)           << 1)
-
-/* Definitions for 4-bit hardware ECC */
-#define NAND_STATUS_RETRY		5
-#define NAND_TIMEOUT			100
-#define NAND_ECC_BUSY			0xC
-#define NAND_4BITECC_MASK		0x03FF03FF
-#define EMIF_NANDFSR_ECC_STATE_MASK  	0x00000F00
-#define ECC_STATE_NO_ERR		0x0
-#define ECC_STATE_TOO_MANY_ERRS		0x1
-#define ECC_STATE_ERR_CORR_COMP_P	0x2
-#define ECC_STATE_ERR_CORR_COMP_N	0x3
-#define ECC_MAX_CORRECTABLE_ERRORS	0x4
-
-/*
- * nand_davinci_select_chip
- * Select a chip in a multi-chip device
- */
-static void nand_davinci_select_chip(struct mtd_info *mtd, int chip)
-{
-	struct nand_chip *this = mtd->priv;
-	struct nand_davinci_info *info = this->priv;
-
-	switch (chip) {
-	case -1:
-		/* deselect all chips */
-		break;
-	case 0:
-	case 1:
-		this->IO_ADDR_R = info->ioaddr[chip];
-		this->IO_ADDR_W = info->ioaddr[chip];
-		break;
-	default:
-		BUG();
-	}
-}
-
-/*
- *      hardware specific access to control-lines
- */
-static void
-nand_davinci_hwcontrol(struct mtd_info *mtd, int cmd, unsigned int ctrl)
-{
-	int i;
-	struct nand_chip *this = mtd->priv;
-	struct nand_davinci_info *info = this->priv;
-	u32 IO_ADDR_W = (u32) this->IO_ADDR_W;
-
-	/* reset to original value */
-	for (i = 0; i < MAX_CHIPS; i++) {
-		/*
-		 * If the chip select is correct, IO_ADDR_W must be
-		 * info->ioaddr[i] + cle_mask, info->ioaddr[i] +
-		 * ale_mask or info->ioaddr[i].  In other words,
-		 * IO_ADDR_W - info->ioaddr[i], must be cle_mask, ale_mask,
-		 * or 0, so if we ignore cle_mask and ale_mask, all other
-		 * bits must be 0 for address match. If the other bits are
-		 * not 0, address does not match, and we try the next entry.
-		 */
-		if (((IO_ADDR_W - (u32) info->ioaddr[i]) &
-		    ~(info->cle_mask | info->ale_mask)) == 0) {
-			IO_ADDR_W = (u32) info->ioaddr[i];
-			break;
-		}
-	}
-
-	/*
-	 * Please note that "+" is used to get the offset instead of the
-	 * typical "|".  The reason is DM646x uses a NAND chip with cle_mask =
-	 * 0x80000.  Due to the high bit position, it interferes with the IO
-	 * address (kernel assigned 0xc8080000).  Therefore, the "|" has no
-	 * affect on getting the offset, and "+" is used.
-	 */
-	if (ctrl & NAND_CLE)
-		IO_ADDR_W += info->cle_mask;
-	else if (ctrl & NAND_ALE)
-		IO_ADDR_W += info->ale_mask;
-
-	this->IO_ADDR_W = (void __iomem *)IO_ADDR_W;
-
-	if (cmd == NAND_CMD_NONE)
-		return;
-
-	__raw_writeb(cmd, this->IO_ADDR_W);
-}
-
-/*
- * 1-bit ECC routines
- */
-
-static void nand_davinci_1bit_enable_hwecc(struct mtd_info *mtd, int mode)
-{
-	struct nand_chip *this = mtd->priv;
-	struct nand_davinci_info *info = this->priv;
-	void __iomem *nandfcr = info->emifregs + NANDFCR;
-
-	switch (mode) {
-	case NAND_ECC_WRITE:
-	case NAND_ECC_READ:
-		__raw_writel(__raw_readl(nandfcr) | (1 << (8 + info->ce)),
-			     nandfcr);
-		break;
-	default:
-		break;
-	}
-}
-
-/*
- * Read the NAND ECC register corresponding to chip enable ce, where 0<=ce<=3.
- */
-static u32 nand_davinci_1bit_readecc(struct mtd_info *mtd, u32 ce)
-{
-	struct nand_chip *this = mtd->priv;
-	struct nand_davinci_info *info = this->priv;
-
-	return __raw_readl(info->emifregs + NANDF1ECC + 4 * ce);
-}
-
-static int nand_davinci_1bit_calculate_ecc(struct mtd_info *mtd,
-					   const uint8_t *dat,
-					   uint8_t *ecc_code)
-{
-	unsigned int l;
-	struct nand_chip *this = mtd->priv;
-	struct nand_davinci_info *info = this->priv;
-
-	l = nand_davinci_1bit_readecc(mtd, info->ce);
-	*ecc_code++ = l;	/* P128e, ..., P1e */
-	*ecc_code++ = l >> 16;	/* P128o, ..., P1o */
-	/* P2048o, P1024o, P512o, P256o, P2048e, P1024e, P512e, P256e */
-	*ecc_code++ = ((l >> 8) & 0x0f) | ((l >> 20) & 0xf0);
-
-	return 0;
-}
-
-static void nand_davinci_1bit_gen_true_ecc(uint8_t *ecc_buf)
-{
-	u32 tmp =
-	    ecc_buf[0] | (ecc_buf[1] << 16) | ((ecc_buf[2] & 0xF0) << 20) |
-	    ((ecc_buf[2] & 0x0F) << 8);
-
-	ecc_buf[0] =
-	    ~(P64o(tmp) | P64e(tmp) | P32o(tmp) | P32e(tmp) | P16o(tmp) |
-	      P16e(tmp) | P8o(tmp) | P8e(tmp));
-	ecc_buf[1] =
-	    ~(P1024o(tmp) | P1024e(tmp) | P512o(tmp) | P512e(tmp) | P256o(tmp) |
-	      P256e(tmp) | P128o(tmp) | P128e(tmp));
-	ecc_buf[2] =
-	    ~(P4o(tmp) | P4e(tmp) | P2o(tmp) | P2e(tmp) | P1o(tmp) | P1e(tmp) |
-	      P2048o(tmp) | P2048e(tmp));
-}
-
-/**
- * nand_davinci_1bit_compare_ecc
- * @ecc_data1	read from NAND memory
- * @ecc_data2	read from register
- * @page_data	data
- */
-
-static int
-nand_davinci_1bit_compare_ecc(uint8_t *ecc_data1, uint8_t *ecc_data2,
-				uint8_t *page_data)
-{
-	u32 i;
-	u8 tmp0_bit[8], tmp1_bit[8], tmp2_bit[8];
-	u8 comp0_bit[8], comp1_bit[8], comp2_bit[8];
-	u8 ecc_bit[24];
-	u8 ecc_sum = 0;
-	u8 find_bit = 0;
-	u32 find_byte = 0;
-	int isEccFF;
-
-	isEccFF = ((*(u32 *) ecc_data1 & 0xFFFFFF) == 0xFFFFFF);
-
-	nand_davinci_1bit_gen_true_ecc(ecc_data1);
-	nand_davinci_1bit_gen_true_ecc(ecc_data2);
-
-	for (i = 0; i <= 2; i++) {
-		*(ecc_data1 + i) = ~(*(ecc_data1 + i));
-		*(ecc_data2 + i) = ~(*(ecc_data2 + i));
-	}
-
-	for (i = 0; i < 8; i++) {
-		tmp0_bit[i] = *ecc_data1 % 2;
-		*ecc_data1 = *ecc_data1 / 2;
-	}
-
-	for (i = 0; i < 8; i++) {
-		tmp1_bit[i] = *(ecc_data1 + 1) % 2;
-		*(ecc_data1 + 1) = *(ecc_data1 + 1) / 2;
-	}
-
-	for (i = 0; i < 8; i++) {
-		tmp2_bit[i] = *(ecc_data1 + 2) % 2;
-		*(ecc_data1 + 2) = *(ecc_data1 + 2) / 2;
-	}
-
-	for (i = 0; i < 8; i++) {
-		comp0_bit[i] = *ecc_data2 % 2;
-		*ecc_data2 = *ecc_data2 / 2;
-	}
-
-	for (i = 0; i < 8; i++) {
-		comp1_bit[i] = *(ecc_data2 + 1) % 2;
-		*(ecc_data2 + 1) = *(ecc_data2 + 1) / 2;
-	}
-
-	for (i = 0; i < 8; i++) {
-		comp2_bit[i] = *(ecc_data2 + 2) % 2;
-		*(ecc_data2 + 2) = *(ecc_data2 + 2) / 2;
-	}
-
-	for (i = 0; i < 6; i++)
-		ecc_bit[i] = tmp2_bit[i + 2] ^ comp2_bit[i + 2];
-
-	for (i = 0; i < 8; i++)
-		ecc_bit[i + 6] = tmp0_bit[i] ^ comp0_bit[i];
-
-	for (i = 0; i < 8; i++)
-		ecc_bit[i + 14] = tmp1_bit[i] ^ comp1_bit[i];
-
-	ecc_bit[22] = tmp2_bit[0] ^ comp2_bit[0];
-	ecc_bit[23] = tmp2_bit[1] ^ comp2_bit[1];
-
-	for (i = 0; i < 24; i++)
-		ecc_sum += ecc_bit[i];
-
-	switch (ecc_sum) {
-	case 0:
-		/* Not reached because this function is not called if
-		   ECC values are equal */
-		return 0;
-
-	case 1:
-		/*
-		 * This case corresponds to a 1-bit error in the ECC code
-		 * itself.  We'll return 1 to indicate that a 1-bit error was
-		 * detected and corrected, but there is no need to correct
-		 * anything.
-		 */
-		DEBUG(MTD_DEBUG_LEVEL0, "Detected single-bit error in ECC\n");
-		return 1;
-
-	case 12:
-		/* Correctable error */
-		find_byte = (ecc_bit[23] << 8) +
-		    (ecc_bit[21] << 7) +
-		    (ecc_bit[19] << 6) +
-		    (ecc_bit[17] << 5) +
-		    (ecc_bit[15] << 4) +
-		    (ecc_bit[13] << 3) +
-		    (ecc_bit[11] << 2) + (ecc_bit[9] << 1) + ecc_bit[7];
-
-		find_bit = (ecc_bit[5] << 2) + (ecc_bit[3] << 1) + ecc_bit[1];
-
-		DEBUG(MTD_DEBUG_LEVEL0,
-		      "Correcting single bit ECC error at offset: %d, "
-		      "bit: %d\n", find_byte, find_bit);
-
-		page_data[find_byte] ^= (1 << find_bit);
-
-		return 1;
-
-	default:
-		if (isEccFF) {
-			if (ecc_data2[0] == 0 && ecc_data2[1] == 0
-			    && ecc_data2[2] == 0)
-				return 0;
-		}
-		DEBUG(MTD_DEBUG_LEVEL0, "UNCORRECTED_ERROR default\n");
-		return -1;
-	}
-}
-
-static int nand_davinci_1bit_correct_data(struct mtd_info *mtd, uint8_t *dat,
-					  uint8_t *read_ecc, uint8_t *calc_ecc)
-{
-	int r = 0;
-
-	if (memcmp(read_ecc, calc_ecc, 3) != 0) {
-		u_char read_ecc_copy[3], calc_ecc_copy[3];
-		int i;
-
-		for (i = 0; i < 3; i++) {
-			read_ecc_copy[i] = read_ecc[i];
-			calc_ecc_copy[i] = calc_ecc[i];
-		}
-		r = nand_davinci_1bit_compare_ecc(read_ecc_copy, calc_ecc_copy,
-						  dat);
-	}
-
-	return r;
-}
-
-/*
- * We should always have a flash-based bad block table.  However, if one isn't
- * found then all blocks will be scanned to look for factory-marked bad blocks.
- * We supply a null pattern so that no blocks will be detected as bad.
- */
-static struct nand_bbt_descr nand_davinci_4bit_badblock_pattern = {
-	.options = 0,
-	.offs = 0,
-	.len = 0,
-	.pattern = NULL,
-};
-
-static struct nand_ecclayout nand_davinci_4bit_layout = {
-	.eccbytes = 10,
-	.eccpos = {6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
-		   22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
-		   38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
-		   54, 55, 56, 57, 58, 59, 60, 61, 62, 63,
-		   },
-	.oobfree = {{0, 6}, {16, 6}, {32, 6}, {48, 6} },
-};
-
-/*
- * When using 4-bit ECC with a 2048-byte data + 64-byte spare page size, the
- * oob is scattered throughout the page in 4 16-byte chunks instead of being
- * grouped together at the end of the page.  This means that the factory
- * bad-block markers at offsets 2048 and 2049 will be overwritten when data
- * is written to the flash.  Thus, we cannot use the factory method to mark
- * or detect bad blocks and must rely on a flash-based bad block table instead.
- *
- */
-static int
-nand_davinci_4bit_block_bad(struct mtd_info *mtd, loff_t ofs, int getchip)
-{
-	return 0;
-}
-
-static void nand_davinci_4bit_enable_hwecc(struct mtd_info *mtd, int mode)
-{
-	struct nand_chip *this = mtd->priv;
-	struct nand_davinci_info *info = this->priv;
-	void __iomem *nandfcr;
-	u32 val;
-
-	switch (mode) {
-	case NAND_ECC_WRITE:
-	case NAND_ECC_READ:
-		/*
-		 * Start a new ECC calculation for reading or writing 512 bytes
-		 *  of data.
-		 */
-		nandfcr = info->emifregs + NANDFCR;
-		val = (__raw_readl(nandfcr) & ~(3 << 4))
-		    | (info->ce << 4) | (1 << 12);
-		__raw_writel(val, nandfcr);
-		break;
-	case NAND_ECC_READSYN:
-		__raw_readl(info->emifregs + NAND4BITECC1);
-		break;
-	default:
-		break;
-	}
-}
-
-static u32 nand_davinci_4bit_readecc(struct mtd_info *mtd, unsigned int ecc[4])
-{
-	struct nand_chip *this = mtd->priv;
-	struct nand_davinci_info *info = this->priv;
-
-	ecc[0] = __raw_readl(info->emifregs + NAND4BITECC1) & NAND_4BITECC_MASK;
-	ecc[1] = __raw_readl(info->emifregs + NAND4BITECC2) & NAND_4BITECC_MASK;
-	ecc[2] = __raw_readl(info->emifregs + NAND4BITECC3) & NAND_4BITECC_MASK;
-	ecc[3] = __raw_readl(info->emifregs + NAND4BITECC4) & NAND_4BITECC_MASK;
-
-	return 0;
-}
-
-static int nand_davinci_4bit_calculate_ecc(struct mtd_info *mtd,
-					   const uint8_t *dat,
-					   uint8_t *ecc_code)
-{
-	unsigned int hw_4ecc[4] = { 0, 0, 0, 0 };
-	unsigned int const1 = 0, const2 = 0;
-	unsigned char count1 = 0;
-
-	/*
-	 * Since the NAND_HWECC_SYNDROME option is enabled, this routine is
-	 * only called just after the data and oob have been written.  The
-	 * ECC value calculated by the hardware ECC generator is available
-	 * for us to read.
-	 */
-	nand_davinci_4bit_readecc(mtd, hw_4ecc);
-
-	/*Convert 10 bit ecc value to 8 bit */
-	for (count1 = 0; count1 < 2; count1++) {
-		const2 = count1 * 5;
-		const1 = count1 * 2;
-
-		/* Take first 8 bits from val1 (count1=0) or val5 (count1=1) */
-		ecc_code[const2] = hw_4ecc[const1] & 0xFF;
-
-		/*
-		 * Take 2 bits as LSB bits from val1 (count1=0) or val5
-		 * (count1=1) and 6 bits from val2 (count1=0) or val5 (count1=1)
-		 */
-		ecc_code[const2 + 1] =
-		    ((hw_4ecc[const1] >> 8) & 0x3) | ((hw_4ecc[const1] >> 14) &
-						      0xFC);
-
-		/*
-		 * Take 4 bits from val2 (count1=0) or val5 (count1=1) and
-		 * 4 bits from val3 (count1=0) or val6 (count1=1)
-		 */
-		ecc_code[const2 + 2] =
-		    ((hw_4ecc[const1] >> 22) & 0xF) |
-		    ((hw_4ecc[const1 + 1] << 4) & 0xF0);
-
-		/*
-		 * Take 6 bits from val3(count1=0) or val6 (count1=1) and
-		 * 2 bits from val4 (count1=0) or  val7 (count1=1)
-		 */
-		ecc_code[const2 + 3] =
-		    ((hw_4ecc[const1 + 1] >> 4) & 0x3F) |
-		    ((hw_4ecc[const1 + 1] >> 10) & 0xC0);
-
-		/* Take 8 bits from val4 (count1=0) or val7 (count1=1) */
-		ecc_code[const2 + 4] = (hw_4ecc[const1 + 1] >> 18) & 0xFF;
-	}
-	return 0;
-}
-
-static int nand_davinci_4bit_compare_ecc(struct mtd_info *mtd,
-					 uint8_t *read_ecc, /* read from NAND */
-					 uint8_t *page_data)
-{
-	struct nand_chip *this = mtd->priv;
-	struct nand_davinci_info *info = this->priv;
-	unsigned short ecc_10bit[8] = { 0, 0, 0, 0, 0, 0, 0, 0 };
-	int i;
-	unsigned int hw_4ecc[4] = { 0, 0, 0, 0 }, iserror = 0;
-	unsigned short *pspare = NULL, *pspare1 = NULL;
-	unsigned int numErrors, errorAddress, errorValue;
-	u32 val;
-
-	/*
-	 * Check for an ECC where all bytes are 0xFF.  If this is the case, we
-	 * will assume we are looking at an erased page and we should ignore the
-	 * ECC.
-	 */
-	for (i = 0; i < 10; i++) {
-		if (read_ecc[i] != 0xFF)
-			break;
-	}
-	if (i == 10)
-		return 0;
-
-	/* Convert 8 bit in to 10 bit */
-	pspare = (unsigned short *)&read_ecc[2];
-	pspare1 = (unsigned short *)&read_ecc[0];
-	/* Take 10 bits from 0th and 1st bytes */
-	ecc_10bit[0] = (*pspare1) & 0x3FF;	/* 10 */
-	/* Take 6 bits from 1st byte and 4 bits from 2nd byte */
-	ecc_10bit[1] = (((*pspare1) >> 10) & 0x3F)
-	    | (((pspare[0]) << 6) & 0x3C0);	/* 6 + 4 */
-	/* Take 4 bits form 2nd bytes and 6 bits from 3rd bytes */
-	ecc_10bit[2] = ((pspare[0]) >> 4) & 0x3FF;	/* 10 */
-	/*Take 2 bits from 3rd byte and 8 bits from 4th byte */
-	ecc_10bit[3] = (((pspare[0]) >> 14) & 0x3)
-	    | ((((pspare[1])) << 2) & 0x3FC);	/* 2 + 8 */
-	/* Take 8 bits from 5th byte and 2 bits from 6th byte */
-	ecc_10bit[4] = ((pspare[1]) >> 8)
-	    | ((((pspare[2])) << 8) & 0x300);	/* 8 + 2 */
-	/* Take 6 bits from 6th byte and 4 bits from 7th byte */
-	ecc_10bit[5] = (pspare[2] >> 2) & 0x3FF;	/* 10 */
-	/* Take 4 bits from 7th byte and 6 bits from 8th byte */
-	ecc_10bit[6] = (((pspare[2]) >> 12) & 0xF)
-	    | ((((pspare[3])) << 4) & 0x3F0);	/* 4 + 6 */
-	/*Take 2 bits from 8th byte and 8 bits from 9th byte */
-	ecc_10bit[7] = ((pspare[3]) >> 6) & 0x3FF;	/* 10 */
-
-	/*
-	 * Write the parity values in the NAND Flash 4-bit ECC Load register.
-	 * Write each parity value one at a time starting from 4bit_ecc_val8
-	 * to 4bit_ecc_val1.
-	 */
-	for (i = 7; i >= 0; i--)
-		__raw_writel(ecc_10bit[i], info->emifregs + NAND4BITECCLOAD);
-
-	/*
-	 * Perform a dummy read to the EMIF Revision Code and Status register.
-	 * This is required to ensure time for syndrome calculation after
-	 * writing the ECC values in previous step.
-	 */
-	__raw_readl(info->emifregs + NANDFSR);
-
-	/*
-	 * Read the syndrome from the NAND Flash 4-Bit ECC 1-4 registers.
-	 * A syndrome value of 0 means no bit errors. If the syndrome is
-	 * non-zero then go further otherwise return.
-	 */
-	nand_davinci_4bit_readecc(mtd, hw_4ecc);
-
-	if (hw_4ecc[0] == ECC_STATE_NO_ERR && hw_4ecc[1] == ECC_STATE_NO_ERR &&
-	    hw_4ecc[2] == ECC_STATE_NO_ERR && hw_4ecc[3] == ECC_STATE_NO_ERR)
-		return 0;
-
-	/*
-	 * Clear any previous address calculation by doing a dummy read of an
-	 * error address register.
-	 */
-	__raw_readl(info->emifregs + NANDERRADD1);
-
-	/*
-	 * Set the addr_calc_st bit(bit no 13) in the NAND Flash Control
-	 * register to 1.
-	 */
-	__raw_writel(__raw_readl(info->emifregs + NANDFCR) | (1 << 13),
-		     info->emifregs + NANDFCR);
-
-	/*
-	 * Wait for the corr_state field (bits 8 to 11)in the
-	 * NAND Flash Status register to be equal to 0x0, 0x1, 0x2, or 0x3.
-	 */
-	i = NAND_TIMEOUT;
-	val = NAND_STATUS_RETRY;
-	do {
-		iserror = __raw_readl(info->emifregs + NANDFSR);
-		iserror &= EMIF_NANDFSR_ECC_STATE_MASK;
-		iserror = iserror >> 8;
-		if (iserror & NAND_ECC_BUSY && val != NAND_STATUS_RETRY)
-			val = NAND_STATUS_RETRY;
-		else
-			val--;
-		i--;
-	} while ((i > 0) && (val > 0));
-
-
-	/*
-	 * ECC_STATE_TOO_MANY_ERRS (0x1) means errors cannot be
-	 * corrected (five or more errors).  The number of errors
-	 * calculated (err_num field) differs from the number of errors
-	 * searched.  ECC_STATE_ERR_CORR_COMP_P (0x2) means error
-	 * correction complete (errors on bit 8 or 9).
-	 * ECC_STATE_ERR_CORR_COMP_N (0x3) means error correction
-	 * complete (error exists).
-	 */
-
-	if (iserror == ECC_STATE_NO_ERR)
-		return 0;
-	else if (iserror == ECC_STATE_TOO_MANY_ERRS) {
-		printk(KERN_ERR "%s Too many errors to be corrected!\n"
-				, __func__);
-		return -1;
-	}
-
-	numErrors = ((__raw_readl(info->emifregs + NANDFSR) >> 16) & 0x3) + 1;
-
-	/* Read the error address, error value and correct */
-	for (i = 0; i < numErrors; i++) {
-		if (i > 1) {
-			errorAddress =
-			    ((__raw_readl(info->emifregs + NANDERRADD2) >>
-			      (16 * (i & 1))) & 0x3FF);
-			errorAddress = ((512 + 7) - errorAddress);
-			errorValue =
-			    ((__raw_readl(info->emifregs + NANDERRVAL2) >>
-			      (16 * (i & 1))) & 0xFF);
-		} else {
-			errorAddress =
-			    ((__raw_readl(info->emifregs + NANDERRADD1) >>
-			      (16 * (i & 1))) & 0x3FF);
-			errorAddress = ((512 + 7) - errorAddress);
-			errorValue =
-			    ((__raw_readl(info->emifregs + NANDERRVAL1) >>
-			      (16 * (i & 1))) & 0xFF);
-		}
-		/* xor the corrupt data with error value */
-		if (errorAddress < 512)
-			page_data[errorAddress] ^= errorValue;
-	}
-
-	return numErrors;
-}
-
-static int nand_davinci_4bit_correct_data(struct mtd_info *mtd, uint8_t *dat,
-					  uint8_t *read_ecc, uint8_t *calc_ecc)
-{
-	int r;
-
-	/*
-	 * dat points to 512 bytes of data.  read_ecc points to the start of the
-	 * ECC code exactly...  The calc_ecc pointer is not needed since
-	 * our caclulated ECC is already latched in the hardware ECC generator.
-	 */
-	r = nand_davinci_4bit_compare_ecc(mtd, read_ecc, dat);
-
-	return r;
-}
-
-static int
-davinci_read_page_syndrome(struct mtd_info *mtd, struct nand_chip *chip,
-				   uint8_t *buf)
-{
-	int i, eccsize = chip->ecc.size;
-	int eccbytes = chip->ecc.bytes;
-	int eccsteps = chip->ecc.steps;
-	uint8_t *p = buf;
-	uint8_t *oob = chip->oob_poi;
-
-	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
-		int stat;
-
-		chip->ecc.hwctl(mtd, NAND_ECC_READ);
-		chip->read_buf(mtd, p, eccsize);
-
-		chip->ecc.hwctl(mtd, NAND_ECC_READSYN);
-
-		if (chip->ecc.prepad) {
-			chip->read_buf(mtd, oob, chip->ecc.prepad);
-			oob += chip->ecc.prepad;
-		}
-
-		chip->read_buf(mtd, oob, eccbytes);
-		stat = chip->ecc.correct(mtd, p, oob, NULL);
-
-		if (stat == -1)
-			mtd->ecc_stats.failed++;
-		else
-			mtd->ecc_stats.corrected += stat;
-
-		oob += eccbytes;
-
-		if (chip->ecc.postpad) {
-			chip->read_buf(mtd, oob, chip->ecc.postpad);
-			oob += chip->ecc.postpad;
-		}
-	}
-
-	/* Calculate remaining oob bytes */
-	i = mtd->oobsize - (oob - chip->oob_poi);
-	if (i)
-		chip->read_buf(mtd, oob, i);
-
-	return 0;
-}
-
-static void davinci_write_page_syndrome(struct mtd_info *mtd,
-				    struct nand_chip *chip, const uint8_t *buf)
-{
-	int i, eccsize = chip->ecc.size;
-	int eccbytes = chip->ecc.bytes;
-	int eccsteps = chip->ecc.steps;
-	const uint8_t *p = buf;
-	uint8_t *oob = chip->oob_poi;
-
-	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
-
-		chip->ecc.hwctl(mtd, NAND_ECC_WRITE);
-		chip->write_buf(mtd, p, eccsize);
-
-		/* Calculate ECC without prepad */
-		chip->ecc.calculate(mtd, p, oob + chip->ecc.prepad);
-
-		if (chip->ecc.prepad) {
-			chip->write_buf(mtd, oob, chip->ecc.prepad);
-			oob += chip->ecc.prepad;
-		}
-		chip->write_buf(mtd, oob, eccbytes);
-		oob += eccbytes;
-
-		if (chip->ecc.postpad) {
-			chip->write_buf(mtd, oob, chip->ecc.postpad);
-			oob += chip->ecc.postpad;
-		}
-	}
-
-	/* Calculate remaining oob bytes */
-	i = mtd->oobsize - (oob - chip->oob_poi);
-	if (i)
-		chip->write_buf(mtd, oob, i);
-}
-static int nand_flash_init(struct nand_davinci_info *info)
-{
-	__raw_writel((1 << info->ce), info->emifregs + NANDFCR);
-
-	return 0;
-}
-
-#define res_size(_r) (((_r)->end - (_r)->start) + 1)
-
-static int __devinit nand_davinci_probe(struct device *dev)
-{
-	int err = 0, cs;
-	struct nand_davinci_info *info;
-	struct platform_device *pdev = to_platform_device(dev);
-	struct nand_davinci_platform_data *pdata = pdev->dev.platform_data;
-	struct nand_chip *this;
-	struct resource *res;
-	u32 rev_code;
-
-	info = kzalloc(sizeof(struct nand_davinci_info), GFP_KERNEL);
-	if (!info) {
-		err = -ENOMEM;
-		goto out;
-	}
-
-	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-	if (!res || (res_size(res) < EMIF_REG_SIZE)) {
-		dev_err(dev, "insufficient resources\n");
-		err = -ENOENT;
-		goto out_free_info;
-	}
-
-	/*
-	 * We exclude the EMIF registers prior to NANDFCR (the chip select
-	 * timing registers) from our resource reservation request because we
-	 * don't use them and another module might need them.
-	 */
-	info->reg_res = request_mem_region(res->start + NANDFCR,
-					   res_size(res) - NANDFCR, pdev->name);
-	if (!info->reg_res) {
-		dev_err(dev, "cannot claim register memory region\n");
-		err = -EIO;
-		goto out_free_info;
-	}
-	info->emifregs = ioremap_nocache(res->start, res_size(res));
-
-	for (cs = 0; cs < MAX_CHIPS; cs++) {
-		res = platform_get_resource(pdev, IORESOURCE_MEM, cs + 1);
-		if (!res)
-			break;
-
-		if (cs == 0)
-			info->ce = EMIF_ADDR_TO_CE(res->start);
-		else {
-			if (info->ce != EMIF_ADDR_TO_CE(res->start)) {
-				dev_err(dev,
-					"bad secondary nand address 0x%08lx\n",
-					(unsigned long) res->start);
-				err = -EIO;
-				goto out_release_mem;
-			}
-		}
-
-		info->data_res[cs] = request_mem_region(res->start,
-							res_size(res),
-							pdev->name);
-		if (!info->data_res[cs]) {
-			dev_err(dev,
-				"cannot claim nand memory region at 0x%08lx\n",
-				(unsigned long) res->start);
-			err = -EIO;
-			goto out_release_mem;
-		}
-
-		info->ioaddr[cs] = ioremap_nocache(res->start, res_size(res));
-		if (!info->ioaddr[cs]) {
-			dev_err(dev,
-				"cannot ioremap nand memory region "
-				"at 0x%08lx\n", (unsigned long) res->start);
-			err = -ENOMEM;
-			goto out_release_mem;
-		}
-	}
-	if (!info->data_res[0]) {
-		dev_err(dev, "insufficient resources\n");
-		err = -ENOENT;
-		goto out_release_mem;
-	}
-
-	/* Allocate memory for the MTD device structure */
-	info->mtd = kzalloc(sizeof(struct mtd_info) +
-			    sizeof(struct nand_chip), GFP_KERNEL);
-	if (!info->mtd) {
-		err = -ENOMEM;
-		goto out_release_mem;
-	}
-
-	/* Get pointer to the nand private data */
-	this = (struct nand_chip *)(&info->mtd[1]);
-	/* Link the nand private data with the MTD structure */
-	info->mtd->priv = this;
-	/* Link our driver private data with the nand private data */
-	this->priv = info;
-
-	this->select_chip = nand_davinci_select_chip;
-	this->cmd_ctrl = nand_davinci_hwcontrol;
-	this->options = pdata->options;
-	this->bbt_td = pdata->bbt_td;
-	this->bbt_md = pdata->bbt_md;
-	this->chip_delay = 25;
-
-	info->cle_mask = pdata->cle_mask;
-	info->ale_mask = pdata->ale_mask;
-
-	this->ecc.mode = pdata->ecc_mode;
-
-	switch (this->ecc.mode) {
-	case NAND_ECC_NONE:
-		dev_warn(dev, "Warning: NAND ECC is disabled\n");
-		break;
-	case NAND_ECC_SOFT:
-		dev_info(dev, "Using soft ECC\n");
-		break;
-	case NAND_ECC_HW:
-			dev_info(dev, "Using 1-bit hardware ECC\n");
-		this->ecc.size = 512;
-		this->ecc.bytes = 3;
-			this->ecc.calculate = nand_davinci_1bit_calculate_ecc;
-			this->ecc.correct = nand_davinci_1bit_correct_data;
-			this->ecc.hwctl = nand_davinci_1bit_enable_hwecc;
-		break;
-	case NAND_ECC_HW_SYNDROME:
-		dev_info(dev, "Using 4-bit hardware ECC\n");
-		this->ecc.size = 512;
-		this->ecc.bytes = 10;
-		this->ecc.prepad = 6;
-		this->ecc.layout = &nand_davinci_4bit_layout;
-		this->ecc.calculate = nand_davinci_4bit_calculate_ecc;
-		this->ecc.correct = nand_davinci_4bit_correct_data;
-		this->ecc.hwctl = nand_davinci_4bit_enable_hwecc;
-		this->ecc.read_page = davinci_read_page_syndrome;
-		this->ecc.write_page = davinci_write_page_syndrome;
-		/* we also need special bad block table because
-		 * factory marks are overwritten */
-		this->options |= (NAND_USE_FLASH_BBT
-				| NAND_USE_DATA_ADJACENT_OOB);
-		this->badblock_pattern = &nand_davinci_4bit_badblock_pattern;
-		this->block_bad = nand_davinci_4bit_block_bad;
-		break;
-	default:
-		dev_err(dev, "Unsupported ECC mode %d requested\n",
-			this->ecc.mode);
-		goto out_release_mem;
-	}
-
-	info->mtd->name = pdev->dev.bus_id;
-	info->mtd->owner = THIS_MODULE;
-
-	info->clk = clk_get(dev, "AEMIFCLK");
-	if (IS_ERR(info->clk)) {
-		err = -ENXIO;
-		goto out_free_mtd;
-	}
-	clk_enable(info->clk);
-
-	nand_flash_init(info);
-
-	/* Scan for the device */
-	if (nand_scan(info->mtd, info->data_res[1] ? 2 : 1)) {
-		dev_err(dev, "no nand device detected\n");
-		err = -ENODEV;
-		goto out_unuse_clk;
-	}
-
-	/* Terminate any ECC calculation already in progress */
-	switch (this->ecc.mode) {
-	case NAND_ECC_HW:
-		nand_davinci_1bit_enable_hwecc(info->mtd, NAND_ECC_WRITE);
-		nand_davinci_1bit_readecc(info->mtd, info->ce);
-		break;
-	case NAND_ECC_HW_SYNDROME:
-		{
-			unsigned int ecc[4];
-			nand_davinci_4bit_enable_hwecc(info->mtd,
-					NAND_ECC_WRITE);
-			nand_davinci_4bit_readecc(info->mtd, ecc);
-		}
-	default:
-		break;
-	}
-
-#ifdef CONFIG_MTD_PARTITIONS
-	err = parse_mtd_partitions(info->mtd, part_probes, &info->parts, 0);
-	if (err > 0)
-		add_mtd_partitions(info->mtd, info->parts, err);
-	else if (err < 0 && pdata->parts)
-		add_mtd_partitions(info->mtd, pdata->parts, pdata->nr_parts);
-	else
-#endif
-		add_mtd_device(info->mtd);
-
-	dev_set_drvdata(dev, info);
-
-	/* show rev code */
-	rev_code = __raw_readl(info->emifregs);
-	dev_info(dev, "hardware revision: %d.%d\n",
-		 (rev_code >> 8) & 0xff, rev_code & 0xff);
-
-	return 0;
-
-out_unuse_clk:
-	clk_disable(info->clk);
-out_free_mtd:
-	kfree(info->mtd);
-out_release_mem:
-	for (cs = 0; cs < MAX_CHIPS; cs++) {
-		if (info->ioaddr[cs])
-			iounmap(info->ioaddr[cs]);
-		if (info->data_res[cs]) {
-			release_resource(info->data_res[cs]);
-			kfree(info->data_res[cs]);
-		}
-	}
-	release_resource(info->reg_res);
-	kfree(info->reg_res);
-out_free_info:
-	kfree(info);
-out:
-	return err;
-}
-
-static int __devexit nand_davinci_remove(struct device *dev)
-{
-	struct nand_davinci_info *info = dev_get_drvdata(dev);
-	int cs;
-
-	if (info) {
-		/* Release NAND device, internal structures, and partitions */
-		nand_release(info->mtd);
-
-		clk_disable(info->clk);
-
-		kfree(info->mtd);
-
-		for (cs = 0; cs < MAX_CHIPS; cs++) {
-			if (info->ioaddr[cs])
-				iounmap(info->ioaddr[cs]);
-			if (info->data_res[cs]) {
-				release_resource(info->data_res[cs]);
-				kfree(info->data_res[cs]);
-			}
-		}
-
-		release_resource(info->reg_res);
-		kfree(info->reg_res);
-
-		kfree(info);
-
-		dev_set_drvdata(dev, NULL);
-	}
-
-	return 0;
-}
-
-static struct device_driver nand_davinci_driver = {
-	.name = "nand_davinci",
-	.bus = &platform_bus_type,
-	.probe = nand_davinci_probe,
-	.remove = __devexit_p(nand_davinci_remove),
-};
-
-static int __init nand_davinci_init(void)
-{
-	return driver_register(&nand_davinci_driver);
-}
-
-static void __exit nand_davinci_exit(void)
-{
-	driver_unregister(&nand_davinci_driver);
-}
-
-module_init(nand_davinci_init);
-module_exit(nand_davinci_exit);
-MODULE_LICENSE("GPL");
-MODULE_AUTHOR("Texas Instruments");
-MODULE_DESCRIPTION("Board-specific driver for NAND flash on davinci board");
Index: linux-2.6.18/mvl_patches/pro50-2267.c
===================================================================
--- /dev/null
+++ linux-2.6.18/mvl_patches/pro50-2267.c
@@ -0,0 +1,16 @@
+/*
+ * Author: MontaVista Software, Inc. <source@mvista.com>
+ *
+ * 2009 (c) MontaVista Software, Inc. This file is licensed under
+ * the terms of the GNU General Public License version 2. This program
+ * is licensed "as is" without any warranty of any kind, whether express
+ * or implied.
+ */
+#include <linux/init.h>
+#include <linux/mvl_patch.h>
+
+static __init int regpatch(void)
+{
+        return mvl_register_patch(2267);
+}
+module_init(regpatch);
EOF

    rv=0
    cat /tmp/mvl_patch_$$
    if [ "$?" != "0" ]; then
	# Patch had a hard error, return 2
	rv=2
    elif grep '^Hunk' ${TMPFILE}; then
	rv=1
    fi

    rm -f ${TMPFILE}
    return $rv
}

function options() {
    echo "Options are:"
    echo "  --force-unsupported - Force the patch to be applied even if the"
    echo "      patch is out of order or the current kernel is unsupported."
    echo "      Use of this option is strongly discouraged."
    echo "  --force-apply-fuzz - If the patch has fuzz, go ahead and apply"
    echo "      it anyway.  This can occur if the patch is applied to an"
    echo "      unsupported kernel or applied out of order or if you have"
    echo "      made your own modifications to the kernel.  Use with"
    echo "      caution."
    echo "  --remove - Remove the patch"
}


function checkpatchnum() {
    local level;

    if [ ! -e ${1} ]; then
	echo "${1} does not exist, make sure you are in the kernel" 1>&2
	echo "base directory" 1>&2
	exit 1;
    fi

    # Extract the current patch number from the lsp info file.
    level=`grep '#define LSP_.*PATCH_LEVEL' ${1} | sed 's/^.*\"\\(.*\\)\".*\$/\\1/'`
    if [ "a$level" = "a" ]; then
	echo "No patch level defined in ${1}, are you sure this is" 1>&2
	echo "a valid MVL kernel LSP?" 1>&2
	exit 1;
    fi

    expr $level + 0 >/dev/null 2>&1
    isnum=$?

    # Check if the kernel is supported
    if [ "$level" = "unsupported" ]; then
	echo "**Current kernel is unsupported by MontaVista due to patches"
	echo "  begin applied out of order."
	if [ $force_unsupported == 't' ]; then
	    echo "  Application is forced, applying patch anyway"
	    unsupported=t
	    fix_patch_level=f
	else
	    echo "  Patch application aborted.  Use --force-unsupported to"
	    echo "  force the patch to be applied, but the kernel will not"
	    echo "  be supported by MontaVista."
	    exit 1;
	fi

    # Check the patch number from the lspinfo file to make sure it is
    # a valid number
    elif [ $isnum = 2 ]; then
	echo "**Patch level from ${1} was not a valid number, " 1>&2
	echo "  are you sure this is a valid MVL kernel LSP?" 1>&2
	exit 1;

    # Check that this is the right patch number to be applied.
    elif [ `expr $level $3` ${4} ${2} ]; then
	echo "**Application of this patch is out of order and will cause the"
	echo "  kernel to be unsupported by MontaVista."
	if [ $force_unsupported == 't' ]; then
	    echo "  application is forced, applying patch anyway"
	    unsupported=t
	else
	    echo "  Patch application aborted.  Please get all the patches in"
	    echo "  proper order from MontaVista Zone and apply them in order"
	    echo "  If you really want to apply this patch, use"
	    echo "  --force-unsupported to force the patch to be applied, but"
	    echo "  the kernel will not be supported by MontaVista."
	    exit 1;
	fi
    fi
}

#
# Update the patch level in the file.  Note that we use patch to do
# this.  Certain weak version control systems don't take kindly to
# arbitrary changes directly to files, but do have a special version
# of "patch" that understands this.
#
function setpatchnum() {
    sed "s/^#define LSP_\(.*\)PATCH_LEVEL[ \t*]\"[0-9]*\".*$/#define LSP_\1PATCH_LEVEL \"${2}\"/" <${1} >/tmp/$$.tmp1
    diff -u ${1} /tmp/$$.tmp1 >/tmp/$$.tmp2
    rm /tmp/$$.tmp1
    sed "s/^+++ \/tmp\/$$.tmp1/+++ include\/linux\/lsppatchlevel.h/" </tmp/$$.tmp2 >/tmp/$$.tmp1
    rm /tmp/$$.tmp2
    patch -p0 </tmp/$$.tmp1
    rm /tmp/$$.tmp1
}

force_unsupported=f
force_apply_fuzz=""
unsupported=f
fix_patch_level=t
reverse=f
common_patchnum_diff='+ 1'
common_patchnum=$PATCHNUM
patch_extraopts=''

# Extract command line parameters.
while [ $# -gt 0 ]; do
    if [ "a$1" == 'a--force-unsupported' ]; then
	force_unsupported=t
    elif [ "a$1" == 'a--force-apply-fuzz' ]; then
	force_apply_fuzz=y
    elif [ "a$1" == 'a--remove' ]; then
	reverse=t
	common_patchnum_diff=''
	common_patchnum=`expr $PATCHNUM - 1`
	patch_extraopts='--reverse'
    else
	echo "'$1' is an invalid command line parameter."
	options
	exit 1
    fi
    shift
done

echo "Checking patch level"
checkpatchnum ${LSPINFO} ${PATCHNUM} "${common_patchnum_diff}" "-ne"

if ! dopatch -p1 --dry-run --force $patch_extraopts; then
    if [ $? = 2 ]; then
	echo -n "**Patch had errors, application aborted" 1>&2
	exit 1;
    fi

    # Patch has warnings
    clean_apply=${force_apply_fuzz}
    while [ "a$clean_apply" != 'ay' -a "a$clean_apply" != 'an' ]; do
	echo -n "**Patch did not apply cleanly.  Do you still want to apply? (y/n) > "
	read clean_apply
	clean_apply=`echo "$clean_apply" | tr '[:upper:]' '[:lower:]'`
    done
    if [ $clean_apply = 'n' ]; then
	exit 1;
    fi
fi

dopatch -p1 --force $patch_extraopts

if [ $fix_patch_level = 't' ]; then 
    if [ $unsupported = 't' ]; then
	common_patchnum="unsupported"
    fi

    setpatchnum ${LSPINFO} ${common_patchnum}
fi

# Move the patch file into the mvl_patches directory if we are not reversing
if [ $reverse != 't' ]; then 
    if echo $0 | grep '/' >/dev/null; then
	# Filename is a path, either absolute or from the current directory.
	srcfile=$0
    else
	# Filename is from the path
	for i in `echo $PATH | tr ':;' '  '`; do
	    if [ -e ${i}/$0 ]; then
		srcfile=${i}/$0
	    fi
	done
    fi

    fname=`basename ${srcfile}`
    diff -uN mvl_patches/${fname} ${srcfile} | (cd mvl_patches; patch)
fi

